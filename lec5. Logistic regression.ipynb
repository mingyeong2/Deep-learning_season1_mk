{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "x_d = len(x_data[0])\n",
    "y_d = len(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plcaeholder for X and Y (tensor)\n",
    "X = tf.placeholder(tf.float32, shape = [None, x_d])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, y_d])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([x_d,y_d]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([y_d]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypothesis: tf의 sigmoid라는 함수를 이용해주면 자동으로 logistic regression 식으로 완성된다.\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid를 쓰지 않고 구현하기\n",
    "tf.div(1. , 1. + tf.exp(tf.matmul(X,W) + b))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost(loss) function\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy computation\n",
    "#True if prediction > 0.5 else False (generally)\n",
    "predicted = tf.cast(hypothesis>0.5, dtype = tf.float32)  #hypothesis를 0.5보다 크면 True로, 아니면 False로 바꾼 후 이를 float로 바꿔줌(1,0)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32)) #같으면 True, 아니면 False로 바꾼 후 이를 float로 바꿔줌(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   cost:  0.8470452\n",
      "200   cost:  0.6788664\n",
      "400   cost:  0.61834925\n",
      "600   cost:  0.58043927\n",
      "800   cost:  0.55224234\n",
      "1000   cost:  0.52883583\n",
      "1200   cost:  0.5081349\n",
      "1400   cost:  0.48917922\n",
      "1600   cost:  0.4714947\n",
      "1800   cost:  0.4548329\n",
      "2000   cost:  0.4390547\n",
      "2200   cost:  0.42407468\n",
      "2400   cost:  0.4098355\n",
      "2600   cost:  0.39629373\n",
      "2800   cost:  0.38341287\n",
      "3000   cost:  0.37116027\n",
      "3200   cost:  0.35950518\n",
      "3400   cost:  0.34841815\n",
      "3600   cost:  0.33787033\n",
      "3800   cost:  0.3278339\n",
      "4000   cost:  0.3182821\n",
      "4200   cost:  0.3091887\n",
      "4400   cost:  0.30052885\n",
      "4600   cost:  0.29227856\n",
      "4800   cost:  0.2844149\n",
      "5000   cost:  0.27691624\n",
      "5200   cost:  0.26976183\n",
      "5400   cost:  0.26293227\n",
      "5600   cost:  0.25640914\n",
      "5800   cost:  0.2501748\n",
      "6000   cost:  0.24421333\n",
      "6200   cost:  0.2385092\n",
      "6400   cost:  0.233048\n",
      "6600   cost:  0.22781612\n",
      "6800   cost:  0.22280096\n",
      "7000   cost:  0.2179905\n",
      "7200   cost:  0.21337368\n",
      "7400   cost:  0.20893998\n",
      "7600   cost:  0.2046796\n",
      "7800   cost:  0.20058328\n",
      "8000   cost:  0.19664252\n",
      "8200   cost:  0.19284916\n",
      "8400   cost:  0.18919553\n",
      "8600   cost:  0.18567462\n",
      "8800   cost:  0.1822797\n",
      "9000   cost:  0.1790045\n",
      "9200   cost:  0.17584318\n",
      "9400   cost:  0.17279005\n",
      "9600   cost:  0.16983996\n",
      "9800   cost:  0.16698806\n",
      "10000   cost:  0.16422975\n",
      "\n",
      "Hypothesis:  [[0.03717247]\n",
      " [0.16674317]\n",
      " [0.33430085]\n",
      " [0.7682397 ]\n",
      " [0.9309928 ]\n",
      " [0.97733283]] \n",
      "Correct (Y): [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Launch graph\n",
    "\n",
    "#gpu 에러 방지\n",
    "# config = tf.ConfigProto(device_count={'GPU': 0}) # uncomment this line to force CPU\n",
    "# config=config\n",
    "with tf.Session() as sess:\n",
    "    #Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict = {X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, '  cost: ', cost_val)\n",
    "            \n",
    "    #accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {X:x_data, Y:y_data})\n",
    "    #hypothesis가 0.5보다 크면 1\n",
    "    print('\\nHypothesis: ', h, '\\nCorrect (Y):', c, '\\nAccuracy: ',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = len(x_data[0])\n",
    "y_dim = len(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, x_dim])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, y_dim])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([x_dim, y_dim]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([y_dim]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W) +b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = - tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy computation\n",
    "#Threshold = 0.5\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.77463144\n",
      "200 0.6066098\n",
      "400 0.5717811\n",
      "600 0.5578814\n",
      "800 0.54833966\n",
      "1000 0.5404225\n",
      "1200 0.5335499\n",
      "1400 0.5275181\n",
      "1600 0.5222029\n",
      "1800 0.5175069\n",
      "2000 0.51334774\n",
      "2200 0.50965536\n",
      "2400 0.5063694\n",
      "2600 0.5034383\n",
      "2800 0.50081766\n",
      "3000 0.49846914\n",
      "3200 0.49635988\n",
      "3400 0.4944612\n",
      "3600 0.49274856\n",
      "3800 0.49120048\n",
      "4000 0.4897984\n",
      "4200 0.48852587\n",
      "4400 0.4873689\n",
      "4600 0.486315\n",
      "4800 0.4853533\n",
      "5000 0.48447415\n",
      "5200 0.4836691\n",
      "5400 0.48293075\n",
      "5600 0.48225248\n",
      "5800 0.48162845\n",
      "6000 0.4810534\n",
      "6200 0.48052278\n",
      "6400 0.48003244\n",
      "6600 0.47957867\n",
      "6800 0.4791583\n",
      "7000 0.47876817\n",
      "7200 0.47840574\n",
      "7400 0.47806868\n",
      "7600 0.47775468\n",
      "7800 0.477462\n",
      "8000 0.47718877\n",
      "8200 0.47693342\n",
      "8400 0.47669458\n",
      "8600 0.4764708\n",
      "8800 0.47626105\n",
      "9000 0.47606418\n",
      "9200 0.47587922\n",
      "9400 0.47570527\n",
      "9600 0.4755416\n",
      "9800 0.4753873\n",
      "10000 0.47524184\n",
      "\n",
      "hypothesis:  [[0.38422185]\n",
      " [0.93804973]\n",
      " [0.25522104]\n",
      " [0.941349  ]\n",
      " [0.15950495]\n",
      " [0.80824685]\n",
      " [0.94736093]\n",
      " [0.641117  ]\n",
      " [0.19871734]\n",
      " [0.54605377]\n",
      " [0.7108032 ]\n",
      " [0.16520421]\n",
      " [0.3080518 ]\n",
      " [0.21762761]\n",
      " [0.7937262 ]\n",
      " [0.43213207]\n",
      " [0.78269494]\n",
      " [0.8134789 ]\n",
      " [0.79474515]\n",
      " [0.5593392 ]\n",
      " [0.69936913]\n",
      " [0.08048825]\n",
      " [0.7099837 ]\n",
      " [0.6860447 ]\n",
      " [0.33225015]\n",
      " [0.9446722 ]\n",
      " [0.59384024]\n",
      " [0.6615734 ]\n",
      " [0.67561775]\n",
      " [0.41739872]\n",
      " [0.9586851 ]\n",
      " [0.92142427]\n",
      " [0.63873935]\n",
      " [0.8595316 ]\n",
      " [0.40884662]\n",
      " [0.6874065 ]\n",
      " [0.8275908 ]\n",
      " [0.53133386]\n",
      " [0.37248388]\n",
      " [0.3569021 ]\n",
      " [0.8627598 ]\n",
      " [0.10498605]\n",
      " [0.42788604]\n",
      " [0.05124471]\n",
      " [0.5802079 ]\n",
      " [0.948028  ]\n",
      " [0.710867  ]\n",
      " [0.7581944 ]\n",
      " [0.9488701 ]\n",
      " [0.9378316 ]\n",
      " [0.94490534]\n",
      " [0.19689113]\n",
      " [0.3401782 ]\n",
      " [0.96918935]\n",
      " [0.16077562]\n",
      " [0.48226744]\n",
      " [0.1276086 ]\n",
      " [0.7110556 ]\n",
      " [0.8795207 ]\n",
      " [0.5285675 ]\n",
      " [0.9702406 ]\n",
      " [0.72215223]\n",
      " [0.6899885 ]\n",
      " [0.87204266]\n",
      " [0.63928443]\n",
      " [0.5340063 ]\n",
      " [0.9646127 ]\n",
      " [0.68180054]\n",
      " [0.85194004]\n",
      " [0.67915046]\n",
      " [0.27307108]\n",
      " [0.6966016 ]\n",
      " [0.92852104]\n",
      " [0.9372384 ]\n",
      " [0.91245556]\n",
      " [0.7978949 ]\n",
      " [0.40324852]\n",
      " [0.8830749 ]\n",
      " [0.91213465]\n",
      " [0.9336446 ]\n",
      " [0.89117336]\n",
      " [0.87454486]\n",
      " [0.29817712]\n",
      " [0.81330496]\n",
      " [0.5890498 ]\n",
      " [0.8525501 ]\n",
      " [0.4179123 ]\n",
      " [0.9066906 ]\n",
      " [0.95896107]\n",
      " [0.75399977]\n",
      " [0.7828551 ]\n",
      " [0.6902652 ]\n",
      " [0.6992756 ]\n",
      " [0.541961  ]\n",
      " [0.9109521 ]\n",
      " [0.98247623]\n",
      " [0.9105938 ]\n",
      " [0.5039525 ]\n",
      " [0.20902596]\n",
      " [0.6674447 ]\n",
      " [0.7002316 ]\n",
      " [0.96414953]\n",
      " [0.7848358 ]\n",
      " [0.74349254]\n",
      " [0.920765  ]\n",
      " [0.66530937]\n",
      " [0.9245953 ]\n",
      " [0.82584196]\n",
      " [0.4354851 ]\n",
      " [0.32375607]\n",
      " [0.93617016]\n",
      " [0.8987411 ]\n",
      " [0.4086025 ]\n",
      " [0.42786804]\n",
      " [0.6421147 ]\n",
      " [0.87239677]\n",
      " [0.8887007 ]\n",
      " [0.9294192 ]\n",
      " [0.1006216 ]\n",
      " [0.74788576]\n",
      " [0.8497272 ]\n",
      " [0.64133155]\n",
      " [0.6857783 ]\n",
      " [0.7303302 ]\n",
      " [0.6368336 ]\n",
      " [0.8287064 ]\n",
      " [0.78402245]\n",
      " [0.6827119 ]\n",
      " [0.4463577 ]\n",
      " [0.4666078 ]\n",
      " [0.37066916]\n",
      " [0.79129136]\n",
      " [0.9462859 ]\n",
      " [0.8017529 ]\n",
      " [0.80395776]\n",
      " [0.8822827 ]\n",
      " [0.5150258 ]\n",
      " [0.79400027]\n",
      " [0.7789929 ]\n",
      " [0.70857626]\n",
      " [0.8759624 ]\n",
      " [0.6873049 ]\n",
      " [0.53762877]\n",
      " [0.71563196]\n",
      " [0.93328786]\n",
      " [0.7633506 ]\n",
      " [0.4204483 ]\n",
      " [0.94094294]\n",
      " [0.6013944 ]\n",
      " [0.83561844]\n",
      " [0.24839808]\n",
      " [0.33350968]\n",
      " [0.07363912]\n",
      " [0.17856951]\n",
      " [0.9154287 ]\n",
      " [0.88787675]\n",
      " [0.94651353]\n",
      " [0.10547338]\n",
      " [0.52013004]\n",
      " [0.7695404 ]\n",
      " [0.57870626]\n",
      " [0.8669881 ]\n",
      " [0.47534385]\n",
      " [0.8141535 ]\n",
      " [0.58862597]\n",
      " [0.68324363]\n",
      " [0.7585017 ]\n",
      " [0.8662857 ]\n",
      " [0.80718184]\n",
      " [0.59298825]\n",
      " [0.904166  ]\n",
      " [0.8654662 ]\n",
      " [0.9550253 ]\n",
      " [0.20645796]\n",
      " [0.85514116]\n",
      " [0.14608416]\n",
      " [0.31712714]\n",
      " [0.38871655]\n",
      " [0.9233231 ]\n",
      " [0.6679977 ]\n",
      " [0.9191416 ]\n",
      " [0.9392668 ]\n",
      " [0.6209235 ]\n",
      " [0.10868023]\n",
      " [0.17469229]\n",
      " [0.6034156 ]\n",
      " [0.78423065]\n",
      " [0.6324673 ]\n",
      " [0.8655325 ]\n",
      " [0.6362796 ]\n",
      " [0.3728379 ]\n",
      " [0.16984951]\n",
      " [0.9254573 ]\n",
      " [0.33206174]\n",
      " [0.8879501 ]\n",
      " [0.9128887 ]\n",
      " [0.73130685]\n",
      " [0.6203692 ]\n",
      " [0.6380056 ]\n",
      " [0.5203008 ]\n",
      " [0.75998515]\n",
      " [0.9556998 ]\n",
      " [0.74399096]\n",
      " [0.85231555]\n",
      " [0.0929418 ]\n",
      " [0.27187788]\n",
      " [0.89343095]\n",
      " [0.17166056]\n",
      " [0.9455796 ]\n",
      " [0.26259086]\n",
      " [0.20649666]\n",
      " [0.41328448]\n",
      " [0.71981806]\n",
      " [0.19152744]\n",
      " [0.7592183 ]\n",
      " [0.7303894 ]\n",
      " [0.84492135]\n",
      " [0.66754365]\n",
      " [0.12856953]\n",
      " [0.3178493 ]\n",
      " [0.76940453]\n",
      " [0.51348513]\n",
      " [0.9326572 ]\n",
      " [0.93432647]\n",
      " [0.7395457 ]\n",
      " [0.3246832 ]\n",
      " [0.03272508]\n",
      " [0.6056115 ]\n",
      " [0.31785908]\n",
      " [0.3711504 ]\n",
      " [0.9594809 ]\n",
      " [0.6491517 ]\n",
      " [0.9569958 ]\n",
      " [0.17762332]\n",
      " [0.10478836]\n",
      " [0.2762689 ]\n",
      " [0.8547429 ]\n",
      " [0.9151769 ]\n",
      " [0.89170235]\n",
      " [0.69537354]\n",
      " [0.6988282 ]\n",
      " [0.52530664]\n",
      " [0.13187584]\n",
      " [0.6060499 ]\n",
      " [0.09291576]\n",
      " [0.5846283 ]\n",
      " [0.8689861 ]\n",
      " [0.7237712 ]\n",
      " [0.7366837 ]\n",
      " [0.9566543 ]\n",
      " [0.8385774 ]\n",
      " [0.8093548 ]\n",
      " [0.7456046 ]\n",
      " [0.79261625]\n",
      " [0.8653378 ]\n",
      " [0.34377152]\n",
      " [0.32576838]\n",
      " [0.545242  ]\n",
      " [0.8412056 ]\n",
      " [0.58663386]\n",
      " [0.7036927 ]\n",
      " [0.8071396 ]\n",
      " [0.34789905]\n",
      " [0.46693677]\n",
      " [0.7006204 ]\n",
      " [0.6473761 ]\n",
      " [0.41199407]\n",
      " [0.90732855]\n",
      " [0.80883944]\n",
      " [0.933667  ]\n",
      " [0.6114348 ]\n",
      " [0.76663357]\n",
      " [0.8490645 ]\n",
      " [0.85271454]\n",
      " [0.7281644 ]\n",
      " [0.87620026]\n",
      " [0.35108322]\n",
      " [0.5685072 ]\n",
      " [0.65870297]\n",
      " [0.36290222]\n",
      " [0.83402187]\n",
      " [0.2649136 ]\n",
      " [0.5382022 ]\n",
      " [0.95057523]\n",
      " [0.78199023]\n",
      " [0.8545289 ]\n",
      " [0.70332676]\n",
      " [0.42666277]\n",
      " [0.6075341 ]\n",
      " [0.44503844]\n",
      " [0.42607418]\n",
      " [0.6484249 ]\n",
      " [0.6566169 ]\n",
      " [0.666361  ]\n",
      " [0.6994882 ]\n",
      " [0.22031435]\n",
      " [0.6579712 ]\n",
      " [0.91310996]\n",
      " [0.4215035 ]\n",
      " [0.67696595]\n",
      " [0.72321457]\n",
      " [0.47146532]\n",
      " [0.7223869 ]\n",
      " [0.5335322 ]\n",
      " [0.69369996]\n",
      " [0.9232375 ]\n",
      " [0.6710491 ]\n",
      " [0.67010134]\n",
      " [0.85707843]\n",
      " [0.5640732 ]\n",
      " [0.8409175 ]\n",
      " [0.9530223 ]\n",
      " [0.2866188 ]\n",
      " [0.7659036 ]\n",
      " [0.24322629]\n",
      " [0.77099705]\n",
      " [0.8201142 ]\n",
      " [0.7260145 ]\n",
      " [0.39127073]\n",
      " [0.76264983]\n",
      " [0.71864414]\n",
      " [0.7226383 ]\n",
      " [0.1733912 ]\n",
      " [0.7747158 ]\n",
      " [0.85817   ]\n",
      " [0.6369378 ]\n",
      " [0.94051856]\n",
      " [0.17983796]\n",
      " [0.7865843 ]\n",
      " [0.95555097]\n",
      " [0.16429408]\n",
      " [0.516528  ]\n",
      " [0.714152  ]\n",
      " [0.32225776]\n",
      " [0.1452991 ]\n",
      " [0.84034276]\n",
      " [0.92323995]\n",
      " [0.8698663 ]\n",
      " [0.6357434 ]\n",
      " [0.68994987]\n",
      " [0.5379083 ]\n",
      " [0.7517389 ]\n",
      " [0.8594275 ]\n",
      " [0.9459825 ]\n",
      " [0.7221392 ]\n",
      " [0.7660854 ]\n",
      " [0.60544544]\n",
      " [0.94127214]\n",
      " [0.9444824 ]\n",
      " [0.7155362 ]\n",
      " [0.27904633]\n",
      " [0.68402684]\n",
      " [0.34783542]\n",
      " [0.7863314 ]\n",
      " [0.15061317]\n",
      " [0.22058807]\n",
      " [0.40624526]\n",
      " [0.6636506 ]\n",
      " [0.32231814]\n",
      " [0.52392185]\n",
      " [0.84695137]\n",
      " [0.7072893 ]\n",
      " [0.88563544]\n",
      " [0.95456344]\n",
      " [0.71241325]\n",
      " [0.08469427]\n",
      " [0.47309467]\n",
      " [0.8419405 ]\n",
      " [0.85755247]\n",
      " [0.6660046 ]\n",
      " [0.26663145]\n",
      " [0.9056014 ]\n",
      " [0.8955608 ]\n",
      " [0.22488128]\n",
      " [0.61165035]\n",
      " [0.84635603]\n",
      " [0.8951797 ]\n",
      " [0.8628026 ]\n",
      " [0.9188361 ]\n",
      " [0.87930614]\n",
      " [0.9236512 ]\n",
      " [0.69402796]\n",
      " [0.58673483]\n",
      " [0.50988364]\n",
      " [0.8430467 ]\n",
      " [0.87307405]\n",
      " [0.1822012 ]\n",
      " [0.8029368 ]\n",
      " [0.8855183 ]\n",
      " [0.32805037]\n",
      " [0.6435126 ]\n",
      " [0.8905415 ]\n",
      " [0.5768063 ]\n",
      " [0.94598126]\n",
      " [0.21622485]\n",
      " [0.860551  ]\n",
      " [0.59926283]\n",
      " [0.90284467]\n",
      " [0.33722425]\n",
      " [0.6440041 ]\n",
      " [0.75185114]\n",
      " [0.86618066]\n",
      " [0.10775438]\n",
      " [0.17668758]\n",
      " [0.7095493 ]\n",
      " [0.8093031 ]\n",
      " [0.3818836 ]\n",
      " [0.756307  ]\n",
      " [0.47013828]\n",
      " [0.31288055]\n",
      " [0.8701204 ]\n",
      " [0.40754923]\n",
      " [0.9521097 ]\n",
      " [0.82280695]\n",
      " [0.6028404 ]\n",
      " [0.9206424 ]\n",
      " [0.65459716]\n",
      " [0.78586954]\n",
      " [0.27611646]\n",
      " [0.22446507]\n",
      " [0.8036735 ]\n",
      " [0.3416652 ]\n",
      " [0.4451866 ]\n",
      " [0.88440573]\n",
      " [0.92820644]\n",
      " [0.91266364]\n",
      " [0.95195496]\n",
      " [0.7222015 ]\n",
      " [0.9062313 ]\n",
      " [0.34659323]\n",
      " [0.35685447]\n",
      " [0.50825906]\n",
      " [0.9511481 ]\n",
      " [0.63014877]\n",
      " [0.14012529]\n",
      " [0.9332211 ]\n",
      " [0.8090391 ]\n",
      " [0.6530074 ]\n",
      " [0.80462426]\n",
      " [0.01341881]\n",
      " [0.9247354 ]\n",
      " [0.79599524]\n",
      " [0.7838653 ]\n",
      " [0.77280396]\n",
      " [0.9717239 ]\n",
      " [0.668278  ]\n",
      " [0.78393805]\n",
      " [0.7777255 ]\n",
      " [0.84322566]\n",
      " [0.18610446]\n",
      " [0.63554114]\n",
      " [0.92196494]\n",
      " [0.6043844 ]\n",
      " [0.78942895]\n",
      " [0.96474385]\n",
      " [0.8685894 ]\n",
      " [0.90469015]\n",
      " [0.6334733 ]\n",
      " [0.8049101 ]\n",
      " [0.9540724 ]\n",
      " [0.76951426]\n",
      " [0.6915491 ]\n",
      " [0.24805944]\n",
      " [0.40878394]\n",
      " [0.55267644]\n",
      " [0.6132189 ]\n",
      " [0.5495999 ]\n",
      " [0.8154943 ]\n",
      " [0.58291733]\n",
      " [0.7920624 ]\n",
      " [0.8527064 ]\n",
      " [0.76776457]\n",
      " [0.6417868 ]\n",
      " [0.4310327 ]\n",
      " [0.60362285]\n",
      " [0.9441696 ]\n",
      " [0.85411966]\n",
      " [0.23458761]\n",
      " [0.41414794]\n",
      " [0.4311805 ]\n",
      " [0.07157496]\n",
      " [0.90498203]\n",
      " [0.14213042]\n",
      " [0.8996517 ]\n",
      " [0.8779118 ]\n",
      " [0.84769773]\n",
      " [0.6763691 ]\n",
      " [0.91142815]\n",
      " [0.35392436]\n",
      " [0.8259197 ]\n",
      " [0.9428936 ]\n",
      " [0.27239984]\n",
      " [0.43241906]\n",
      " [0.867626  ]\n",
      " [0.8777534 ]\n",
      " [0.66416824]\n",
      " [0.82141507]\n",
      " [0.810333  ]\n",
      " [0.8541073 ]\n",
      " [0.22005317]\n",
      " [0.73897684]\n",
      " [0.90192056]\n",
      " [0.67763174]\n",
      " [0.83947897]\n",
      " [0.724532  ]\n",
      " [0.8645263 ]\n",
      " [0.90076834]\n",
      " [0.93906987]\n",
      " [0.5421695 ]\n",
      " [0.41333348]\n",
      " [0.83826035]\n",
      " [0.7716155 ]\n",
      " [0.9751887 ]\n",
      " [0.7562398 ]\n",
      " [0.7304052 ]\n",
      " [0.43890148]\n",
      " [0.73847556]\n",
      " [0.9376818 ]\n",
      " [0.957016  ]\n",
      " [0.8953163 ]\n",
      " [0.7337065 ]\n",
      " [0.7513721 ]\n",
      " [0.804297  ]\n",
      " [0.48034364]\n",
      " [0.8125958 ]\n",
      " [0.8472958 ]\n",
      " [0.9059164 ]\n",
      " [0.63533723]\n",
      " [0.7555408 ]\n",
      " [0.9379857 ]\n",
      " [0.5064115 ]\n",
      " [0.52438504]\n",
      " [0.6621515 ]\n",
      " [0.7147846 ]\n",
      " [0.6906898 ]\n",
      " [0.89479345]\n",
      " [0.92480516]\n",
      " [0.17497925]\n",
      " [0.08623422]\n",
      " [0.7364962 ]\n",
      " [0.4525811 ]\n",
      " [0.21029505]\n",
      " [0.83816284]\n",
      " [0.91416186]\n",
      " [0.72560704]\n",
      " [0.9399103 ]\n",
      " [0.91006255]\n",
      " [0.7886485 ]\n",
      " [0.8337046 ]\n",
      " [0.7404348 ]\n",
      " [0.5416446 ]\n",
      " [0.8315755 ]\n",
      " [0.6096192 ]\n",
      " [0.08790318]\n",
      " [0.8988127 ]\n",
      " [0.89563274]\n",
      " [0.7813247 ]\n",
      " [0.9270937 ]\n",
      " [0.8334812 ]\n",
      " [0.88882077]\n",
      " [0.5461859 ]\n",
      " [0.69307345]\n",
      " [0.9049437 ]\n",
      " [0.75999826]\n",
      " [0.8651822 ]\n",
      " [0.9020378 ]\n",
      " [0.5852556 ]\n",
      " [0.7950359 ]\n",
      " [0.8567115 ]\n",
      " [0.49913555]\n",
      " [0.5966231 ]\n",
      " [0.08832906]\n",
      " [0.22263771]\n",
      " [0.86448693]\n",
      " [0.66613305]\n",
      " [0.69363374]\n",
      " [0.58434844]\n",
      " [0.94807327]\n",
      " [0.4429056 ]\n",
      " [0.86482066]\n",
      " [0.21775702]\n",
      " [0.9429342 ]\n",
      " [0.3226961 ]\n",
      " [0.76212883]\n",
      " [0.5665334 ]\n",
      " [0.885852  ]\n",
      " [0.6046444 ]\n",
      " [0.20487125]\n",
      " [0.7987908 ]\n",
      " [0.93818545]\n",
      " [0.31773725]\n",
      " [0.9281965 ]\n",
      " [0.87944925]\n",
      " [0.8981833 ]\n",
      " [0.81903875]\n",
      " [0.37017852]\n",
      " [0.30914792]\n",
      " [0.6549658 ]\n",
      " [0.14472069]\n",
      " [0.9616335 ]\n",
      " [0.3054025 ]\n",
      " [0.9290583 ]\n",
      " [0.88216734]\n",
      " [0.3529885 ]\n",
      " [0.1775105 ]\n",
      " [0.72806   ]\n",
      " [0.4114617 ]\n",
      " [0.87109274]\n",
      " [0.75180334]\n",
      " [0.98451173]\n",
      " [0.5981126 ]\n",
      " [0.68479383]\n",
      " [0.76416737]\n",
      " [0.84625375]\n",
      " [0.06004056]\n",
      " [0.713748  ]\n",
      " [0.81665826]\n",
      " [0.8481397 ]\n",
      " [0.69506663]\n",
      " [0.48937586]\n",
      " [0.60055757]\n",
      " [0.91629946]\n",
      " [0.7057681 ]\n",
      " [0.80038637]\n",
      " [0.85391957]\n",
      " [0.85176075]\n",
      " [0.8659865 ]\n",
      " [0.6569425 ]\n",
      " [0.82140064]\n",
      " [0.901462  ]\n",
      " [0.69510275]\n",
      " [0.962326  ]\n",
      " [0.8211921 ]\n",
      " [0.63674396]\n",
      " [0.4994322 ]\n",
      " [0.8732031 ]\n",
      " [0.8676745 ]\n",
      " [0.4078174 ]\n",
      " [0.6264658 ]\n",
      " [0.20701535]\n",
      " [0.59255344]\n",
      " [0.85056037]\n",
      " [0.95500344]\n",
      " [0.816417  ]\n",
      " [0.7260328 ]\n",
      " [0.7947236 ]\n",
      " [0.87944376]\n",
      " [0.43598855]\n",
      " [0.945949  ]\n",
      " [0.545143  ]\n",
      " [0.8616648 ]\n",
      " [0.33263153]\n",
      " [0.06156812]\n",
      " [0.24239922]\n",
      " [0.3332165 ]\n",
      " [0.71165997]\n",
      " [0.8232265 ]\n",
      " [0.51876175]\n",
      " [0.78045505]\n",
      " [0.81749773]\n",
      " [0.47681743]\n",
      " [0.32356396]\n",
      " [0.903848  ]\n",
      " [0.8991571 ]\n",
      " [0.29218283]\n",
      " [0.69622797]\n",
      " [0.1737872 ]\n",
      " [0.43015528]\n",
      " [0.79052883]\n",
      " [0.71343887]\n",
      " [0.91632336]\n",
      " [0.9838126 ]\n",
      " [0.14391002]\n",
      " [0.7171827 ]\n",
      " [0.63972527]\n",
      " [0.42732027]\n",
      " [0.7046673 ]\n",
      " [0.7863089 ]\n",
      " [0.89691114]\n",
      " [0.7385973 ]\n",
      " [0.38365737]\n",
      " [0.7450196 ]\n",
      " [0.144575  ]\n",
      " [0.6470303 ]\n",
      " [0.5127619 ]\n",
      " [0.9366756 ]\n",
      " [0.55834603]\n",
      " [0.508128  ]\n",
      " [0.86000496]\n",
      " [0.6885352 ]\n",
      " [0.45083678]\n",
      " [0.7269001 ]\n",
      " [0.66860545]\n",
      " [0.26227275]\n",
      " [0.57834184]\n",
      " [0.88719904]\n",
      " [0.84875405]\n",
      " [0.64483476]\n",
      " [0.76537526]\n",
      " [0.287335  ]\n",
      " [0.8426719 ]\n",
      " [0.5515026 ]\n",
      " [0.74911463]\n",
      " [0.39859867]\n",
      " [0.6638777 ]\n",
      " [0.86088926]\n",
      " [0.15063189]\n",
      " [0.26207304]\n",
      " [0.8488528 ]\n",
      " [0.8170561 ]\n",
      " [0.7859017 ]\n",
      " [0.91805756]\n",
      " [0.74777013]\n",
      " [0.6586256 ]\n",
      " [0.6872265 ]\n",
      " [0.7738963 ]\n",
      " [0.6783924 ]\n",
      " [0.7723082 ]\n",
      " [0.5017731 ]\n",
      " [0.47195014]\n",
      " [0.9079953 ]\n",
      " [0.7855637 ]\n",
      " [0.71057427]\n",
      " [0.20365955]\n",
      " [0.88804394]\n",
      " [0.8510151 ]\n",
      " [0.8435177 ]\n",
      " [0.6804076 ]\n",
      " [0.9073357 ]\n",
      " [0.84057724]\n",
      " [0.75896037]\n",
      " [0.39442474]\n",
      " [0.89475834]\n",
      " [0.9107791 ]\n",
      " [0.35670388]\n",
      " [0.15000106]\n",
      " [0.76572305]\n",
      " [0.30315942]\n",
      " [0.77426374]\n",
      " [0.24064493]\n",
      " [0.4751553 ]\n",
      " [0.47749883]\n",
      " [0.73561645]\n",
      " [0.88688886]\n",
      " [0.11437855]\n",
      " [0.36277875]\n",
      " [0.57284546]\n",
      " [0.5124241 ]\n",
      " [0.5246244 ]\n",
      " [0.7888178 ]\n",
      " [0.12369796]\n",
      " [0.92808175]\n",
      " [0.13959844]\n",
      " [0.9048971 ]\n",
      " [0.74425125]\n",
      " [0.70360035]\n",
      " [0.8389992 ]\n",
      " [0.7204199 ]\n",
      " [0.9069298 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.77602106\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) #tf.Variable들 초기화\n",
    "    feed = {X:x_data, Y:y_data}\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = feed)\n",
    "        if step%200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = feed))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = feed)\n",
    "    print('\\nhypothesis: ', h, '\\nCorrect (Y): ', c, '\\nAccuracy: ',a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.decode_csv로 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 이름 쌓기\n",
    "filename_queue = tf.train.string_input_producer(['data-03-diabetes.csv'], shuffle = False, name = 'filename_queue')\n",
    "\n",
    "#define reader\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)  #value에는 파일에서 읽은 값이 들어감\n",
    "\n",
    "record_defaults = [[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.],[0.]]  #값이 없을 경우 & 필드의 데이터 타입 정의\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X,W) +b)\n",
    "\n",
    "cost = tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord = coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.294118    0.487437    0.180328   -0.292929    0.          0.00149028\n",
      "  -0.53117    -0.0333333 ]\n",
      " [-0.882353   -0.145729    0.0819672  -0.414141    0.         -0.207153\n",
      "  -0.766866   -0.666667  ]\n",
      " [-0.0588235   0.839196    0.0491803   0.          0.         -0.305514\n",
      "  -0.492741   -0.633333  ]\n",
      " [-0.882353   -0.105528    0.0819672  -0.535354   -0.777778   -0.162444\n",
      "  -0.923997    0.        ]\n",
      " [ 0.          0.376884   -0.344262   -0.292929   -0.602837    0.28465\n",
      "   0.887276   -0.6       ]\n",
      " [-0.411765    0.165829    0.213115    0.          0.         -0.23696\n",
      "  -0.894962   -0.7       ]\n",
      " [-0.647059   -0.21608    -0.180328   -0.353535   -0.791962   -0.0760059\n",
      "  -0.854825   -0.833333  ]\n",
      " [ 0.176471    0.155779    0.          0.          0.          0.052161\n",
      "  -0.952178   -0.733333  ]\n",
      " [-0.764706    0.979899    0.147541   -0.0909091   0.283688   -0.0909091\n",
      "  -0.931682    0.0666667 ]\n",
      " [-0.0588235   0.256281    0.57377     0.          0.          0.\n",
      "  -0.868488    0.1       ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  0  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.41464028 0.23689221 0.5843424  0.434595   0.03257411 0.41947067\n",
      " 0.32304627 0.5628382  0.7500123  0.43022504]\n",
      "Batch:  [[-0.529412   0.155779   0.180328   0.         0.        -0.138599\n",
      "  -0.745517  -0.166667 ]\n",
      " [ 0.         0.0150754  0.0163934  0.         0.        -0.347243\n",
      "  -0.779675  -0.866667 ]\n",
      " [-0.0588235  0.979899   0.213115   0.         0.        -0.228018\n",
      "  -0.0495303 -0.4      ]\n",
      " [-0.882353   0.728643   0.114754  -0.010101   0.368794   0.263785\n",
      "  -0.467122  -0.766667 ]\n",
      " [-0.294118   0.0251256  0.47541   -0.212121   0.         0.0640835\n",
      "  -0.491033  -0.766667 ]\n",
      " [-0.882353   0.125628   0.180328  -0.393939  -0.583924   0.0253354\n",
      "  -0.615713  -0.866667 ]\n",
      " [-0.882353   0.437186   0.377049  -0.535354  -0.267139   0.263785\n",
      "  -0.147737  -0.966667 ]\n",
      " [-0.882353   0.437186   0.213115  -0.555556  -0.855792  -0.219076\n",
      "  -0.847993   0.       ]\n",
      " [ 0.         0.386935  -0.0163934 -0.292929  -0.605201   0.0312965\n",
      "  -0.610589   0.       ]\n",
      " [-0.647059   0.738693   0.377049  -0.333333   0.120567   0.0640835\n",
      "  -0.846285  -0.966667 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  40  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.3572887  0.42267165 0.29084352 0.13367596 0.06589749 0.08625746\n",
      " 0.0210089  0.41291916 0.5149164  0.20161712]\n",
      "Batch:  [[ 0.0588235  0.718593   0.803279  -0.515152  -0.432624   0.353204\n",
      "  -0.450897   0.1      ]\n",
      " [-0.176471   0.59799    0.0491803  0.         0.        -0.183308\n",
      "  -0.815542  -0.366667 ]\n",
      " [ 0.         0.809045   0.0819672 -0.212121   0.         0.251863\n",
      "   0.549957  -0.866667 ]\n",
      " [-0.882353   0.467337  -0.0819672  0.         0.        -0.114754\n",
      "  -0.58497   -0.733333 ]\n",
      " [-0.764706  -0.286432   0.147541  -0.454545   0.        -0.165425\n",
      "  -0.566183  -0.966667 ]\n",
      " [-0.176471   0.0351759  0.0819672 -0.353535   0.         0.165425\n",
      "  -0.772844  -0.666667 ]\n",
      " [-0.176471   0.0552764  0.         0.         0.         0.\n",
      "  -0.806149  -0.9      ]\n",
      " [-0.882353   0.0351759  0.311475  -0.777778  -0.806147  -0.421759\n",
      "  -0.64731   -0.966667 ]\n",
      " [-0.882353   0.0150754 -0.180328  -0.69697   -0.914894  -0.278688\n",
      "  -0.617421  -0.833333 ]\n",
      " [-0.411765  -0.115578   0.0819672 -0.575758  -0.945626  -0.272727\n",
      "  -0.774552  -0.7      ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  80  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.10251308 0.54952323 0.02881924 0.19949873 0.04812458 0.17425282\n",
      " 0.22362655 0.05831306 0.12965079 0.16309528]\n",
      "Batch:  [[ 0.         -0.0452261   0.311475   -0.0909091  -0.782506    0.0879285\n",
      "  -0.784799   -0.833333  ]\n",
      " [ 0.          0.0452261   0.0491803  -0.252525   -0.8487      0.00149028\n",
      "  -0.631085   -0.966667  ]\n",
      " [ 0.          0.20603     0.213115   -0.636364   -0.851064   -0.0909091\n",
      "  -0.823228   -0.833333  ]\n",
      " [-0.882353   -0.175879    0.0491803  -0.737374   -0.775414   -0.368107\n",
      "  -0.712212   -0.933333  ]\n",
      " [-0.764706    0.346734    0.147541    0.          0.         -0.138599\n",
      "  -0.603757   -0.933333  ]\n",
      " [ 0.         -0.0854271   0.114754   -0.353535   -0.503546    0.18927\n",
      "  -0.741247   -0.866667  ]\n",
      " [-0.764706    0.19598     0.          0.          0.         -0.415797\n",
      "  -0.356106    0.7       ]\n",
      " [-0.764706    0.00502513 -0.114754   -0.434343   -0.751773    0.126677\n",
      "  -0.641332   -0.9       ]\n",
      " [ 0.647059    0.758794    0.0163934  -0.393939    0.          0.00149028\n",
      "  -0.885568   -0.433333  ]\n",
      " [-0.882353    0.356784   -0.114754    0.          0.         -0.204173\n",
      "  -0.479932    0.366667  ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  120  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.07151014 0.08875644 0.12662876 0.04892787 0.0754619  0.0778488\n",
      " 0.41309428 0.04863155 0.66151273 0.36760837]\n",
      "Batch:  [[-0.411765    0.376884    0.770492    0.          0.          0.454545\n",
      "  -0.872758   -0.466667  ]\n",
      " [-0.764706    0.105528    0.213115   -0.414141   -0.704492   -0.0342771\n",
      "  -0.470538   -0.8       ]\n",
      " [ 0.529412    0.0653266   0.180328    0.0909091   0.          0.0909091\n",
      "  -0.914603   -0.2       ]\n",
      " [-0.764706    0.00502513  0.114754   -0.494949   -0.832151    0.147541\n",
      "  -0.789923   -0.833333  ]\n",
      " [ 0.764706    0.366834    0.147541   -0.353535   -0.739953    0.105812\n",
      "  -0.935952   -0.266667  ]\n",
      " [-0.882353    0.0753769   0.114754   -0.616162    0.         -0.210134\n",
      "  -0.925705   -0.9       ]\n",
      " [-0.882353   -0.19598    -0.0983607   0.          0.         -0.4307\n",
      "  -0.846285    0.        ]\n",
      " [-0.529412    0.236181    0.311475   -0.69697    -0.583924   -0.0461997\n",
      "  -0.688301   -0.566667  ]\n",
      " [-0.176471   -0.18593     0.278689   -0.191919   -0.886525    0.391952\n",
      "  -0.843723   -0.3       ]\n",
      " [-0.529412    0.346734    0.180328    0.          0.         -0.290611\n",
      "  -0.83006     0.3       ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  160  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.02732489 0.01679615 0.36695352 0.02216504 0.4080745  0.05048262\n",
      " 0.24836713 0.04037161 0.04602659 0.3916043 ]\n",
      "Batch:  [[-0.0588235   0.949749    0.311475    0.          0.         -0.222057\n",
      "  -0.596072    0.533333  ]\n",
      " [-0.764706   -0.165829    0.0655738  -0.434343   -0.843972    0.0968703\n",
      "  -0.529462   -0.9       ]\n",
      " [-0.764706   -0.105528    0.47541    -0.393939    0.         -0.00149028\n",
      "  -0.81725    -0.3       ]\n",
      " [-0.529412   -0.00502513  0.114754   -0.232323    0.         -0.0223547\n",
      "  -0.942784   -0.6       ]\n",
      " [-0.529412    0.256281    0.147541   -0.636364   -0.711584   -0.138599\n",
      "  -0.089667   -0.2       ]\n",
      " [-0.647059   -0.19598     0.          0.          0.          0.\n",
      "  -0.918019   -0.966667  ]\n",
      " [-0.294118    0.668342    0.213115    0.          0.         -0.207153\n",
      "  -0.807003    0.5       ]\n",
      " [-0.411765    0.105528    0.114754    0.          0.         -0.225037\n",
      "  -0.81725    -0.7       ]\n",
      " [-0.764706   -0.18593     0.180328   -0.69697    -0.820331   -0.102832\n",
      "  -0.599488   -0.866667  ]\n",
      " [-0.176471    0.959799    0.147541   -0.333333   -0.65721    -0.251863\n",
      "  -0.927412    0.133333  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  200  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.52252275 0.00696867 0.02148634 0.05881191 0.02448441 0.03133501\n",
      " 0.48621684 0.07834307 0.00739357 0.44953784]\n",
      "Batch:  [[-0.882353   -0.115578   -0.508197   -0.151515   -0.765957    0.639344\n",
      "  -0.64304    -0.833333  ]\n",
      " [-0.647059    0.20603     0.147541   -0.393939   -0.680851    0.278689\n",
      "  -0.680615   -0.7       ]\n",
      " [-0.882353    0.18593    -0.0491803  -0.272727   -0.777778   -0.00745157\n",
      "  -0.843723   -0.933333  ]\n",
      " [-0.882353    0.175879    0.442623   -0.515152   -0.65721     0.028316\n",
      "  -0.722459   -0.366667  ]\n",
      " [ 0.          0.0552764   0.377049    0.          0.         -0.168405\n",
      "  -0.433817    0.366667  ]\n",
      " [-0.529412    0.738693    0.147541   -0.717172   -0.602837   -0.114754\n",
      "  -0.758326   -0.6       ]\n",
      " [ 0.0588235   0.226131   -0.0819672   0.          0.         -0.00745157\n",
      "  -0.115286   -0.6       ]\n",
      " [-0.647059    0.708543    0.0491803  -0.252525   -0.468085    0.028316\n",
      "  -0.762596   -0.7       ]\n",
      " [-0.0588235  -0.155779    0.213115   -0.373737    0.          0.14158\n",
      "  -0.676345   -0.4       ]\n",
      " [-0.764706   -0.0351759   0.114754   -0.737374   -0.884161   -0.371088\n",
      "  -0.514091   -0.833333  ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  240  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.00869383 0.00828088 0.01128192 0.00746537 0.1336169  0.03450285\n",
      " 0.0512698  0.03391621 0.03215688 0.00640632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[ 0.          0.0753769   0.245902    0.          0.          0.350224\n",
      "  -0.480786   -0.9       ]\n",
      " [-0.882353   -0.135678    0.0819672   0.0505051  -0.846336    0.230999\n",
      "  -0.283518   -0.733333  ]\n",
      " [-0.294118   -0.0854271   0.          0.          0.         -0.111773\n",
      "  -0.63877    -0.666667  ]\n",
      " [-0.882353   -0.226131   -0.0819672  -0.393939   -0.867612   -0.00745157\n",
      "   0.00170794 -0.9       ]\n",
      " [-0.529412    0.326633    0.          0.          0.         -0.019374\n",
      "  -0.808711   -0.933333  ]\n",
      " [ 0.          0.0552764   0.47541     0.          0.         -0.117735\n",
      "  -0.898377   -0.166667  ]\n",
      " [ 0.         -0.427136   -0.0163934   0.          0.         -0.353204\n",
      "  -0.438941    0.533333  ]\n",
      " [ 0.          0.276382    0.311475   -0.252525   -0.503546    0.0819672\n",
      "  -0.380017   -0.933333  ]\n",
      " [-0.647059    0.296482    0.508197   -0.010101   -0.63357     0.0849479\n",
      "  -0.239966   -0.633333  ]\n",
      " [-0.0588235   0.00502513  0.213115   -0.191919   -0.491726    0.174367\n",
      "  -0.502135   -0.266667  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  280  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.00819268 0.00174182 0.02582778 0.0011833  0.0191505  0.05662224\n",
      " 0.22346148 0.00640353 0.00238209 0.01965548]\n",
      "Batch:  [[-0.647059   0.487437   0.0819672 -0.494949   0.        -0.0312965\n",
      "  -0.847993  -0.966667 ]\n",
      " [-0.529412   0.20603    0.114754   0.         0.        -0.117735\n",
      "  -0.461144  -0.566667 ]\n",
      " [-0.529412   0.105528   0.0819672  0.         0.        -0.0491803\n",
      "  -0.664389  -0.733333 ]\n",
      " [-0.647059   0.115578   0.47541   -0.757576  -0.815603  -0.153502\n",
      "  -0.643894  -0.733333 ]\n",
      " [-0.294118   0.0251256  0.344262   0.         0.        -0.0819672\n",
      "  -0.912895  -0.5      ]\n",
      " [-0.294118   0.346734   0.147541  -0.535354  -0.692671   0.0551417\n",
      "  -0.603757  -0.733333 ]\n",
      " [-0.764706  -0.125628   0.        -0.535354   0.        -0.138599\n",
      "  -0.40649   -0.866667 ]\n",
      " [-0.882353  -0.20603   -0.0163934 -0.151515  -0.886525   0.296572\n",
      "  -0.487617  -0.933333 ]\n",
      " [-0.764706  -0.246231   0.0491803 -0.515152  -0.869976  -0.114754\n",
      "  -0.75064   -0.6      ]\n",
      " [-0.0588235  0.798995   0.180328  -0.151515  -0.692671  -0.0253353\n",
      "  -0.452605  -0.5      ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  320  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.0059635  0.01131522 0.00904595 0.00110291 0.01485518 0.00500246\n",
      " 0.0025389  0.00072739 0.00256299 0.02162288]\n",
      "Batch:  [[-0.647059   0.115578  -0.0491803 -0.373737  -0.895981  -0.120715\n",
      "  -0.699402  -0.966667 ]\n",
      " [-0.764706  -0.0150754 -0.0163934 -0.656566  -0.716312   0.0342773\n",
      "  -0.897523  -0.966667 ]\n",
      " [-0.882353   0.437186   0.409836  -0.393939  -0.219858  -0.102832\n",
      "  -0.304868  -0.933333 ]\n",
      " [-0.882353   0.19598   -0.278689  -0.0505051 -0.851064   0.0581222\n",
      "  -0.827498  -0.866667 ]\n",
      " [-0.294118   0.0854271 -0.278689  -0.59596   -0.692671  -0.28465\n",
      "  -0.372331  -0.533333 ]\n",
      " [-0.764706   0.18593    0.311475   0.         0.         0.278689\n",
      "  -0.474808   0.       ]\n",
      " [ 0.176471   0.336683   0.114754   0.         0.        -0.195231\n",
      "  -0.857387  -0.5      ]\n",
      " [-0.764706   0.979899   0.147541   1.         0.         0.0342773\n",
      "  -0.575576   0.366667 ]\n",
      " [ 0.         0.517588   0.47541   -0.0707071  0.         0.254843\n",
      "  -0.749787   0.       ]\n",
      " [-0.294118   0.0954774 -0.0163934 -0.454545   0.        -0.254843\n",
      "  -0.890692  -0.8      ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  360  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.0014137  0.00084843 0.00056467 0.00254051 0.00985064 0.00572234\n",
      " 0.05075683 0.12367254 0.02728887 0.0097898 ]\n",
      "Batch:  [[-0.411765   0.628141   0.704918   0.         0.         0.123696\n",
      "  -0.93766    0.0333333]\n",
      " [-0.882353  -0.0351759  0.0491803 -0.454545  -0.794326  -0.0104321\n",
      "  -0.819812   0.       ]\n",
      " [-0.176471   0.849246   0.377049  -0.333333   0.         0.0581222\n",
      "  -0.76345   -0.333333 ]\n",
      " [-0.764706  -0.18593   -0.0163934 -0.555556   0.        -0.174367\n",
      "  -0.818958  -0.866667 ]\n",
      " [ 0.         0.477387   0.393443   0.0909091  0.         0.275708\n",
      "  -0.746371  -0.9      ]\n",
      " [-0.176471   0.798995   0.557377  -0.373737   0.         0.0193741\n",
      "  -0.926558   0.3      ]\n",
      " [ 0.         0.407035   0.0655738 -0.474747  -0.692671   0.269747\n",
      "  -0.698548  -0.9      ]\n",
      " [ 0.0588235  0.125628   0.344262  -0.353535  -0.586288   0.0193741\n",
      "  -0.844577  -0.5      ]\n",
      " [ 0.411765   0.517588   0.147541  -0.191919  -0.359338   0.245902\n",
      "  -0.432963  -0.433333 ]\n",
      " [-0.411765   0.0954774  0.0163934 -0.171717  -0.695035   0.0670641\n",
      "  -0.627669  -0.866667 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  400  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.00851188 0.00262082 0.01116221 0.00109076 0.00311691 0.03288718\n",
      " 0.00193993 0.00397127 0.01654618 0.00123357]\n",
      "Batch:  [[-0.294118   0.0552764  0.311475  -0.434343   0.        -0.0312965\n",
      "  -0.316823  -0.833333 ]\n",
      " [ 0.294118   0.386935   0.213115  -0.474747  -0.659574   0.0760059\n",
      "  -0.590948  -0.0333333]\n",
      " [-0.647059   0.0653266  0.180328   0.         0.        -0.230999\n",
      "  -0.889838  -0.8      ]\n",
      " [-0.294118   0.175879   0.57377    0.         0.        -0.14456\n",
      "  -0.932536  -0.7      ]\n",
      " [-0.764706  -0.316583   0.0163934 -0.737374  -0.964539  -0.400894\n",
      "  -0.847139  -0.933333 ]\n",
      " [ 0.0588235  0.125628   0.344262  -0.515152   0.        -0.159463\n",
      "   0.028181  -0.0333333]\n",
      " [ 0.         0.19598    0.         0.         0.        -0.0342771\n",
      "  -0.9462    -0.9      ]\n",
      " [-0.764706   0.125628   0.409836  -0.151515  -0.621749   0.14456\n",
      "  -0.856533  -0.766667 ]\n",
      " [-0.764706  -0.0753769  0.245902  -0.59596    0.        -0.278688\n",
      "   0.383433  -0.766667 ]\n",
      " [-0.294118   0.839196   0.540984   0.         0.         0.216095\n",
      "   0.181042  -0.2      ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  440  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [0.00064316 0.01277813 0.00128449 0.00135318 0.00016122 0.00793873\n",
      " 0.00534467 0.00018631 0.00022797 0.00308879]\n",
      "Batch:  [[-0.882353    0.115578    0.409836   -0.616162    0.         -0.102832\n",
      "  -0.944492   -0.933333  ]\n",
      " [ 0.0588235   0.0653266  -0.147541    0.          0.         -0.0700447\n",
      "  -0.742101   -0.3       ]\n",
      " [-0.764706    0.296482    0.377049    0.          0.         -0.165425\n",
      "  -0.824082   -0.8       ]\n",
      " [-0.764706   -0.0954774   0.311475   -0.717172   -0.869976   -0.272727\n",
      "  -0.853971   -0.9       ]\n",
      " [ 0.         -0.135678    0.114754   -0.353535    0.          0.0670641\n",
      "  -0.863365   -0.866667  ]\n",
      " [ 0.411765   -0.0753769   0.0163934  -0.858586   -0.390071   -0.177347\n",
      "  -0.275833   -0.233333  ]\n",
      " [-0.882353    0.135678    0.0491803  -0.292929    0.          0.00149028\n",
      "  -0.602904    0.        ]\n",
      " [-0.647059    0.115578   -0.0819672  -0.212121    0.         -0.102832\n",
      "  -0.590948   -0.7       ]\n",
      " [-0.764706    0.145729    0.114754   -0.555556    0.         -0.14456\n",
      "  -0.988044   -0.866667  ]\n",
      " [-0.882353    0.939698   -0.180328   -0.676768   -0.113475   -0.228018\n",
      "  -0.507259   -0.9       ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  480  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [8.1781793e-05 1.9269204e-02 3.7456167e-04 4.8002792e-05 1.0854076e-03\n",
      " 7.2239460e-03 2.3127000e-03 1.0719479e-03 3.0105689e-04 6.6488184e-04]\n",
      "Batch:  [[-0.882353   0.0653266  0.147541  -0.434343  -0.680851   0.0193741\n",
      "  -0.945346  -0.966667 ]\n",
      " [-0.764706   0.557789  -0.147541  -0.454545   0.276596   0.153502\n",
      "  -0.861657  -0.866667 ]\n",
      " [-0.764706   0.0150754 -0.0491803 -0.292929  -0.787234  -0.350224\n",
      "  -0.934244  -0.966667 ]\n",
      " [-0.882353   0.20603    0.311475  -0.030303  -0.527187   0.159464\n",
      "  -0.0742955 -0.333333 ]\n",
      " [-0.647059  -0.19598    0.344262  -0.373737  -0.834515   0.0193741\n",
      "   0.0367208 -0.8      ]\n",
      " [ 0.176471   0.628141   0.377049   0.         0.        -0.174367\n",
      "  -0.911187   0.1      ]\n",
      " [-0.882353   1.         0.245902  -0.131313   0.         0.278689\n",
      "   0.123826  -0.966667 ]\n",
      " [-0.0588235  0.678392   0.737705  -0.0707071 -0.453901   0.120715\n",
      "  -0.925705  -0.266667 ]\n",
      " [ 0.0588235  0.457286   0.311475  -0.0707071 -0.692671   0.129657\n",
      "  -0.52263   -0.366667 ]\n",
      " [-0.294118   0.155779  -0.0163934 -0.212121   0.         0.004471\n",
      "  -0.857387  -0.366667 ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  520  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.8717928e-05 4.2750142e-04 9.3957016e-05 1.5990477e-04 2.6392150e-05\n",
      " 2.5936140e-02 1.0075934e-04 9.1787567e-04 1.4346294e-03 2.7031435e-03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.764706    0.286432    0.278689   -0.252525   -0.56974     0.290611\n",
      "  -0.0213493  -0.666667  ]\n",
      " [-0.882353    0.286432   -0.213115   -0.0909091  -0.541371    0.207154\n",
      "  -0.543126   -0.9       ]\n",
      " [ 0.          0.61809    -0.180328    0.          0.         -0.347243\n",
      "  -0.849701    0.466667  ]\n",
      " [-0.294118    0.517588    0.0163934  -0.373737   -0.716312    0.0581222\n",
      "  -0.475662   -0.766667  ]\n",
      " [-0.764706    0.467337    0.147541   -0.232323   -0.148936   -0.165425\n",
      "  -0.778822   -0.733333  ]\n",
      " [ 0.          0.266332    0.377049   -0.414141   -0.491726   -0.0849478\n",
      "  -0.622545   -0.9       ]\n",
      " [ 0.647059    0.00502513  0.278689   -0.494949   -0.565012    0.0909091\n",
      "  -0.714774   -0.166667  ]\n",
      " [-0.0588235   0.125628    0.180328    0.          0.         -0.296572\n",
      "  -0.349274    0.233333  ]\n",
      " [ 0.          0.678392    0.          0.          0.         -0.0372578\n",
      "  -0.350128   -0.7       ]\n",
      " [-0.764706    0.447236   -0.0491803  -0.333333   -0.680851   -0.0581222\n",
      "  -0.706234   -0.866667  ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  560  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [3.6787500e-05 7.0264119e-05 1.3861088e-01 1.9796060e-04 1.5977764e-04\n",
      " 1.3600598e-04 3.5100721e-03 1.6774688e-02 2.6312133e-03 6.7746856e-05]\n",
      "Batch:  [[-0.647059    0.698492    0.213115   -0.616162   -0.704492   -0.108793\n",
      "  -0.837746   -0.666667  ]\n",
      " [ 0.         -0.00502513  0.          0.          0.         -0.254843\n",
      "  -0.850555   -0.966667  ]\n",
      " [-0.529412    0.276382    0.442623   -0.777778   -0.63357     0.028316\n",
      "  -0.555935   -0.766667  ]\n",
      " [-0.529412    0.18593     0.147541    0.          0.          0.326379\n",
      "  -0.29462    -0.833333  ]\n",
      " [-0.764706    0.226131    0.245902   -0.454545   -0.527187    0.0700448\n",
      "  -0.654142   -0.833333  ]\n",
      " [-0.294118    0.256281    0.278689   -0.373737    0.         -0.177347\n",
      "  -0.584116   -0.0666667 ]\n",
      " [-0.882353    0.688442    0.442623   -0.414141    0.          0.0432191\n",
      "  -0.293766    0.0333333 ]\n",
      " [-0.764706    0.296482    0.          0.          0.          0.147541\n",
      "  -0.807003   -0.333333  ]\n",
      " [-0.529412    0.105528    0.245902   -0.59596    -0.763593   -0.153502\n",
      "  -0.965841   -0.8       ]\n",
      " [-0.294118   -0.19598     0.311475   -0.272727    0.          0.186289\n",
      "  -0.915457   -0.766667  ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  600  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [3.5405243e-05 4.9859931e-04 1.0762148e-05 8.5426786e-05 1.2770620e-05\n",
      " 1.2473572e-03 2.7693468e-04 3.8738272e-04 1.7109287e-05 6.7858717e-05]\n",
      "Batch:  [[ 0.411765    0.0653266   0.311475    0.          0.         -0.296572\n",
      "  -0.949616   -0.233333  ]\n",
      " [-0.882353   -0.0452261  -0.0163934  -0.636364   -0.862884   -0.28763\n",
      "  -0.844577   -0.966667  ]\n",
      " [ 0.          0.658291    0.245902   -0.131313   -0.397163    0.42772\n",
      "  -0.845431   -0.833333  ]\n",
      " [ 0.          0.175879    0.          0.          0.          0.00745157\n",
      "  -0.270709   -0.233333  ]\n",
      " [-0.411765    0.155779    0.245902    0.          0.         -0.0700447\n",
      "  -0.773698   -0.233333  ]\n",
      " [ 0.0588235   0.527638    0.278689   -0.313131   -0.595745    0.0193741\n",
      "  -0.304014   -0.6       ]\n",
      " [-0.176471    0.788945    0.377049    0.          0.          0.18927\n",
      "  -0.783945   -0.333333  ]\n",
      " [-0.882353    0.306533    0.147541   -0.737374   -0.751773   -0.228018\n",
      "  -0.663535   -0.966667  ]\n",
      " [-0.882353   -0.0452261   0.213115   -0.575758   -0.827423   -0.228018\n",
      "  -0.491887   -0.5       ]\n",
      " [-0.882353    0.          0.114754   -0.292929    0.         -0.0461997\n",
      "  -0.734415   -0.966667  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  640  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [4.1633588e-03 3.3366421e-06 8.6200744e-05 2.9707274e-03 4.8721861e-04\n",
      " 1.8762183e-04 6.0004863e-04 2.9865466e-06 9.4532970e-06 1.1391223e-05]\n",
      "Batch:  [[-0.0588235  -0.346734    0.180328   -0.535354    0.         -0.0461997\n",
      "  -0.554227   -0.3       ]\n",
      " [-0.764706   -0.00502513 -0.0163934  -0.656566   -0.621749    0.0909091\n",
      "  -0.679761    0.        ]\n",
      " [-0.882353    0.0251256   0.213115    0.          0.          0.177347\n",
      "  -0.816396   -0.3       ]\n",
      " [ 0.294118    0.20603     0.311475   -0.252525   -0.64539     0.260805\n",
      "  -0.396243   -0.1       ]\n",
      " [-0.647059    0.0251256  -0.278689   -0.59596    -0.777778   -0.0819672\n",
      "  -0.725021   -0.833333  ]\n",
      " [-0.882353    0.0954774  -0.0491803  -0.636364   -0.725768   -0.150522\n",
      "  -0.87959    -0.966667  ]\n",
      " [ 0.0588235   0.407035    0.540984    0.          0.         -0.0253353\n",
      "  -0.439795   -0.2       ]\n",
      " [ 0.529412    0.537688    0.442623   -0.252525   -0.669031    0.210134\n",
      "  -0.0640478  -0.4       ]\n",
      " [ 0.411765    0.00502513  0.377049   -0.333333   -0.751773   -0.105812\n",
      "  -0.649872   -0.166667  ]\n",
      " [-0.882353    0.477387    0.540984   -0.171717    0.          0.469449\n",
      "  -0.760888   -0.8       ]] [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  680  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.3855011e-04 4.8930986e-05 4.4954093e-05 5.6184357e-04 9.1650909e-06\n",
      " 1.8275334e-06 7.5397087e-04 4.5367022e-04 4.4732736e-04 3.0665572e-06]\n",
      "Batch:  [[-0.764706   0.226131  -0.147541  -0.131313  -0.626478   0.0789866\n",
      "  -0.369769  -0.766667 ]\n",
      " [ 0.411765   0.407035   0.344262  -0.131313  -0.231678   0.168405\n",
      "  -0.615713   0.233333 ]\n",
      " [ 0.        -0.0150754  0.344262  -0.69697   -0.801418  -0.248882\n",
      "  -0.811272  -0.966667 ]\n",
      " [-0.882353  -0.125628  -0.0163934 -0.252525  -0.822695   0.108793\n",
      "  -0.631939  -0.966667 ]\n",
      " [-0.529412   0.567839   0.229508   0.         0.         0.439642\n",
      "  -0.863365  -0.633333 ]\n",
      " [ 0.        -0.0653266  0.639344  -0.212121  -0.829787   0.293592\n",
      "  -0.194705  -0.533333 ]\n",
      " [-0.882353   0.0753769  0.180328  -0.393939  -0.806147  -0.0819672\n",
      "  -0.3655    -0.9      ]\n",
      " [ 0.         0.0552764  0.114754  -0.555556   0.        -0.403875\n",
      "  -0.865073  -0.966667 ]\n",
      " [-0.882353   0.0954774 -0.0163934 -0.838384  -0.56974   -0.242921\n",
      "  -0.257899   0.       ]\n",
      " [-0.882353  -0.0954774  0.0163934 -0.636364  -0.86052   -0.251863\n",
      "   0.0162254 -0.866667 ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  720  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [9.8094824e-06 4.1809715e-03 3.3496181e-06 9.0487146e-07 2.5019956e-05\n",
      " 1.0738824e-05 9.6345832e-07 3.6405490e-05 3.4240235e-05 1.4251783e-06]\n",
      "Batch:  [[-0.529412    0.105528    0.508197    0.          0.          0.120715\n",
      "  -0.903501   -0.7       ]\n",
      " [ 0.176471    0.688442    0.213115    0.          0.          0.132638\n",
      "  -0.608027   -0.566667  ]\n",
      " [ 0.176471    0.396985    0.311475    0.          0.         -0.19225\n",
      "   0.163962    0.2       ]\n",
      " [-0.882353    0.899497   -0.0163934  -0.535354    1.         -0.102832\n",
      "  -0.726729    0.266667  ]\n",
      " [-0.176471    0.00502513  0.          0.          0.         -0.105812\n",
      "  -0.653288   -0.633333  ]\n",
      " [ 0.          0.18593     0.377049   -0.0505051  -0.456265    0.365127\n",
      "  -0.596072   -0.666667  ]\n",
      " [-0.176471    0.0753769   0.213115    0.          0.         -0.117735\n",
      "  -0.849701   -0.666667  ]\n",
      " [-0.882353    0.0351759  -0.508197   -0.232323   -0.803783    0.290611\n",
      "  -0.910333   -0.6       ]\n",
      " [-0.882353    0.155779    0.147541   -0.393939   -0.77305     0.0312965\n",
      "  -0.614859   -0.633333  ]\n",
      " [-0.647059    0.266332    0.442623   -0.171717   -0.444444    0.171386\n",
      "  -0.465414   -0.8       ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  760  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [4.8541392e-06 2.9251404e-04 7.5467806e-03 1.4734385e-03 1.0435155e-04\n",
      " 1.6610502e-05 4.7029102e-05 4.6804312e-06 1.0718612e-06 1.5013399e-06]\n",
      "Batch:  [[-0.882353  -0.0251256  0.114754  -0.575758   0.        -0.18927\n",
      "  -0.131512  -0.966667 ]\n",
      " [-0.529412   0.447236   0.344262  -0.353535   0.         0.147541\n",
      "  -0.59351   -0.466667 ]\n",
      " [-0.882353  -0.165829   0.114754   0.         0.        -0.457526\n",
      "  -0.533732  -0.8      ]\n",
      " [-0.647059   0.296482   0.0491803 -0.414141  -0.728132  -0.213115\n",
      "  -0.87959   -0.766667 ]\n",
      " [-0.882353   0.19598    0.442623  -0.171717  -0.598109   0.350224\n",
      "  -0.633646  -0.833333 ]\n",
      " [-0.764706  -0.0552764  0.114754  -0.636364  -0.820331  -0.225037\n",
      "  -0.587532   0.       ]\n",
      " [ 0.         0.0251256  0.0491803 -0.0707071 -0.815603   0.210134\n",
      "  -0.64304    0.       ]\n",
      " [-0.764706   0.155779   0.0491803 -0.555556   0.        -0.0819672\n",
      "  -0.707088   0.       ]\n",
      " [-0.0588235  0.517588   0.278689  -0.353535  -0.503546   0.278689\n",
      "  -0.625961  -0.5      ]\n",
      " [-0.529412   0.849246   0.278689  -0.212121  -0.345154   0.102832\n",
      "  -0.841161  -0.666667 ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  800  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.0142199e-06 9.3787376e-06 4.0459563e-06 1.0711520e-06 1.7195801e-07\n",
      " 6.3532757e-06 1.4211048e-04 3.6581623e-05 1.4887936e-05 3.8961757e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.0588235   0.768844    0.47541    -0.313131   -0.29078     0.004471\n",
      "  -0.667805    0.233333  ]\n",
      " [-0.176471    0.507538    0.0819672  -0.151515   -0.191489    0.0342773\n",
      "  -0.453459   -0.3       ]\n",
      " [-0.882353   -0.266332   -0.180328   -0.79798     0.         -0.314456\n",
      "  -0.854825    0.        ]\n",
      " [-0.176471    0.879397    0.114754   -0.212121   -0.281324    0.123696\n",
      "  -0.849701   -0.333333  ]\n",
      " [ 0.          0.00502513  0.442623    0.212121   -0.739953    0.394933\n",
      "  -0.24509    -0.666667  ]\n",
      " [ 0.          0.467337    0.344262    0.          0.          0.207154\n",
      "   0.454313   -0.233333  ]\n",
      " [ 0.          0.0552764   0.0491803  -0.171717   -0.664303    0.23696\n",
      "  -0.918873   -0.966667  ]\n",
      " [-0.764706   -0.155779    0.          0.          0.          0.\n",
      "  -0.807003    0.        ]\n",
      " [-0.0588235   0.336683    0.180328    0.          0.         -0.019374\n",
      "  -0.836038   -0.4       ]\n",
      " [-0.411765   -0.557789    0.0163934   0.          0.         -0.254843\n",
      "  -0.565329   -0.5       ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  840  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.0348867e-04 9.1197922e-05 1.3829865e-05 4.0081191e-05 5.8192318e-06\n",
      " 4.7668946e-04 1.7149989e-06 4.3019627e-05 7.8558936e-05 2.5193540e-05]\n",
      "Batch:  [[-0.411765  -0.135678   0.114754  -0.434343  -0.832151  -0.0998509\n",
      "  -0.755764  -0.9      ]\n",
      " [ 0.0588235  0.346734   0.213115  -0.333333  -0.858156  -0.228018\n",
      "  -0.673783   1.       ]\n",
      " [ 0.0588235  0.20603    0.180328  -0.555556  -0.867612  -0.38003\n",
      "  -0.440649  -0.1      ]\n",
      " [-0.882353  -0.286432   0.0163934  0.         0.        -0.350224\n",
      "  -0.711358  -0.833333 ]\n",
      " [-0.0588235 -0.256281   0.147541  -0.191919  -0.884161   0.052161\n",
      "  -0.46456   -0.4      ]\n",
      " [-0.411765  -0.115578   0.278689  -0.393939   0.        -0.177347\n",
      "  -0.846285  -0.466667 ]\n",
      " [ 0.176471   0.155779   0.606557   0.         0.        -0.28465\n",
      "  -0.193851  -0.566667 ]\n",
      " [ 0.         0.246231  -0.0819672 -0.737374  -0.751773  -0.350224\n",
      "  -0.680615   0.       ]\n",
      " [ 0.        -0.256281  -0.147541  -0.79798   -0.914894  -0.171386\n",
      "  -0.836892  -0.966667 ]\n",
      " [ 0.        -0.0251256  0.0491803 -0.272727  -0.763593   0.0968703\n",
      "  -0.554227  -0.866667 ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  880  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.6402620e-07 2.4320371e-03 3.1522497e-05 9.2105330e-07 6.1064852e-06\n",
      " 3.4419868e-06 4.7536185e-05 5.1878003e-05 3.9868110e-07 1.6666246e-06]\n",
      "Batch:  [[-0.764706   0.427136   0.344262  -0.636364  -0.8487    -0.263785\n",
      "  -0.416738   0.       ]\n",
      " [-0.294118   0.447236   0.180328  -0.454545  -0.460993   0.0104323\n",
      "  -0.848847  -0.366667 ]\n",
      " [-0.764706  -0.0753769  0.0163934 -0.434343   0.        -0.0581222\n",
      "  -0.955594  -0.9      ]\n",
      " [-0.882353  -0.286432  -0.213115  -0.636364  -0.820331  -0.391952\n",
      "  -0.790777  -0.966667 ]\n",
      " [-0.294118  -0.0653266 -0.180328  -0.393939  -0.8487    -0.14456\n",
      "  -0.762596  -0.933333 ]\n",
      " [-0.882353   0.226131   0.47541    0.030303  -0.479905   0.481371\n",
      "  -0.789069  -0.666667 ]\n",
      " [-0.882353   0.638191   0.180328   0.         0.         0.162444\n",
      "  -0.0230572 -0.6      ]\n",
      " [-0.882353   0.517588  -0.0163934  0.         0.        -0.222057\n",
      "  -0.913749  -0.966667 ]\n",
      " [ 0.         0.256281   0.57377    0.         0.        -0.329359\n",
      "  -0.842869   0.       ]\n",
      " [-0.882353  -0.18593    0.180328  -0.636364  -0.905437  -0.207153\n",
      "  -0.824936  -0.9      ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  920  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [9.2788866e-07 2.2049612e-06 1.3584912e-07 2.3399283e-08 2.7694799e-07\n",
      " 5.1233076e-08 2.5720622e-06 3.2989345e-07 7.7465753e-05 6.9465886e-09]\n",
      "Batch:  [[-0.294118    0.547739    0.213115   -0.353535   -0.543735   -0.126677\n",
      "  -0.350128   -0.4       ]\n",
      " [-0.764706    0.175879    0.47541    -0.616162   -0.832151   -0.248882\n",
      "  -0.799317    0.        ]\n",
      " [-0.647059   -0.155779    0.180328   -0.353535    0.          0.108793\n",
      "  -0.838599   -0.766667  ]\n",
      " [-0.294118    0.          0.114754   -0.171717    0.          0.162444\n",
      "  -0.445773   -0.333333  ]\n",
      " [-0.176471   -0.0552764   0.0491803  -0.494949   -0.813239   -0.00745157\n",
      "  -0.436379   -0.333333  ]\n",
      " [-0.647059   -0.0351759   0.278689   -0.212121    0.          0.111773\n",
      "  -0.863365   -0.366667  ]\n",
      " [ 0.176471   -0.246231    0.344262    0.          0.         -0.00745157\n",
      "  -0.842015   -0.433333  ]\n",
      " [ 0.          0.809045    0.47541    -0.474747   -0.787234    0.0879285\n",
      "  -0.798463   -0.533333  ]\n",
      " [-0.882353    0.306533   -0.0163934  -0.535354   -0.598109   -0.147541\n",
      "  -0.475662    0.        ]\n",
      " [-0.764706   -0.155779   -0.180328   -0.535354   -0.820331   -0.0938897\n",
      "  -0.239966    0.        ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  960  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.8643906e-06 1.6262592e-07 1.3580366e-07 1.1507287e-05 1.9923341e-06\n",
      " 7.7760734e-07 1.5382497e-05 4.2408794e-07 1.5499846e-06 2.4878009e-06]\n",
      "Batch:  [[-0.764706    0.256281   -0.0163934  -0.59596    -0.669031    0.00745157\n",
      "  -0.99146    -0.666667  ]\n",
      " [ 0.          0.00502513  0.147541   -0.474747   -0.881797   -0.0819672\n",
      "  -0.556789    0.        ]\n",
      " [ 0.         -0.0653266  -0.0163934  -0.494949   -0.782506   -0.14456\n",
      "  -0.612297   -0.966667  ]\n",
      " [ 0.          0.296482    0.311475    0.          0.         -0.0700447\n",
      "  -0.466268   -0.733333  ]\n",
      " [-0.411765    0.0552764   0.180328   -0.414141   -0.231678    0.0998511\n",
      "  -0.930828   -0.766667  ]\n",
      " [-0.647059    0.286432    0.278689    0.          0.         -0.371088\n",
      "  -0.837746    0.133333  ]\n",
      " [-0.411765    0.0653266   0.344262   -0.393939    0.          0.177347\n",
      "  -0.822374   -0.433333  ]\n",
      " [-0.764706    0.0854271  -0.147541   -0.474747   -0.851064   -0.0312965\n",
      "  -0.795047   -0.966667  ]\n",
      " [ 0.176471    0.0854271   0.0819672   0.          0.         -0.0342771\n",
      "  -0.83433    -0.3       ]\n",
      " [-0.529412    0.547739    0.0163934  -0.373737   -0.328605   -0.0223547\n",
      "  -0.864219   -0.933333  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  1000  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.6080511e-08 5.7890315e-06 1.4457824e-07 4.4120811e-06 8.3313481e-08\n",
      " 1.2680378e-05 4.6837792e-07 7.2807680e-09 4.7635745e-05 6.1919813e-08]\n",
      "Batch:  [[-0.647059   0.286432   0.180328  -0.494949  -0.550827  -0.0342771\n",
      "  -0.59778   -0.8      ]\n",
      " [ 0.176471  -0.0954774  0.393443  -0.353535   0.         0.0402385\n",
      "  -0.362084   0.166667 ]\n",
      " [-0.529412  -0.155779   0.47541   -0.535354  -0.867612   0.177347\n",
      "  -0.930828  -0.866667 ]\n",
      " [-0.882353  -0.115578   0.278689  -0.414141  -0.820331  -0.0461997\n",
      "  -0.75491   -0.733333 ]\n",
      " [-0.0588235  0.869347   0.47541   -0.292929  -0.468085   0.028316\n",
      "  -0.70538   -0.466667 ]\n",
      " [-0.411765   0.879397   0.245902  -0.454545  -0.510638   0.299553\n",
      "  -0.183604   0.0666667]\n",
      " [-0.529412   0.316583   0.114754  -0.575758  -0.607565  -0.0134128\n",
      "  -0.929974  -0.766667 ]\n",
      " [-0.882353   0.648241   0.344262  -0.131313  -0.841608  -0.0223547\n",
      "  -0.775406  -0.0333333]\n",
      " [-0.529412   0.899497   0.803279  -0.373737   0.        -0.150522\n",
      "  -0.485909  -0.466667 ]\n",
      " [-0.882353   0.165829   0.147541  -0.434343   0.        -0.183308\n",
      "  -0.8924     0.       ]] [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1040  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.4930109e-08 1.0546406e-04 9.4124175e-10 2.1470659e-09 5.5826541e-07\n",
      " 4.7384119e-06 1.1897895e-08 1.1091606e-07 1.7204592e-07 6.5193302e-07]\n",
      "Batch:  [[-0.294118  -0.145729   0.278689   0.         0.        -0.0700447\n",
      "  -0.740393  -0.3      ]\n",
      " [ 0.         0.296482   0.803279  -0.0707071 -0.692671   1.\n",
      "  -0.794193  -0.833333 ]\n",
      " [-0.411765   0.437186   0.278689   0.         0.         0.341282\n",
      "  -0.904355  -0.133333 ]\n",
      " [-0.411765   0.306533   0.344262   0.         0.         0.165425\n",
      "  -0.250213  -0.466667 ]\n",
      " [-0.294118  -0.125628   0.311475   0.         0.        -0.308495\n",
      "  -0.994876  -0.633333 ]\n",
      " [ 0.         0.19598    0.0491803 -0.636364  -0.782506   0.0402385\n",
      "  -0.447481  -0.933333 ]\n",
      " [-0.882353   0.         0.213115  -0.59596   -0.945626  -0.174367\n",
      "  -0.811272   0.       ]\n",
      " [-0.411765  -0.266332  -0.0163934  0.         0.        -0.201192\n",
      "  -0.837746  -0.8      ]\n",
      " [-0.529412   0.417085   0.213115   0.         0.        -0.177347\n",
      "  -0.858241  -0.366667 ]\n",
      " [-0.176471   0.949749   0.114754  -0.434343   0.         0.0700448\n",
      "  -0.430401  -0.333333 ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1080  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.8500758e-06 5.9054535e-09 1.6160200e-06 1.3762061e-06 2.4365124e-07\n",
      " 3.9823796e-08 1.9515923e-08 2.2573163e-07 7.3022159e-07 4.9266696e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[ 0.411765    0.21608     0.278689   -0.656566    0.         -0.210134\n",
      "  -0.845431    0.366667  ]\n",
      " [-0.0588235   0.00502513  0.245902    0.          0.          0.153502\n",
      "  -0.904355   -0.3       ]\n",
      " [-0.0588235   0.246231    0.245902   -0.515152    0.41844    -0.14456\n",
      "  -0.479932    0.0333333 ]\n",
      " [-0.882353   -0.0653266  -0.0819672  -0.777778    0.         -0.329359\n",
      "  -0.710504   -0.966667  ]\n",
      " [-0.0588235   0.437186    0.0819672   0.          0.          0.0402385\n",
      "  -0.956447   -0.333333  ]\n",
      " [-0.294118    0.0351759   0.0819672   0.          0.         -0.275708\n",
      "  -0.853971   -0.733333  ]\n",
      " [-0.647059    0.768844    0.409836   -0.454545   -0.631206   -0.00745157\n",
      "  -0.0811272   0.0333333 ]\n",
      " [ 0.         -0.266332    0.          0.          0.         -0.371088\n",
      "  -0.774552   -0.866667  ]\n",
      " [ 0.294118    0.115578    0.377049   -0.191919    0.          0.394933\n",
      "  -0.276687   -0.2       ]\n",
      " [-0.764706    0.125628    0.278689    0.010101   -0.669031    0.174367\n",
      "  -0.917165   -0.9       ]] [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  1120  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.1495738e-04 1.9546210e-06 3.7040110e-05 2.6045384e-09 3.3353790e-06\n",
      " 2.5455947e-07 4.3223875e-07 6.5963229e-07 2.3368286e-05 9.0563929e-10]\n",
      "Batch:  [[-0.294118    0.256281    0.114754   -0.393939   -0.716312   -0.105812\n",
      "  -0.670367   -0.633333  ]\n",
      " [-0.411765   -0.145729    0.213115   -0.555556    0.         -0.135618\n",
      "  -0.0213493  -0.633333  ]\n",
      " [-0.411765    0.125628    0.0819672   0.          0.          0.126677\n",
      "  -0.843723   -0.333333  ]\n",
      " [ 0.          0.778894   -0.0163934  -0.414141    0.130024    0.0312965\n",
      "  -0.151153    0.        ]\n",
      " [-0.764706    0.58794     0.47541     0.          0.         -0.0581222\n",
      "  -0.379163    0.5       ]\n",
      " [-0.176471    0.19598     0.          0.          0.         -0.248882\n",
      "  -0.88813    -0.466667  ]\n",
      " [-0.176471    0.427136   -0.0163934  -0.333333   -0.550827   -0.14158\n",
      "  -0.479932    0.333333  ]\n",
      " [-0.882353    0.00502513  0.0819672  -0.69697    -0.867612   -0.296572\n",
      "  -0.497865   -0.833333  ]\n",
      " [-0.882353   -0.125628    0.278689   -0.454545   -0.92435     0.0312965\n",
      "  -0.980359   -0.966667  ]\n",
      " [ 0.          0.0150754   0.245902    0.          0.          0.0640835\n",
      "  -0.897523   -0.833333  ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1160  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.7623199e-08 1.8172382e-07 4.8759364e-07 9.7954144e-05 1.0487931e-05\n",
      " 1.1292072e-06 1.8706309e-05 3.0318686e-10 2.5483348e-11 1.2071187e-07]\n",
      "Batch:  [[ 0.        -0.0552764  0.147541  -0.454545  -0.728132   0.296572\n",
      "  -0.770282   0.       ]\n",
      " [-0.764706   0.0854271  0.0491803  0.         0.        -0.0819672\n",
      "  -0.931682   0.       ]\n",
      " [-0.529412  -0.0954774  0.442623  -0.0505051 -0.87234    0.123696\n",
      "  -0.757472  -0.733333 ]\n",
      " [ 0.         0.256281   0.114754   0.         0.        -0.263785\n",
      "  -0.890692   0.       ]\n",
      " [ 0.         0.326633   0.278689   0.         0.        -0.0342771\n",
      "  -0.730999   0.       ]\n",
      " [-0.411765   0.286432   0.311475   0.         0.         0.0312965\n",
      "  -0.943638  -0.2      ]\n",
      " [-0.529412  -0.0552764  0.0655738 -0.555556   0.        -0.263785\n",
      "  -0.940222   0.       ]\n",
      " [-0.176471   0.145729   0.0491803  0.         0.        -0.183308\n",
      "  -0.441503  -0.566667 ]\n",
      " [ 0.         0.0251256  0.278689  -0.191919  -0.787234   0.028316\n",
      "  -0.863365  -0.9      ]\n",
      " [-0.764706   0.115578  -0.0163934  0.         0.        -0.219076\n",
      "  -0.773698  -0.933333 ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1200  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.9801913e-07 3.4613811e-07 5.9669075e-10 1.1385933e-05 9.0750382e-06\n",
      " 2.4380188e-07 2.3446087e-07 1.1277037e-06 3.2317271e-09 6.3116605e-09]\n",
      "Batch:  [[-0.647059    0.919598    0.114754   -0.69697    -0.692671   -0.0789866\n",
      "  -0.811272   -0.566667  ]\n",
      " [-0.647059    0.417085    0.          0.          0.         -0.105812\n",
      "  -0.416738   -0.8       ]\n",
      " [-0.529412   -0.0452261   0.147541   -0.353535    0.         -0.0432191\n",
      "  -0.54398    -0.9       ]\n",
      " [-0.647059    0.427136    0.311475   -0.69697     0.         -0.0342771\n",
      "  -0.895816    0.4       ]\n",
      " [-0.529412    0.236181    0.0163934   0.          0.         -0.0461997\n",
      "  -0.873612   -0.533333  ]\n",
      " [-0.411765   -0.0351759   0.213115   -0.636364   -0.841608    0.00149028\n",
      "  -0.215201   -0.266667  ]\n",
      " [ 0.          0.386935    0.          0.          0.          0.0819672\n",
      "  -0.269855   -0.866667  ]\n",
      " [-0.764706    0.286432    0.0491803  -0.151515    0.          0.19225\n",
      "  -0.126388   -0.9       ]\n",
      " [ 0.          0.0251256  -0.147541    0.          0.         -0.251863\n",
      "   0.          0.        ]\n",
      " [-0.764706    0.467337    0.          0.          0.         -0.180328\n",
      "  -0.861657   -0.766667  ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1240  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [5.8941185e-10 3.3490064e-08 4.3163295e-09 2.4120868e-07 4.8417579e-08\n",
      " 1.7573319e-08 5.6992639e-07 1.1791645e-08 2.3036345e-04 6.6098216e-09]\n",
      "Batch:  [[-0.882353    0.125628    0.311475   -0.0909091  -0.687943    0.0372578\n",
      "  -0.881298   -0.9       ]\n",
      " [-0.529412    0.457286    0.344262   -0.636364    0.         -0.0312965\n",
      "  -0.865927    0.633333  ]\n",
      " [ 0.176471    0.115578    0.147541   -0.454545    0.         -0.180328\n",
      "  -0.9462     -0.366667  ]\n",
      " [-0.294118   -0.0150754  -0.0491803  -0.333333   -0.550827    0.0134128\n",
      "  -0.699402   -0.266667  ]\n",
      " [ 0.0588235   0.547739    0.278689   -0.393939   -0.763593   -0.0789866\n",
      "  -0.926558   -0.2       ]\n",
      " [-0.294118    0.658291    0.114754   -0.474747   -0.602837    0.00149028\n",
      "  -0.527754   -0.0666667 ]\n",
      " [-0.882353   -0.00502513 -0.0491803  -0.79798     0.         -0.242921\n",
      "  -0.596072    0.        ]\n",
      " [ 0.176471   -0.316583    0.737705   -0.535354   -0.884161    0.0581222\n",
      "  -0.823228   -0.133333  ]\n",
      " [-0.647059    0.236181    0.639344   -0.292929   -0.432624    0.707899\n",
      "  -0.315115   -0.966667  ]\n",
      " [-0.0588235  -0.0854271   0.344262    0.          0.          0.0611028\n",
      "  -0.565329    0.566667  ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1280  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.3164781e-11 1.0063503e-06 2.7509114e-07 4.7407347e-08 3.4527915e-08\n",
      " 1.0945920e-07 3.4281769e-08 8.0535285e-09 7.7418190e-11 7.0445531e-05]\n",
      "Batch:  [[-0.411765  -0.226131   0.344262  -0.171717  -0.900709   0.0670641\n",
      "  -0.93339   -0.533333 ]\n",
      " [-0.411765   0.155779   0.606557   0.         0.         0.576751\n",
      "  -0.88813   -0.766667 ]\n",
      " [-0.647059   0.507538   0.245902   0.         0.        -0.374069\n",
      "  -0.889838  -0.466667 ]\n",
      " [-0.764706   0.20603    0.245902  -0.252525  -0.751773   0.183309\n",
      "  -0.883006  -0.733333 ]\n",
      " [ 0.176471   0.61809    0.114754  -0.535354  -0.687943  -0.23994\n",
      "  -0.788215  -0.133333 ]\n",
      " [ 0.         0.376884   0.114754  -0.717172  -0.650118  -0.260805\n",
      "  -0.944492   0.       ]\n",
      " [ 0.         0.286432   0.114754  -0.616162  -0.574468  -0.0909091\n",
      "   0.121264  -0.866667 ]\n",
      " [-0.764706   0.246231   0.114754  -0.434343  -0.515366  -0.019374\n",
      "  -0.319385  -0.7      ]\n",
      " [-0.294118  -0.19598    0.0819672 -0.393939   0.        -0.219076\n",
      "  -0.799317  -0.333333 ]\n",
      " [ 0.         0.0653266  0.147541  -0.252525  -0.650118   0.174367\n",
      "  -0.549957  -0.966667 ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1320  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.1492773e-10 6.0458516e-10 8.3465972e-09 2.9316560e-11 1.3620794e-07\n",
      " 4.5577199e-08 1.9616984e-08 5.5262189e-10 4.8535924e-08 1.6940237e-09]\n",
      "Batch:  [[ 0.176471   0.155779   0.         0.         0.         0.\n",
      "  -0.843723  -0.7      ]\n",
      " [-0.764706   0.276382  -0.245902  -0.575758  -0.208038   0.0253354\n",
      "  -0.916311  -0.966667 ]\n",
      " [ 0.0588235  0.648241   0.278689   0.         0.        -0.0223547\n",
      "  -0.940222  -0.2      ]\n",
      " [-0.764706  -0.0653266  0.0491803 -0.353535  -0.621749   0.132638\n",
      "  -0.491033  -0.933333 ]\n",
      " [-0.647059   0.58794    0.0491803 -0.737374  -0.0851064 -0.0700447\n",
      "  -0.814688  -0.9      ]\n",
      " [-0.411765   0.266332   0.278689  -0.454545  -0.947991  -0.117735\n",
      "  -0.691716  -0.366667 ]\n",
      " [ 0.176471   0.296482   0.0163934 -0.272727   0.         0.228018\n",
      "  -0.690009  -0.433333 ]\n",
      " [ 0.         0.346734  -0.0491803 -0.59596   -0.312057  -0.213115\n",
      "  -0.766012   0.       ]\n",
      " [-0.647059   0.0251256  0.213115   0.         0.        -0.120715\n",
      "  -0.963279  -0.633333 ]\n",
      " [-0.176471   0.879397  -0.180328  -0.333333  -0.0732861  0.0104323\n",
      "  -0.36123   -0.566667 ]] [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1360  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.1424739e-07 4.2687735e-11 3.7872570e-07 3.6753531e-11 6.6740946e-11\n",
      " 4.1802736e-10 3.4047937e-07 3.2956927e-07 1.0249170e-09 1.6983391e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.411765    0.226131    0.409836    0.          0.          0.0342773\n",
      "  -0.818958   -0.6       ]\n",
      " [-0.0588235  -0.0452261   0.180328    0.          0.          0.0968703\n",
      "  -0.652434    0.2       ]\n",
      " [-0.0588235   0.266332    0.442623   -0.272727   -0.744681    0.147541\n",
      "  -0.768574   -0.0666667 ]\n",
      " [-0.882353    0.396985   -0.245902   -0.616162   -0.803783   -0.14456\n",
      "  -0.508113   -0.966667  ]\n",
      " [-0.647059    0.165829    0.          0.          0.         -0.299553\n",
      "  -0.906917   -0.933333  ]\n",
      " [-0.647059   -0.00502513  0.0163934  -0.616162   -0.825059   -0.350224\n",
      "  -0.828352   -0.833333  ]\n",
      " [-0.411765    0.          0.311475   -0.353535    0.          0.222057\n",
      "  -0.771136   -0.466667  ]\n",
      " [-0.529412   -0.0753769   0.311475    0.          0.          0.257824\n",
      "  -0.864219   -0.733333  ]\n",
      " [-0.529412    0.376884    0.377049    0.          0.         -0.0700447\n",
      "  -0.851409   -0.7       ]\n",
      " [-0.647059   -0.386935    0.344262   -0.434343    0.          0.0253354\n",
      "  -0.859095   -0.166667  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1400  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.8828901e-09 4.1851827e-06 9.2140455e-09 7.9930836e-12 2.9775063e-10\n",
      " 6.7564353e-12 1.9080706e-09 4.3222426e-10 6.5371242e-10 1.7807883e-09]\n",
      "Batch:  [[-0.882353  -0.18593    0.213115  -0.171717  -0.865248   0.38003\n",
      "  -0.130658  -0.633333 ]\n",
      " [-0.647059   0.879397   0.147541  -0.555556  -0.527187   0.0849479\n",
      "  -0.71819   -0.5      ]\n",
      " [-0.294118   0.628141   0.0163934  0.         0.        -0.275708\n",
      "  -0.914603  -0.0333333]\n",
      " [-0.529412   0.366834   0.147541   0.         0.        -0.0700447\n",
      "  -0.0572161 -0.966667 ]\n",
      " [-0.882353   0.21608    0.278689  -0.212121  -0.825059   0.162444\n",
      "  -0.843723  -0.766667 ]\n",
      " [-0.647059   0.0854271  0.0163934 -0.515152   0.        -0.225037\n",
      "  -0.876174  -0.866667 ]\n",
      " [ 0.         0.819095   0.442623  -0.111111   0.205674   0.290611\n",
      "  -0.877028  -0.833333 ]\n",
      " [-0.0588235  0.547739   0.278689  -0.353535   0.        -0.0342771\n",
      "  -0.688301  -0.2      ]\n",
      " [-0.882353   0.286432   0.442623  -0.212121  -0.739953   0.0879285\n",
      "  -0.163962  -0.466667 ]\n",
      " [-0.176471   0.376884   0.47541   -0.171717   0.        -0.0461997\n",
      "  -0.732707  -0.4      ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  1440  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [4.7131840e-11 6.9565922e-11 2.0807929e-07 3.5080936e-09 1.3440920e-12\n",
      " 4.5000972e-11 2.0887461e-09 7.0017556e-08 9.9163774e-11 8.3995078e-09]\n",
      "Batch:  [[-0.882353    0.256281    0.147541   -0.515152   -0.739953   -0.275708\n",
      "  -0.877882   -0.866667  ]\n",
      " [-0.882353    0.19598    -0.114754   -0.737374   -0.881797   -0.33532\n",
      "  -0.891546   -0.9       ]\n",
      " [-0.411765    0.165829    0.213115   -0.414141    0.         -0.0372578\n",
      "  -0.502989   -0.533333  ]\n",
      " [-0.0588235   0.0552764   0.639344   -0.272727    0.          0.290611\n",
      "  -0.862511   -0.2       ]\n",
      " [-0.411765    0.447236    0.344262   -0.474747   -0.326241   -0.0461997\n",
      "  -0.680615    0.233333  ]\n",
      " [-0.647059    0.00502513  0.114754   -0.535354   -0.808511   -0.0581222\n",
      "  -0.256191   -0.766667  ]\n",
      " [-0.882353    0.00502513  0.0819672  -0.414141   -0.536643   -0.0461997\n",
      "  -0.687447   -0.3       ]\n",
      " [-0.411765    0.668342    0.245902    0.          0.          0.362146\n",
      "  -0.77626    -0.8       ]\n",
      " [-0.882353    0.316583    0.0491803  -0.717172   -0.0189125  -0.293592\n",
      "  -0.734415    0.        ]\n",
      " [-0.529412    0.165829    0.180328   -0.757576   -0.794326   -0.341282\n",
      "  -0.671221   -0.466667  ]] [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1480  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [3.4843065e-13 2.0322929e-13 1.8251060e-09 5.6391944e-09 1.7443282e-08\n",
      " 1.8998216e-11 6.9686638e-11 3.2483802e-10 1.2392275e-09 2.1137887e-11]\n",
      "Batch:  [[-0.0588235  -0.00502513  0.377049    0.          0.          0.0551417\n",
      "  -0.735269   -0.0333333 ]\n",
      " [-0.176471    0.969849    0.47541     0.          0.          0.186289\n",
      "  -0.681469   -0.333333  ]\n",
      " [ 0.0588235   0.19598     0.311475   -0.292929    0.         -0.135618\n",
      "  -0.842015   -0.733333  ]\n",
      " [ 0.176471    0.256281    0.147541   -0.474747   -0.728132   -0.0730253\n",
      "  -0.891546   -0.333333  ]\n",
      " [-0.176471    0.477387    0.245902    0.          0.          0.174367\n",
      "  -0.847139   -0.266667  ]\n",
      " [-0.882353   -0.0251256   0.0819672  -0.69697    -0.669031   -0.308495\n",
      "  -0.650726   -0.966667  ]\n",
      " [ 0.529412    0.457286    0.344262   -0.616162   -0.739953   -0.338301\n",
      "  -0.857387    0.2       ]\n",
      " [-0.411765    0.175879    0.508197    0.          0.          0.0163934\n",
      "  -0.778822   -0.433333  ]\n",
      " [-0.411765    0.0954774   0.229508   -0.474747    0.          0.0730254\n",
      "  -0.600342    0.3       ]\n",
      " [-0.647059    0.58794     0.245902   -0.272727   -0.420804   -0.0581222\n",
      "  -0.33988    -0.766667  ]] [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1520  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.1832134e-07 9.7083710e-09 9.9466346e-10 1.2627632e-09 1.4479149e-08\n",
      " 1.9168468e-13 1.0641719e-07 8.1308665e-10 9.2964882e-08 4.8495416e-11]\n",
      "Batch:  [[ 0.         -0.0552764   0.          0.          0.          0.\n",
      "  -0.847993   -0.866667  ]\n",
      " [-0.882353    0.819095    0.0491803  -0.393939   -0.574468    0.0163934\n",
      "  -0.786507   -0.433333  ]\n",
      " [ 0.          0.356784    0.540984   -0.0707071  -0.65721     0.210134\n",
      "  -0.824082   -0.833333  ]\n",
      " [-0.882353   -0.0452261   0.344262   -0.494949   -0.574468    0.0432191\n",
      "  -0.867635   -0.266667  ]\n",
      " [-0.764706   -0.00502513  0.          0.          0.         -0.338301\n",
      "  -0.974381   -0.933333  ]\n",
      " [-0.647059   -0.105528    0.213115   -0.676768   -0.799054   -0.0938897\n",
      "  -0.596072   -0.433333  ]\n",
      " [-0.882353   -0.19598     0.213115   -0.777778   -0.858156   -0.105812\n",
      "  -0.616567   -0.966667  ]\n",
      " [-0.764706    0.396985    0.229508    0.          0.         -0.23696\n",
      "  -0.923997   -0.733333  ]\n",
      " [-0.882353   -0.0954774   0.114754   -0.838384    0.         -0.269747\n",
      "  -0.0947908  -0.5       ]\n",
      " [ 0.          0.417085    0.          0.          0.          0.263785\n",
      "  -0.891546   -0.733333  ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1560  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.2024803e-09 6.3583878e-12 1.5986266e-11 2.7073166e-12 8.5770774e-12\n",
      " 4.6297497e-12 2.1453002e-14 1.7507253e-11 1.4259768e-10 2.1299427e-09]\n",
      "Batch:  [[-0.764706    0.417085   -0.0491803  -0.313131   -0.6974     -0.242921\n",
      "  -0.469684   -0.9       ]\n",
      " [-0.176471    0.145729    0.0819672   0.          0.         -0.0223547\n",
      "  -0.846285   -0.3       ]\n",
      " [-0.411765   -0.00502513  0.213115   -0.454545    0.         -0.135618\n",
      "  -0.893254   -0.633333  ]\n",
      " [ 0.          0.0954774   0.442623   -0.393939    0.         -0.0312965\n",
      "  -0.336465   -0.433333  ]\n",
      " [-0.764706    0.0954774   0.508197    0.          0.          0.272727\n",
      "  -0.345004    0.1       ]\n",
      " [-0.882353   -0.0452261   0.0819672  -0.737374   -0.910165   -0.415797\n",
      "  -0.781383   -0.866667  ]\n",
      " [-0.529412    0.467337    0.393443   -0.454545   -0.763593   -0.138599\n",
      "  -0.905209   -0.8       ]\n",
      " [-0.764706    0.00502513  0.0819672  -0.59596    -0.787234   -0.019374\n",
      "  -0.326217   -0.766667  ]\n",
      " [-0.411765    0.396985    0.0491803  -0.292929   -0.669031   -0.147541\n",
      "  -0.715628   -0.833333  ]\n",
      " [ 0.529412    0.266332    0.47541     0.          0.          0.293592\n",
      "  -0.568745   -0.3       ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1600  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.6240700e-12 8.3863325e-09 2.7941791e-11 7.2952799e-09 8.0658724e-09\n",
      " 1.6425607e-14 1.4219062e-13 1.0367694e-12 4.5248479e-12 3.2689323e-07]\n",
      "Batch:  [[-0.0588235  0.20603    0.         0.         0.        -0.105812\n",
      "  -0.910333  -0.433333 ]\n",
      " [-0.294118   0.547739   0.278689  -0.171717  -0.669031   0.374069\n",
      "  -0.578992  -0.8      ]\n",
      " [-0.882353   0.447236   0.344262  -0.191919   0.         0.230999\n",
      "  -0.548249  -0.766667 ]\n",
      " [ 0.         0.376884   0.147541  -0.232323   0.        -0.0104321\n",
      "  -0.921435  -0.966667 ]\n",
      " [ 0.         0.19598    0.0819672 -0.454545   0.         0.156483\n",
      "  -0.845431  -0.966667 ]\n",
      " [-0.176471   0.366834   0.47541    0.         0.        -0.108793\n",
      "  -0.887276  -0.0333333]\n",
      " [-0.529412   0.145729   0.0491803  0.         0.        -0.138599\n",
      "  -0.959009  -0.9      ]\n",
      " [ 0.         0.376884   0.377049  -0.454545   0.        -0.186289\n",
      "  -0.869342   0.266667 ]\n",
      " [-0.764706   0.0552764  0.311475  -0.0909091 -0.548463   0.004471\n",
      "  -0.459436  -0.733333 ]\n",
      " [-0.176471   0.145729   0.245902  -0.656566  -0.739953  -0.290611\n",
      "  -0.668659  -0.666667 ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]]\n",
      "step:  1640  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [4.3616981e-09 5.4604667e-12 2.9806112e-12 4.0302234e-11 2.9541532e-11\n",
      " 6.7740458e-09 8.6237146e-12 4.5906287e-08 2.3178957e-12 3.7947111e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.764706   -0.145729    0.0655738   0.          0.          0.180328\n",
      "  -0.272417   -0.8       ]\n",
      " [-0.882353    0.266332   -0.0819672  -0.414141   -0.640662   -0.14456\n",
      "  -0.382579    0.        ]\n",
      " [-0.882353   -0.0351759   1.          0.          0.         -0.33234\n",
      "  -0.889838   -0.8       ]\n",
      " [-0.529412    0.447236   -0.0491803  -0.434343   -0.669031   -0.120715\n",
      "  -0.82152    -0.466667  ]\n",
      " [-0.647059   -0.165829   -0.0491803  -0.373737   -0.957447    0.0223547\n",
      "  -0.779675   -0.866667  ]\n",
      " [ 0.         -0.0452261   0.393443   -0.494949   -0.914894    0.114754\n",
      "  -0.855679   -0.9       ]\n",
      " [-0.647059    0.718593    0.180328   -0.333333   -0.680851   -0.00745157\n",
      "  -0.89667    -0.9       ]\n",
      " [-0.0588235   0.557789    0.0163934  -0.474747    0.170213    0.0134128\n",
      "  -0.602904   -0.166667  ]\n",
      " [-0.882353   -0.105528    0.245902   -0.313131   -0.91253    -0.0700447\n",
      "  -0.902647   -0.933333  ]\n",
      " [-0.529412   -0.236181    0.0163934   0.          0.          0.0134128\n",
      "  -0.732707   -0.866667  ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1680  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [5.3190431e-11 1.4025951e-10 5.5136888e-14 3.6254441e-12 4.8514774e-14\n",
      " 1.6969176e-13 3.6455356e-14 2.4547788e-08 2.2636585e-15 1.7135295e-11]\n",
      "Batch:  [[-0.0588235   0.20603     0.278689    0.          0.         -0.254843\n",
      "  -0.717336    0.433333  ]\n",
      " [ 0.411765   -0.155779    0.180328   -0.373737    0.         -0.114754\n",
      "  -0.81298    -0.166667  ]\n",
      " [ 0.          0.396985    0.0163934  -0.656566   -0.503546   -0.341282\n",
      "  -0.889838    0.        ]\n",
      " [ 0.0588235  -0.0854271   0.114754    0.          0.         -0.278688\n",
      "  -0.895816    0.233333  ]\n",
      " [-0.764706   -0.0854271   0.0163934   0.          0.         -0.186289\n",
      "  -0.618275   -0.966667  ]\n",
      " [-0.647059   -0.00502513 -0.114754   -0.616162   -0.79669    -0.23696\n",
      "  -0.935098   -0.9       ]\n",
      " [-0.647059    0.638191    0.147541   -0.636364   -0.751773   -0.0581222\n",
      "  -0.837746   -0.766667  ]\n",
      " [ 0.0588235   0.457286    0.442623   -0.313131   -0.609929   -0.0968703\n",
      "  -0.408198    0.0666667 ]\n",
      " [ 0.529412   -0.236181   -0.0163934   0.          0.         -0.0223547\n",
      "  -0.912895   -0.333333  ]\n",
      " [-0.294118    0.296482    0.47541    -0.858586   -0.229314   -0.415797\n",
      "  -0.569599    0.3       ]] [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1720  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [7.3059908e-07 3.5556678e-08 6.3725025e-10 2.5933599e-07 2.4794028e-12\n",
      " 1.0000463e-14 1.6981893e-14 7.4414088e-09 1.0224695e-07 1.3429923e-09]\n",
      "Batch:  [[ 0.         0.0251256  0.229508  -0.535354   0.         0.\n",
      "  -0.578138   0.       ]\n",
      " [ 0.0588235 -0.427136   0.311475  -0.252525   0.        -0.0223547\n",
      "  -0.984629  -0.333333 ]\n",
      " [-0.764706   0.0653266  0.0491803 -0.292929  -0.718676  -0.0909091\n",
      "   0.12895   -0.566667 ]\n",
      " [-0.411765   0.477387   0.278689   0.         0.         0.004471\n",
      "  -0.880444   0.466667 ]\n",
      " [-0.764706  -0.0954774  0.147541  -0.656566   0.        -0.186289\n",
      "  -0.994022  -0.966667 ]\n",
      " [-0.882353   0.366834   0.213115   0.010101  -0.51773    0.114754\n",
      "  -0.725875  -0.9      ]\n",
      " [-0.529412   0.145729   0.0655738  0.         0.        -0.347243\n",
      "  -0.697694  -0.466667 ]\n",
      " [ 0.0588235  0.567839   0.409836  -0.434343  -0.63357    0.0223547\n",
      "  -0.0512383 -0.3      ]\n",
      " [-0.882353   0.537688   0.344262  -0.151515   0.146572   0.210134\n",
      "  -0.479932  -0.933333 ]\n",
      " [-0.0588235  0.889447   0.278689   0.         0.         0.42772\n",
      "  -0.949616  -0.266667 ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1760  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [9.4451709e-09 2.9319255e-10 1.8019496e-11 2.7044836e-08 8.8738204e-15\n",
      " 2.8397308e-14 1.1921461e-10 1.4609636e-09 4.3843431e-13 6.7428590e-10]\n",
      "Batch:  [[-0.647059   -0.155779    0.114754   -0.393939   -0.749409   -0.0491803\n",
      "  -0.561913   -0.866667  ]\n",
      " [-0.294118    0.145729    0.442623    0.          0.         -0.171386\n",
      "  -0.855679    0.5       ]\n",
      " [-0.882353   -0.115578    0.0163934  -0.515152   -0.895981   -0.108793\n",
      "  -0.706234   -0.933333  ]\n",
      " [-0.882353   -0.155779    0.0491803  -0.535354   -0.728132    0.0998511\n",
      "  -0.664389   -0.766667  ]\n",
      " [-0.176471    0.246231    0.147541   -0.333333   -0.491726   -0.23994\n",
      "  -0.92912    -0.466667  ]\n",
      " [-0.882353   -0.0251256   0.147541   -0.191919    0.          0.135618\n",
      "  -0.880444   -0.7       ]\n",
      " [-0.0588235   0.105528    0.245902    0.          0.         -0.171386\n",
      "  -0.864219    0.233333  ]\n",
      " [ 0.294118    0.0351759   0.114754   -0.191919    0.          0.377049\n",
      "  -0.959009   -0.3       ]\n",
      " [ 0.294118   -0.145729    0.213115    0.          0.         -0.102832\n",
      "  -0.810418   -0.533333  ]\n",
      " [-0.294118    0.256281    0.245902    0.          0.          0.00745157\n",
      "  -0.963279    0.1       ]] [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1800  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.4002405e-14 3.1692032e-08 7.6257582e-16 4.8525391e-15 4.0099712e-12\n",
      " 1.3785637e-13 3.9077900e-08 2.4237272e-09 1.9213311e-09 1.7885904e-09]\n",
      "Batch:  [[-0.0588235  0.819095   0.114754  -0.272727   0.170213  -0.102832\n",
      "  -0.541418   0.3      ]\n",
      " [-0.882353   0.286432   0.606557  -0.171717  -0.862884  -0.0461997\n",
      "   0.0614859 -0.6      ]\n",
      " [-0.0588235  0.0954774  0.245902  -0.212121  -0.730496  -0.168405\n",
      "  -0.520068  -0.666667 ]\n",
      " [-0.411765   0.396985   0.311475  -0.292929  -0.621749  -0.0581222\n",
      "  -0.758326  -0.866667 ]\n",
      " [-0.647059   0.115578   0.0163934  0.         0.        -0.326379\n",
      "  -0.945346   0.       ]\n",
      " [ 0.0588235  0.236181   0.147541  -0.111111  -0.777778  -0.0134128\n",
      "  -0.747225  -0.366667 ]\n",
      " [-0.176471   0.59799    0.0819672  0.         0.        -0.0938897\n",
      "  -0.739539  -0.5      ]\n",
      " [ 0.294118   0.356784   0.         0.         0.         0.558867\n",
      "  -0.573015  -0.366667 ]\n",
      " [-0.0588235 -0.145729  -0.0983607 -0.59596    0.        -0.272727\n",
      "  -0.95047   -0.3      ]\n",
      " [-0.411765   0.58794    0.377049  -0.171717  -0.503546   0.174367\n",
      "  -0.729291  -0.733333 ]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1840  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [3.1100822e-07 1.6246486e-13 4.0853809e-12 2.1314491e-14 1.7711503e-10\n",
      " 3.4930673e-11 1.9157495e-10 2.5726401e-08 1.1011805e-10 1.2662651e-13]\n",
      "Batch:  [[-0.647059    0.326633    0.311475    0.          0.          0.0253354\n",
      "  -0.723313   -0.233333  ]\n",
      " [-0.764706   -0.175879   -0.147541   -0.555556   -0.728132   -0.150522\n",
      "   0.384287   -0.866667  ]\n",
      " [-0.294118    0.236181    0.180328   -0.0909091  -0.456265    0.00149028\n",
      "  -0.440649   -0.566667  ]\n",
      " [ 0.          0.889447    0.344262   -0.717172   -0.562648   -0.0461997\n",
      "  -0.484202   -0.966667  ]\n",
      " [ 0.         -0.326633    0.245902    0.          0.          0.350224\n",
      "  -0.900939   -0.166667  ]\n",
      " [-0.882353   -0.105528   -0.606557   -0.616162   -0.940898   -0.171386\n",
      "  -0.58924     0.        ]\n",
      " [-0.882353    0.738693    0.213115    0.          0.          0.0968703\n",
      "  -0.99146    -0.433333  ]\n",
      " [-0.882353    0.0954774  -0.377049   -0.636364   -0.716312   -0.311475\n",
      "  -0.719044   -0.833333  ]\n",
      " [-0.882353    0.0854271   0.442623   -0.616162    0.         -0.19225\n",
      "  -0.725021   -0.9       ]\n",
      " [-0.294118   -0.0351759   0.          0.          0.         -0.293592\n",
      "  -0.904355   -0.766667  ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  1880  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [1.8014068e-11 1.3398253e-12 1.1402490e-11 7.5036460e-14 7.5295248e-10\n",
      " 2.3764274e-12 2.4264236e-13 2.2214680e-15 1.4169342e-15 4.1559659e-12]\n",
      "Batch:  [[-0.647059   0.628141  -0.147541  -0.232323   0.         0.108793\n",
      "  -0.509821  -0.9      ]\n",
      " [-0.529412   0.979899   0.147541  -0.212121   0.758865   0.0938898\n",
      "   0.922289  -0.666667 ]\n",
      " [ 0.         0.175879   0.311475  -0.373737  -0.874704   0.347243\n",
      "  -0.990606  -0.9      ]\n",
      " [-0.529412   0.427136   0.409836   0.         0.         0.311475\n",
      "  -0.515798  -0.966667 ]\n",
      " [-0.294118   0.346734   0.311475  -0.252525  -0.125296   0.377049\n",
      "  -0.863365  -0.166667 ]\n",
      " [-0.882353  -0.20603    0.311475  -0.494949  -0.91253   -0.242921\n",
      "  -0.568745  -0.966667 ]\n",
      " [-0.529412   0.226131   0.114754   0.         0.         0.0432191\n",
      "  -0.730145  -0.733333 ]\n",
      " [-0.647059  -0.256281   0.114754  -0.434343  -0.893617  -0.114754\n",
      "  -0.816396  -0.933333 ]\n",
      " [-0.529412   0.718593   0.180328   0.         0.         0.299553\n",
      "  -0.657558  -0.833333 ]\n",
      " [ 0.         0.798995   0.47541   -0.454545   0.         0.314456\n",
      "  -0.480786  -0.933333 ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "step:  1920  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [4.95918411e-13 4.72646093e-07 2.88763018e-15 1.70311072e-13\n",
      " 1.29582525e-11 4.83848612e-17 1.00483120e-12 1.81818507e-16\n",
      " 4.80064176e-13 1.03878245e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:  [[-0.882353    0.286432    0.344262   -0.656566   -0.567376   -0.180328\n",
      "  -0.968403   -0.966667  ]\n",
      " [ 0.176471   -0.0753769   0.0163934   0.          0.         -0.228018\n",
      "  -0.923997   -0.666667  ]\n",
      " [ 0.529412    0.0452261   0.180328    0.          0.         -0.0700447\n",
      "  -0.669513   -0.433333  ]\n",
      " [-0.411765    0.0452261   0.213115    0.          0.         -0.14158\n",
      "  -0.935952   -0.1       ]\n",
      " [-0.764706   -0.0552764   0.245902   -0.636364   -0.843972   -0.0581222\n",
      "  -0.512383   -0.933333  ]\n",
      " [-0.176471   -0.0251256   0.245902   -0.353535   -0.78487     0.219076\n",
      "  -0.322801   -0.633333  ]\n",
      " [-0.882353    0.00502513  0.213115   -0.757576   -0.891253   -0.418778\n",
      "  -0.939368   -0.766667  ]\n",
      " [ 0.          0.0251256   0.409836   -0.656566   -0.751773   -0.126677\n",
      "  -0.4731     -0.8       ]\n",
      " [-0.529412    0.286432    0.147541    0.          0.          0.0223547\n",
      "  -0.807857   -0.9       ]\n",
      " [-0.294118    0.477387    0.311475    0.          0.         -0.120715\n",
      "  -0.914603   -0.0333333 ]] [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "step:  1960  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [3.6937382e-18 5.4154747e-11 8.7357055e-09 3.6749326e-11 8.0760006e-17\n",
      " 5.5534825e-13 5.9019924e-18 3.8061744e-14 8.1331460e-14 1.0121821e-10]\n",
      "Batch:  [[ 0.176471    0.0150754   0.409836   -0.252525    0.          0.359165\n",
      "  -0.0964987  -0.433333  ]\n",
      " [-0.764706    0.0854271   0.0163934  -0.353535   -0.867612   -0.248882\n",
      "  -0.957301    0.        ]\n",
      " [-0.647059    0.226131    0.278689    0.          0.         -0.314456\n",
      "  -0.849701   -0.366667  ]\n",
      " [-0.882353   -0.286432    0.278689    0.010101   -0.893617   -0.0104321\n",
      "  -0.706234    0.        ]\n",
      " [ 0.529412    0.0653266   0.147541    0.          0.          0.0193741\n",
      "  -0.852263    0.0333333 ]\n",
      " [-0.764706    0.00502513  0.147541    0.0505051  -0.865248    0.207154\n",
      "  -0.488471   -0.866667  ]\n",
      " [-0.176471    0.0653266  -0.0163934  -0.515152    0.         -0.210134\n",
      "  -0.813834   -0.733333  ]\n",
      " [ 0.          0.0452261   0.0491803  -0.535354   -0.725768   -0.171386\n",
      "  -0.678907   -0.933333  ]\n",
      " [-0.411765    0.145729    0.213115    0.          0.         -0.257824\n",
      "  -0.431255    0.2       ]\n",
      " [-0.764706    0.0854271   0.0163934  -0.79798    -0.34279    -0.245902\n",
      "  -0.314261   -0.966667  ]] [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "step:  2000  | cost:  Tensor(\"Mean_4:0\", shape=(), dtype=float32) \n",
      "Prediction: \n",
      " [2.5158877e-09 3.1327497e-14 7.6101067e-13 1.0023250e-13 8.3660147e-08\n",
      " 1.7813058e-15 4.3482159e-13 1.5445358e-14 6.8833472e-09 1.6089383e-15]\n",
      "\n",
      " Y_data: \n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    \n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict = {X:x_batch, Y:y_batch})\n",
    "    \n",
    "    if step %40 == 0:\n",
    "        print('Batch: ', x_batch, y_batch)\n",
    "        print('step: ', step, ' | cost: ', cost, '\\nPrediction: \\n', np.concatenate(hy_val))\n",
    "\n",
    "print('\\n Y_data: \\n', np.concatenate(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
