{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data creation\n",
    "idx2char = ['h', 'i', 'e','l', 'o']\n",
    "x_data = [[0,1,0,2,3,3]] #hihell\n",
    "x_one_hot = [[[1,0,0,0,0],\n",
    "              [0,1,0,0,0],\n",
    "              [1,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,1,0],\n",
    "              [0,0,0,1,0]]]\n",
    "\n",
    "y_data = [1,0,2,3,3,4] #ihello\n",
    "\n",
    "\n",
    "X = Variable(torch.tensor(x_one_hot)).float()\n",
    "Y = Variable(torch.tensor(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, input_dim, num_classes, sequence_length, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        #RNN parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = 0.1\n",
    "        self._build_net()\n",
    "    \n",
    "    def _build_net(self):\n",
    "        #Batch_first: the input data shape will be (batch_size, seq_length, input_dim)\n",
    "        #otherwise, (seq_length, batch_size, input_dim)\n",
    "        self.rnn1 = nn.RNN(input_size = self.input_dim, hidden_size = self.hidden_size, \n",
    "                        num_layers = self.num_layers, batch_first = True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.num_classes)\n",
    "        \n",
    "        #cost definition & optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = self.lr)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Inputs for nn.RNN: input_data & h_0\n",
    "        #h_0: tensor containing the initial hidden state for each element in the batch\n",
    "        #+ Defaluts to zero if not provided\n",
    "        #reshape input\n",
    "        x.view(x.size(0), self.sequence_length, self.input_dim)\n",
    "        outputs, _ = self.rnn1(x)\n",
    "        #Reshape output from (batch_size, seq_length, input_dim) to (batch*seq_lenght, hidden_size)\n",
    "        outputs = outputs.view(-1, self.hidden_size)\n",
    "        outputs = self.fc(outputs)\n",
    "        return outputs\n",
    "        \n",
    "    def train_(self,train_X, train_Y):\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.forward(train_X)\n",
    "        self.cost = self.criterion(outputs, train_Y)\n",
    "        self.cost.backward()\n",
    "        self.optimizer.step()\n",
    "        return self.cost, outputs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN parameters\n",
    "hidden_size = 5\n",
    "input_dim = 5\n",
    "batch_size = 1 #one sentence\n",
    "sequence_length = 6\n",
    "num_classes = 5\n",
    "\n",
    "model = RNN(hidden_size, input_dim, num_classes, sequence_length, 1)\n",
    "\n",
    "epochs = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.05341649055480957\n",
      "Predicted String:  ihello\n",
      "epoch: 2, loss: 0.041533470153808594\n",
      "Predicted String:  ihello\n",
      "epoch: 3, loss: 0.03344957157969475\n",
      "Predicted String:  ihello\n",
      "epoch: 4, loss: 0.027612289413809776\n",
      "Predicted String:  ihello\n",
      "epoch: 5, loss: 0.02317102812230587\n",
      "Predicted String:  ihello\n",
      "epoch: 6, loss: 0.019658884033560753\n",
      "Predicted String:  ihello\n",
      "epoch: 7, loss: 0.016809701919555664\n",
      "Predicted String:  ihello\n",
      "epoch: 8, loss: 0.014463345520198345\n",
      "Predicted String:  ihello\n",
      "epoch: 9, loss: 0.012513796798884869\n",
      "Predicted String:  ihello\n",
      "epoch: 10, loss: 0.010885079391300678\n",
      "Predicted String:  ihello\n",
      "epoch: 11, loss: 0.009519259445369244\n",
      "Predicted String:  ihello\n",
      "epoch: 12, loss: 0.008370240218937397\n",
      "Predicted String:  ihello\n",
      "epoch: 13, loss: 0.0074005126953125\n",
      "Predicted String:  ihello\n",
      "epoch: 14, loss: 0.00657963752746582\n",
      "Predicted String:  ihello\n",
      "epoch: 15, loss: 0.005882898811250925\n",
      "Predicted String:  ihello\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    cost, outputs = model.train_(X,Y)\n",
    "    one_hot = outputs.argmax(1)\n",
    "    result_str = [idx2char[c] for c in one_hot]\n",
    "    print('epoch: {}, loss: {}'.format(epoch, cost))\n",
    "    print('Predicted String: ',''.join(result_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
