{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression _ tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "#tf.Variable: tensorflow가 학습하는 과정에서 스스로 변경하는 값\n",
    "#그 값의 shape을 결정해줘야 하는데 보통 random한 값을 주는 것\n",
    "#[1]은 rank가 1인 shape을 정의하는 것\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#가설 정의\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost 정의\n",
    "#tf.reduce_mean: 특정 차원을 제거하고 평균을 구한다!\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent를 0.01 learning rate로 실행하는 optimizer 만들기\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)  #optimizer를 통해 cost 최소화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.881123 [-1.0463816] [1.4301822]\n",
      "20 0.58134955 [0.06837] [1.8110436]\n",
      "40 0.45189527 [0.20914163] [1.7685964]\n",
      "60 0.40972862 [0.25554422] [1.6895416]\n",
      "80 0.37211594 [0.29141024] [1.6105263]\n",
      "100 0.33796158 [0.32479507] [1.5348744]\n",
      "120 0.30694214 [0.3565351] [1.4627445]\n",
      "140 0.27876973 [0.38677636] [1.3940011]\n",
      "160 0.2531832 [0.41559574] [1.3284882]\n",
      "180 0.22994506 [0.4430606] [1.2660542]\n",
      "200 0.20883976 [0.46923468] [1.2065543]\n",
      "220 0.18967168 [0.49417865] [1.1498508]\n",
      "240 0.17226285 [0.51795036] [1.0958122]\n",
      "260 0.15645182 [0.5406049] [1.044313]\n",
      "280 0.14209212 [0.5621947] [0.9952342]\n",
      "300 0.12905033 [0.58277] [0.94846183]\n",
      "320 0.11720557 [0.60237825] [0.9038876]\n",
      "340 0.10644797 [0.62106514] [0.86140823]\n",
      "360 0.09667777 [0.63887364] [0.8209251]\n",
      "380 0.08780428 [0.6558452] [0.78234464]\n",
      "400 0.07974521 [0.6720193] [0.7455772]\n",
      "420 0.072425894 [0.6874332] [0.71053773]\n",
      "440 0.06577832 [0.70212275] [0.6771452]\n",
      "460 0.059740946 [0.7161219] [0.64532185]\n",
      "480 0.05425768 [0.7294631] [0.6149941]\n",
      "500 0.04927766 [0.7421773] [0.5860915]\n",
      "520 0.04475479 [0.7542941] [0.5585473]\n",
      "540 0.040647008 [0.7658413] [0.5322977]\n",
      "560 0.03691625 [0.77684593] [0.5072816]\n",
      "580 0.03352795 [0.78733337] [0.4834412]\n",
      "600 0.030450596 [0.79732794] [0.46072122]\n",
      "620 0.027655736 [0.80685276] [0.43906903]\n",
      "640 0.025117358 [0.81593] [0.4184344]\n",
      "660 0.022812 [0.8245806] [0.39876956]\n",
      "680 0.02071823 [0.83282465] [0.38002887]\n",
      "700 0.01881663 [0.84068125] [0.36216894]\n",
      "720 0.017089568 [0.84816873] [0.3451483]\n",
      "740 0.01552102 [0.8553042] [0.3289276]\n",
      "760 0.014096444 [0.86210436] [0.3134692]\n",
      "780 0.012802609 [0.86858493] [0.29873732]\n",
      "800 0.011627539 [0.874761] [0.28469774]\n",
      "820 0.010560294 [0.88064677] [0.27131796]\n",
      "840 0.009591039 [0.8862559] [0.258567]\n",
      "860 0.008710722 [0.8916015] [0.24641526]\n",
      "880 0.007911238 [0.8966958] [0.23483467]\n",
      "900 0.0071851 [0.90155077] [0.2237983]\n",
      "920 0.006525626 [0.90617746] [0.21328062]\n",
      "940 0.00592668 [0.91058683] [0.20325717]\n",
      "960 0.0053826985 [0.9147889] [0.1937048]\n",
      "980 0.004888663 [0.91879356] [0.1846014]\n",
      "1000 0.004439955 [0.9226099] [0.17592579]\n",
      "1020 0.004032438 [0.92624694] [0.16765796]\n",
      "1040 0.0036623264 [0.9297131] [0.15977868]\n",
      "1060 0.003326188 [0.9330163] [0.15226969]\n",
      "1080 0.0030208963 [0.9361643] [0.14511354]\n",
      "1100 0.0027436295 [0.93916434] [0.13829374]\n",
      "1120 0.0024917994 [0.94202346] [0.13179444]\n",
      "1140 0.0022630936 [0.94474816] [0.12560058]\n",
      "1160 0.0020553763 [0.9473447] [0.11969779]\n",
      "1180 0.0018667256 [0.9498193] [0.11407248]\n",
      "1200 0.0016953902 [0.9521776] [0.10871148]\n",
      "1220 0.0015397818 [0.9544251] [0.10360243]\n",
      "1240 0.0013984554 [0.95656693] [0.09873352]\n",
      "1260 0.001270102 [0.95860815] [0.09409343]\n",
      "1280 0.0011535207 [0.96055347] [0.08967137]\n",
      "1300 0.0010476521 [0.9624073] [0.08545712]\n",
      "1320 0.0009514899 [0.9641739] [0.08144095]\n",
      "1340 0.00086415984 [0.9658577] [0.07761352]\n",
      "1360 0.0007848435 [0.96746224] [0.07396595]\n",
      "1380 0.00071280677 [0.96899146] [0.07048985]\n",
      "1400 0.0006473795 [0.9704488] [0.06717701]\n",
      "1420 0.0005879593 [0.9718376] [0.06401991]\n",
      "1440 0.0005339958 [0.97316104] [0.06101121]\n",
      "1460 0.0004849834 [0.97442245] [0.05814391]\n",
      "1480 0.00044047183 [0.97562444] [0.05541134]\n",
      "1500 0.0004000416 [0.97677] [0.05280722]\n",
      "1520 0.0003633251 [0.9778617] [0.05032549]\n",
      "1540 0.00032997897 [0.9789021] [0.04796039]\n",
      "1560 0.00029969055 [0.97989386] [0.04570638]\n",
      "1580 0.00027218254 [0.9808387] [0.04355827]\n",
      "1600 0.00024720098 [0.9817392] [0.04151114]\n",
      "1620 0.00022451168 [0.98259735] [0.03956028]\n",
      "1640 0.00020390401 [0.98341525] [0.0377011]\n",
      "1660 0.00018519028 [0.9841947] [0.03592928]\n",
      "1680 0.00016819204 [0.9849374] [0.03424075]\n",
      "1700 0.00015275391 [0.98564535] [0.03263154]\n",
      "1720 0.00013873591 [0.9863199] [0.03109798]\n",
      "1740 0.00012600051 [0.9869628] [0.02963652]\n",
      "1760 0.000114436574 [0.98757553] [0.02824374]\n",
      "1780 0.00010393248 [0.9881594] [0.02691639]\n",
      "1800 9.439344e-05 [0.9887158] [0.02565143]\n",
      "1820 8.572934e-05 [0.9892462] [0.02444593]\n",
      "1840 7.786108e-05 [0.98975146] [0.02329709]\n",
      "1860 7.071562e-05 [0.9902333] [0.02220223]\n",
      "1880 6.422342e-05 [0.99069226] [0.02115875]\n",
      "1900 5.832993e-05 [0.99112964] [0.02016436]\n",
      "1920 5.2976637e-05 [0.9915465] [0.01921673]\n",
      "1940 4.811342e-05 [0.9919438] [0.01831362]\n",
      "1960 4.3698412e-05 [0.9923224] [0.01745298]\n",
      "1980 3.968636e-05 [0.99268323] [0.01663273]\n",
      "2000 3.604451e-05 [0.9930271] [0.01585107]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step %20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholder를 사용해서 LR해보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None])  #여기서 shape: 1차원 array, 안의 갯수는 자유\n",
    "Y = tf.placeholder(tf.float32, shape = [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = X*W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2100917 [0.999943] [0.00012929]\n",
      "20 0.16588227 [1.2631276] [0.1450575]\n",
      "40 0.14484802 [1.2470838] [0.20792668]\n",
      "60 0.12649687 [1.2309074] [0.26635072]\n",
      "80 0.11047063 [1.215785] [0.32094714]\n",
      "100 0.09647478 [1.2016531] [0.37196794]\n",
      "120 0.084252246 [1.1884468] [0.41964728]\n",
      "140 0.07357808 [1.1761053] [0.46420404]\n",
      "160 0.06425623 [1.164572] [0.50584286]\n",
      "180 0.05611552 [1.153794] [0.5447546]\n",
      "200 0.04900607 [1.1437218] [0.5811181]\n",
      "220 0.042797368 [1.1343095] [0.61510015]\n",
      "240 0.03737528 [1.1255134] [0.64685655]\n",
      "260 0.03264005 [1.1172935] [0.67653346]\n",
      "280 0.028504808 [1.1096117] [0.7042666]\n",
      "300 0.024893478 [1.1024332] [0.7301833]\n",
      "320 0.02173968 [1.0957248] [0.754403]\n",
      "340 0.018985402 [1.0894557] [0.77703637]\n",
      "360 0.016580116 [1.0835972] [0.79818755]\n",
      "380 0.0144795105 [1.0781224] [0.8179535]\n",
      "400 0.012645071 [1.073006] [0.83642495]\n",
      "420 0.011043052 [1.0682248] [0.8536867]\n",
      "440 0.009643963 [1.0637567] [0.8698179]\n",
      "460 0.008422159 [1.0595813] [0.88489276]\n",
      "480 0.0073551326 [1.0556792] [0.8989802]\n",
      "500 0.0064232857 [1.0520327] [0.91214514]\n",
      "520 0.005609499 [1.048625] [0.9244481]\n",
      "540 0.0048988042 [1.0454406] [0.9359453]\n",
      "560 0.004278162 [1.0424645] [0.9466894]\n",
      "580 0.0037361414 [1.0396835] [0.9567299]\n",
      "600 0.0032628097 [1.0370846] [0.96611273]\n",
      "620 0.0028494282 [1.0346559] [0.97488123]\n",
      "640 0.002488427 [1.0323862] [0.9830753]\n",
      "660 0.0021731672 [1.0302653] [0.9907327]\n",
      "680 0.0018978458 [1.0282831] [0.9978887]\n",
      "700 0.0016574044 [1.026431] [1.0045761]\n",
      "720 0.0014474193 [1.0246999] [1.0108254]\n",
      "740 0.0012640437 [1.0230823] [1.0166656]\n",
      "760 0.0011038885 [1.0215706] [1.0221235]\n",
      "780 0.00096403575 [1.0201578] [1.0272236]\n",
      "800 0.0008418959 [1.0188376] [1.0319899]\n",
      "820 0.00073523226 [1.017604] [1.0364441]\n",
      "840 0.0006420836 [1.0164511] [1.0406061]\n",
      "860 0.00056074234 [1.0153737] [1.0444958]\n",
      "880 0.0004897056 [1.0143669] [1.0481308]\n",
      "900 0.00042765765 [1.0134261] [1.0515276]\n",
      "920 0.00037348288 [1.0125469] [1.0547019]\n",
      "940 0.00032616514 [1.0117251] [1.0576686]\n",
      "960 0.00028484044 [1.0109572] [1.0604409]\n",
      "980 0.00024875422 [1.0102396] [1.0630317]\n",
      "1000 0.00021724086 [1.009569] [1.0654526]\n",
      "1020 0.00018972157 [1.0089424] [1.067715]\n",
      "1040 0.00016568477 [1.0083568] [1.0698292]\n",
      "1060 0.00014469556 [1.0078095] [1.0718052]\n",
      "1080 0.00012636073 [1.007298] [1.0736518]\n",
      "1100 0.00011035464 [1.0068201] [1.0753772]\n",
      "1120 9.637184e-05 [1.0063734] [1.0769899]\n",
      "1140 8.41618e-05 [1.0059559] [1.0784968]\n",
      "1160 7.349354e-05 [1.0055658] [1.0799059]\n",
      "1180 6.4182925e-05 [1.0052012] [1.0812217]\n",
      "1200 5.6052657e-05 [1.0048606] [1.0824516]\n",
      "1220 4.895071e-05 [1.0045422] [1.0836008]\n",
      "1240 4.2748226e-05 [1.0042448] [1.084675]\n",
      "1260 3.73319e-05 [1.0039668] [1.0856786]\n",
      "1280 3.2602842e-05 [1.003707] [1.0866164]\n",
      "1300 2.8471917e-05 [1.0034642] [1.0874928]\n",
      "1320 2.4864892e-05 [1.0032374] [1.088312]\n",
      "1340 2.1716109e-05 [1.0030254] [1.0890772]\n",
      "1360 1.8966819e-05 [1.0028274] [1.0897921]\n",
      "1380 1.6562646e-05 [1.0026422] [1.0904608]\n",
      "1400 1.4463556e-05 [1.0024692] [1.0910857]\n",
      "1420 1.2631074e-05 [1.0023074] [1.0916694]\n",
      "1440 1.1030936e-05 [1.0021563] [1.0922152]\n",
      "1460 9.632874e-06 [1.0020151] [1.092725]\n",
      "1480 8.412681e-06 [1.0018831] [1.0932013]\n",
      "1500 7.34793e-06 [1.0017599] [1.0936464]\n",
      "1520 6.4164515e-06 [1.0016446] [1.0940626]\n",
      "1540 5.6035215e-06 [1.0015368] [1.0944514]\n",
      "1560 4.893657e-06 [1.0014362] [1.0948149]\n",
      "1580 4.273504e-06 [1.0013422] [1.0951546]\n",
      "1600 3.7314744e-06 [1.0012542] [1.095472]\n",
      "1620 3.259067e-06 [1.0011721] [1.0957685]\n",
      "1640 2.8463448e-06 [1.0010954] [1.0960455]\n",
      "1660 2.4855794e-06 [1.0010237] [1.0963045]\n",
      "1680 2.170779e-06 [1.0009567] [1.0965465]\n",
      "1700 1.895711e-06 [1.000894] [1.0967727]\n",
      "1720 1.6557408e-06 [1.0008355] [1.0969839]\n",
      "1740 1.4463978e-06 [1.0007808] [1.0971812]\n",
      "1760 1.2630317e-06 [1.0007297] [1.0973657]\n",
      "1780 1.1032009e-06 [1.0006819] [1.0975381]\n",
      "1800 9.634065e-07 [1.0006374] [1.0976993]\n",
      "1820 8.4147104e-07 [1.0005957] [1.0978498]\n",
      "1840 7.34664e-07 [1.0005566] [1.0979908]\n",
      "1860 6.417114e-07 [1.0005201] [1.0981222]\n",
      "1880 5.605175e-07 [1.0004861] [1.0982451]\n",
      "1900 4.894622e-07 [1.0004543] [1.0983601]\n",
      "1920 4.2749608e-07 [1.0004246] [1.0984674]\n",
      "1940 3.7333194e-07 [1.0003968] [1.0985676]\n",
      "1960 3.2631084e-07 [1.0003707] [1.0986612]\n",
      "1980 2.8496902e-07 [1.0003467] [1.0987488]\n",
      "2000 2.4888877e-07 [1.0003239] [1.0988306]\n"
     ]
    }
   ],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val,_= sess.run([cost, W, b, train],\n",
    "                                        feed_dict = {X:[1,2,3,4,5],Y:[2.1,3.1,4.1,5.1,6.1]})\n",
    "    if step %20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1000085]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X:[5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5999942]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X:[2.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5999885 4.099997  6.1000085]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypothesis, feed_dict = {X:[1.5, 3,5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression _ pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, Module, MSELoss\n",
    "from torch.optim import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor([1,2,3])\n",
    "y_train = torch.tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "hypothesis = W*x_train + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (hypothesis - y_train).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.linear\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "output_dim = 1\n",
    "\n",
    "model = LinearRegressionModel(input_dim, output_dim)\n",
    "\n",
    "criterion = MSELoss()\n",
    "l_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = l_rate)\n",
    "\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-a9301504dee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "    inputs = Variable(torch(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    ouptuts = model.forward(inputs)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.forward(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "\n",
    "plt.plot(x_train, y_train, 'go',labe = 'from data', alpha = .5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
