{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main topics: Learning rate, data preprocessing, overfitting, Learning and test data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Learning Rate\n",
    "<img src=\"learning.png\">\n",
    "출처: https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html\n",
    "#### Big learning rate: overshooting \n",
    "- 밖으로 튕겨 나갈 수도 있다.\n",
    "\n",
    "#### Small learning rate: takes too long, stops at local minimum\n",
    "\n",
    "### Solution: Try several learning rates\n",
    "- observe the cost function\n",
    "- Check it goes down in reasonable rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing for gradient descent\n",
    "같은 class의 data가 어떤 것은 차이가 크게 날 경우\n",
    "- 이상적인 등고선이 안 나올 수 있다.\n",
    "- 이럴 경우, 좋은 learning rate에도 등고선의 폭의 좁아서 좋은 결과가 나오지 않을 수 있다.\n",
    "\n",
    "### Solution: nomalization(/standardization) | zero-centered data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overfitting\n",
    "- When our model is very good with training data set ( with memorization)\n",
    "- But not good at test dataset or in real use\n",
    "\n",
    "## solution for overfitting\n",
    "- More trainin data!\n",
    "- Reduce the number of features (중복된 것들을 줄이기 등)\n",
    "- Regularization (일반화)\n",
    "\n",
    "#### Regularization\n",
    "- Let's not have too big numbers in the weight\n",
    "- overfitting이란 decision boundary를 특정 데이터에 맞게 구부린 것.\n",
    "- 구부린다는 것은 값의 weight가 너무 클 경우 발생한다. \n",
    "- 이를 위해 cost함수에 (람다(regularization strength) * sum of squared weights) 를 추가한다. \n",
    "- regularization strength: 값이 0에 가까우면 regularization을 쓰지 않겠다. 1에 가까우면 regularization을 중시한다는 것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training, validation and test sets\n",
    "<img src=\"validation.png\">\n",
    "(출처:\n",
    "\n",
    "- training set을 다시 training과 validation으로 나눈다.\n",
    "- training set으로 모델을 학습 시키고, validation set을 통해 적절한 learning rate와 regularization strength을 찾는다. (일종의 모의고사)\n",
    "- 이후, test set으로 검증 (실전)\n",
    "\n",
    "### Online learning\n",
    "data set이 너무 많은 경우, 한꺼번에 학습시키기 어려울 수 있다.\n",
    "- 대신 data를 n개로 잘라서 차례로 model을 추가로 학습시킨다.\n",
    "- 이는 data가 계속 쌓일 경우 효율적이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7-1\n",
    "\n",
    "## Training and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divde dataset\n",
    "x_train = [[1,2,1],[1,3,2],[1,3,4],[1,5,5],[1,7,5],[1,2,5],[1,6,6],[1,7,7]]\n",
    "y_train = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "x_test = [[2,1,1],[3,1,2],[3,3,4]]\n",
    "y_test = [[0,0,1],[0,0,1],[0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = len(x_train[0])\n",
    "y_dim = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.placeholder('float',[None, x_dim])\n",
    "# Y = tf.placeholder('float', [None, y_dim])\n",
    "# W = tf.Variable(tf.random_normal([x_dim, y_dim]))\n",
    "# b = tf.Variable(tf.random_normal([y_dim]))\n",
    "\n",
    "X = tf.placeholder('float',[None, 3])\n",
    "Y = tf.placeholder('float', [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.2495584 \n",
      " [[ 0.46148756 -1.5410167   0.42855257]\n",
      " [ 1.6138189  -0.51178074  1.2576936 ]\n",
      " [-0.62386644  0.45392382 -0.4923103 ]]\n",
      "1 3.0638208 \n",
      " [[ 0.41078904 -1.5065776   0.44481197]\n",
      " [ 1.4235234  -0.34313828  1.2793467 ]\n",
      " [-0.79945576  0.6265803  -0.48937744]]\n",
      "2 2.1530833 \n",
      " [[ 0.40070084 -1.4786539   0.4269765 ]\n",
      " [ 1.4337355  -0.18961741  1.1156137 ]\n",
      " [-0.7733957   0.76799774 -0.65685487]]\n",
      "3 1.5546994 \n",
      " [[ 0.36402065 -1.4605469   0.44554967]\n",
      " [ 1.29361    -0.07129508  1.1374168 ]\n",
      " [-0.8825407   0.861431   -0.64114314]]\n",
      "4 1.3095107 \n",
      " [[ 0.36015865 -1.462024    0.45088872]\n",
      " [ 1.3290694  -0.05706812  1.0877304 ]\n",
      " [-0.82483035  0.8467057  -0.68412817]]\n",
      "5 1.2677867 \n",
      " [[ 0.34489083 -1.4629285   0.4670611 ]\n",
      " [ 1.3024067  -0.03949707  1.096822  ]\n",
      " [-0.8222706   0.8352551  -0.67523736]]\n",
      "6 1.2499336 \n",
      " [[ 0.33376136 -1.4648843   0.48014632]\n",
      " [ 1.2974268  -0.02817526  1.09048   ]\n",
      " [-0.8005109   0.81781596 -0.6795579 ]]\n",
      "7 1.2348511 \n",
      " [[ 0.32126385 -1.4659119   0.49367136]\n",
      " [ 1.284366   -0.01190217  1.0872678 ]\n",
      " [-0.7866255   0.8056002  -0.68122756]]\n",
      "8 1.220352 \n",
      " [[ 0.30954435 -1.4673285   0.5068075 ]\n",
      " [ 1.274924    0.00198381  1.0828236 ]\n",
      " [-0.7697551   0.7912148  -0.6837126 ]]\n",
      "9 1.2062263 \n",
      " [[ 0.29768956 -1.4685427   0.5198765 ]\n",
      " [ 1.2641364   0.01676682  1.0788282 ]\n",
      " [-0.75452584  0.7779797  -0.68570673]]\n",
      "10 1.1924372 \n",
      " [[ 0.28609693 -1.4698203   0.5327467 ]\n",
      " [ 1.2541828   0.03096354  1.0745851 ]\n",
      " [-0.7389028   0.7644044  -0.6877545 ]]\n",
      "11 1.1789736 \n",
      " [[ 0.27458504 -1.4710397   0.545478  ]\n",
      " [ 1.2440884   0.0452435   1.0703996 ]\n",
      " [-0.7237967   0.75117105 -0.68962723]]\n",
      "12 1.1658297 \n",
      " [[ 0.26323304 -1.4722565   0.55804694]\n",
      " [ 1.2342987   0.05929145  1.0661415 ]\n",
      " [-0.70879     0.7379679  -0.69143075]]\n",
      "13 1.1530002 \n",
      " [[ 0.25200018 -1.4734441   0.57046735]\n",
      " [ 1.2246066   0.07325065  1.0618743 ]\n",
      " [-0.6940762   0.724946   -0.69312274]]\n",
      "14 1.1404809 \n",
      " [[ 0.24090174 -1.4746145   0.5827362 ]\n",
      " [ 1.2151108   0.08704703  1.0575738 ]\n",
      " [-0.6795623   0.71203727 -0.6947279 ]]\n",
      "15 1.1282665 \n",
      " [[ 0.22992617 -1.4757609   0.5948582 ]\n",
      " [ 1.2057638   0.10071144  1.0532564 ]\n",
      " [-0.6652922   0.69927937 -0.69624007]]\n",
      "16 1.1163526 \n",
      " [[ 0.21907495 -1.4768862   0.60683465]\n",
      " [ 1.1965895   0.11422301  1.0489191 ]\n",
      " [-0.6512432   0.6866579  -0.6976676 ]]\n",
      "17 1.1047344 \n",
      " [[ 0.20834303 -1.477988    0.61866844]\n",
      " [ 1.1875763   0.12758689  1.0445684 ]\n",
      " [-0.63742554  0.6741846  -0.699012  ]]\n",
      "18 1.0934074 \n",
      " [[ 0.1977286  -1.4790668   0.6303617 ]\n",
      " [ 1.1787306   0.140795    1.040206  ]\n",
      " [-0.62383276  0.6618579  -0.700278  ]]\n",
      "19 1.082367 \n",
      " [[ 0.1872282  -1.4801217   0.64191693]\n",
      " [ 1.1700497   0.15384614  1.0358357 ]\n",
      " [-0.610467    0.649683   -0.7014688 ]]\n",
      "20 1.0716081 \n",
      " [[ 0.17683922 -1.4811523   0.65333647]\n",
      " [ 1.1615355   0.16673563  1.0314604 ]\n",
      " [-0.5973259   0.6376616  -0.7025885 ]]\n",
      "21 1.0611267 \n",
      " [[ 0.16655856 -1.482158    0.6646228 ]\n",
      " [ 1.1531874   0.1794607   1.0270834 ]\n",
      " [-0.58440953  0.6257971  -0.7036404 ]]\n",
      "22 1.0509177 \n",
      " [[ 0.15638345 -1.4831382   0.67577815]\n",
      " [ 1.1450064   0.19201757  1.0227075 ]\n",
      " [-0.57171637  0.6140919  -0.70462835]]\n",
      "23 1.040977 \n",
      " [[ 0.14631096 -1.4840926   0.686805  ]\n",
      " [ 1.1369923   0.20440334  1.0183358 ]\n",
      " [-0.5592459   0.60254884 -0.7055558 ]]\n",
      "24 1.0312996 \n",
      " [[ 0.1363383  -1.4850206   0.6977057 ]\n",
      " [ 1.1291459   0.21661466  1.013971  ]\n",
      " [-0.54699683  0.5911704  -0.7064264 ]]\n",
      "25 1.0218809 \n",
      " [[ 0.1264626  -1.4859219   0.70848256]\n",
      " [ 1.1214669   0.22864877  1.0096159 ]\n",
      " [-0.5349685   0.5799591  -0.7072435 ]]\n",
      "26 1.0127163 \n",
      " [[ 0.11668116 -1.4867958   0.7191379 ]\n",
      " [ 1.1139557   0.24050258  1.0052732 ]\n",
      " [-0.5231595   0.5689171  -0.70801055]]\n",
      "27 1.0038011 \n",
      " [[ 0.10699125 -1.4876419   0.729674  ]\n",
      " [ 1.1066126   0.2521736   1.0009454 ]\n",
      " [-0.5115689   0.55804676 -0.7087309 ]]\n",
      "28 0.9951303 \n",
      " [[ 0.0973902  -1.48846     0.74009305]\n",
      " [ 1.0994374   0.26365924  0.9966351 ]\n",
      " [-0.5001954   0.54735005 -0.7094077 ]]\n",
      "29 0.98669946 \n",
      " [[ 0.08787544 -1.4892495   0.7503973 ]\n",
      " [ 1.0924301   0.27495718  0.99234444]\n",
      " [-0.48903772  0.5368288  -0.71004415]]\n",
      "30 0.97850347 \n",
      " [[ 0.0784444  -1.49001     0.760589  ]\n",
      " [ 1.0855906   0.28606525  0.9880759 ]\n",
      " [-0.47809455  0.5264847  -0.71064323]]\n",
      "31 0.97053754 \n",
      " [[ 0.06909463 -1.4907415   0.7706702 ]\n",
      " [ 1.0789187   0.2969816   0.98383147]\n",
      " [-0.46736434  0.5163194  -0.71120805]]\n",
      "32 0.96279675 \n",
      " [[ 0.05982372 -1.4914434   0.780643  ]\n",
      " [ 1.072414    0.30770445  0.9796132 ]\n",
      " [-0.45684555  0.506334   -0.71174145]]\n",
      "33 0.955276 \n",
      " [[ 0.05062933 -1.4921156   0.7905096 ]\n",
      " [ 1.0660762   0.31823236  0.9754231 ]\n",
      " [-0.4465366   0.4965297  -0.7122461 ]]\n",
      "34 0.9479703 \n",
      " [[ 0.04150922 -1.4927578   0.8002719 ]\n",
      " [ 1.0599046   0.32856408  0.97126293]\n",
      " [-0.4364356   0.4869074  -0.7127248 ]]\n",
      "35 0.9408743 \n",
      " [[ 0.03246119 -1.4933699   0.80993205]\n",
      " [ 1.0538985   0.3386987   0.9671344 ]\n",
      " [-0.42654085  0.47746786 -0.71318   ]]\n",
      "36 0.9339833 \n",
      " [[ 0.02348316 -1.4939518   0.8194919 ]\n",
      " [ 1.0480572   0.34863532  0.9630391 ]\n",
      " [-0.41685015  0.46821144 -0.7136143 ]]\n",
      "37 0.92729175 \n",
      " [[ 0.01457306 -1.4945033   0.82895344]\n",
      " [ 1.0423795   0.35837358  0.95897853]\n",
      " [-0.40736163  0.45913848 -0.71402985]]\n",
      "38 0.9207946 \n",
      " [[ 0.005729   -1.4950242   0.8383185 ]\n",
      " [ 1.0368645   0.36791313  0.95495397]\n",
      " [-0.39807287  0.45024893 -0.7144291 ]]\n",
      "39 0.9144866 \n",
      " [[-0.00305092 -1.4955148   0.84758896]\n",
      " [ 1.0315108   0.37725404  0.9509667 ]\n",
      " [-0.38898164  0.44154266 -0.714814  ]]\n",
      "40 0.9083626 \n",
      " [[-0.01176846 -1.4959749   0.8567666 ]\n",
      " [ 1.0263172   0.3863965   0.94701785]\n",
      " [-0.3800854   0.43301922 -0.7151868 ]]\n",
      "41 0.90241694 \n",
      " [[-0.02042537 -1.4964046   0.8658532 ]\n",
      " [ 1.0212821   0.39534107  0.9431084 ]\n",
      " [-0.37138176  0.42467806 -0.7155493 ]]\n",
      "42 0.89664483 \n",
      " [[-0.02902326 -1.4968041   0.8748505 ]\n",
      " [ 1.0164038   0.4040884   0.9392393 ]\n",
      " [-0.36286798  0.41651827 -0.7159033 ]]\n",
      "43 0.8910408 \n",
      " [[-0.0375637  -1.4971734   0.8837602 ]\n",
      " [ 1.0116805   0.41263956  0.9354115 ]\n",
      " [-0.35454136  0.4085389  -0.71625054]]\n",
      "44 0.8855996 \n",
      " [[-0.04604815 -1.4975127   0.89258397]\n",
      " [ 1.0071104   0.4209956   0.93162555]\n",
      " [-0.3463989   0.40073866 -0.7165928 ]]\n",
      "45 0.88031626 \n",
      " [[-0.05447805 -1.4978223   0.9013234 ]\n",
      " [ 1.0026913   0.42915806  0.9278822 ]\n",
      " [-0.3384378   0.3931162  -0.7169314 ]]\n",
      "46 0.8751855 \n",
      " [[-0.06285471 -1.4981023   0.90998006]\n",
      " [ 0.99842113  0.4371285   0.9241819 ]\n",
      " [-0.33065495  0.38566992 -0.71726793]]\n",
      "47 0.87020206 \n",
      " [[-0.07117943 -1.498353    0.9185555 ]\n",
      " [ 0.9942976   0.4449088   0.9205251 ]\n",
      " [-0.32304728  0.37839803 -0.71760374]]\n",
      "48 0.86536133 \n",
      " [[-0.07945341 -1.4985749   0.9270513 ]\n",
      " [ 0.99031836  0.4525009   0.91691226]\n",
      " [-0.3156116   0.3712986  -0.71794   ]]\n",
      "49 0.86065817 \n",
      " [[-0.08767777 -1.4987681   0.93546885]\n",
      " [ 0.98648095  0.45990703  0.9133436 ]\n",
      " [-0.3083446   0.3643696  -0.71827793]]\n",
      "50 0.8560875 \n",
      " [[-0.09585361 -1.4989331   0.9438096 ]\n",
      " [ 0.9827827   0.4671295   0.90981936]\n",
      " [-0.30124307  0.3576088  -0.7186187 ]]\n",
      "51 0.8516449 \n",
      " [[-0.10398195 -1.4990702   0.952075  ]\n",
      " [ 0.9792211   0.4741708   0.9063397 ]\n",
      " [-0.29430357  0.35101384 -0.7189632 ]]\n",
      "52 0.8473257 \n",
      " [[-0.11206375 -1.4991797   0.9602664 ]\n",
      " [ 0.9757933   0.48103362  0.9029047 ]\n",
      " [-0.28752276  0.34458232 -0.7193125 ]]\n",
      "53 0.8431251 \n",
      " [[-0.12009992 -1.4992623   0.96838516]\n",
      " [ 0.9724967   0.48772064  0.8995143 ]\n",
      " [-0.2808971   0.33831155 -0.7196674 ]]\n",
      "54 0.83903885 \n",
      " [[-0.12809137 -1.4993182   0.97643256]\n",
      " [ 0.96932817  0.4942349   0.8961686 ]\n",
      " [-0.27442333  0.3321991  -0.72002864]]\n",
      "55 0.83506256 \n",
      " [[-0.13603885 -1.499348    0.98440987]\n",
      " [ 0.9662851   0.5005791   0.89286745]\n",
      " [-0.26809776  0.32624194 -0.72039706]]\n",
      "56 0.831192 \n",
      " [[-0.14394318 -1.4993522   0.9923184 ]\n",
      " [ 0.9633644   0.5067566   0.88961065]\n",
      " [-0.26191705  0.3204375  -0.7207733 ]]\n",
      "57 0.82742316 \n",
      " [[-0.15180506 -1.4993312   1.0001593 ]\n",
      " [ 0.96056324  0.51277035  0.8863981 ]\n",
      " [-0.2558776   0.31478274 -0.72115797]]\n",
      "58 0.82375205 \n",
      " [[-0.1596252  -1.4992856   1.0079337 ]\n",
      " [ 0.9578785   0.51862365  0.88322955]\n",
      " [-0.24997607  0.30927482 -0.7215516 ]]\n",
      "59 0.8201748 \n",
      " [[-0.16740422 -1.4992158   1.015643  ]\n",
      " [ 0.9553073   0.5243196   0.8801048 ]\n",
      " [-0.24420872  0.30391064 -0.72195476]]\n",
      "60 0.8166877 \n",
      " [[-0.17514278 -1.4991224   1.0232881 ]\n",
      " [ 0.9528465   0.52986175  0.8770234 ]\n",
      " [-0.23857239  0.29868743 -0.7223679 ]]\n",
      "61 0.81328714 \n",
      " [[-0.18284144 -1.4990059   1.0308703 ]\n",
      " [ 0.95049334  0.53525317  0.8739852 ]\n",
      " [-0.23306337  0.29360187 -0.7227913 ]]\n",
      "62 0.8099697 \n",
      " [[-0.19050078 -1.4988668   1.0383905 ]\n",
      " [ 0.94824445  0.5404975   0.8709897 ]\n",
      " [-0.22767851  0.28865117 -0.7232255 ]]\n",
      "63 0.8067323 \n",
      " [[-0.19812128 -1.4987056   1.0458499 ]\n",
      " [ 0.94609725  0.54559773  0.8680366 ]\n",
      " [-0.2224141   0.28383195 -0.72367066]]\n",
      "64 0.80357146 \n",
      " [[-0.20570351 -1.4985229   1.0532495 ]\n",
      " [ 0.9440484   0.5505577   0.86512554]\n",
      " [-0.21726719  0.27914152 -0.7241271 ]]\n",
      "65 0.8004843 \n",
      " [[-0.21324788 -1.4983191   1.0605901 ]\n",
      " [ 0.9420953   0.5553803   0.862256  ]\n",
      " [-0.21223406  0.27457643 -0.7245951 ]]\n",
      "66 0.7974677 \n",
      " [[-0.2207549  -1.4980949   1.067873  ]\n",
      " [ 0.94023466  0.5600693   0.8594276 ]\n",
      " [-0.20731184  0.27013397 -0.7250749 ]]\n",
      "67 0.79451895 \n",
      " [[-0.22822496 -1.4978508   1.075099  ]\n",
      " [ 0.938464    0.56462777  0.85663986]\n",
      " [-0.20249698  0.2658108  -0.72556657]]\n",
      "68 0.7916354 \n",
      " [[-0.23565853 -1.4975872   1.0822691 ]\n",
      " [ 0.93678004  0.5690592   0.8538924 ]\n",
      " [-0.19778663  0.26160416 -0.7260703 ]]\n",
      "69 0.7888144 \n",
      " [[-0.24305594 -1.4973048   1.0893841 ]\n",
      " [ 0.9351803   0.5733667   0.8511846 ]\n",
      " [-0.19317742  0.25751084 -0.72658616]]\n",
      "70 0.78605354 \n",
      " [[-0.25041765 -1.4970039   1.096445  ]\n",
      " [ 0.9336618   0.57755375  0.84851605]\n",
      " [-0.18866652  0.25352812 -0.7271143 ]]\n",
      "71 0.78335035 \n",
      " [[-0.25774395 -1.4966853   1.1034526 ]\n",
      " [ 0.93222207  0.5816233   0.84588623]\n",
      " [-0.18425074  0.24965282 -0.7276548 ]]\n",
      "72 0.7807027 \n",
      " [[-0.26503527 -1.4963492   1.1104078 ]\n",
      " [ 0.9308581   0.58557886  0.8432947 ]\n",
      " [-0.17992744  0.2458823  -0.7282076 ]]\n",
      "73 0.77810836 \n",
      " [[-0.2722919  -1.4959962   1.1173115 ]\n",
      " [ 0.9295676   0.58942324  0.84074086]\n",
      " [-0.17569344  0.24221349 -0.72877276]]\n",
      "74 0.7755653 \n",
      " [[-0.2795142  -1.4956269   1.1241645 ]\n",
      " [ 0.92834777  0.5931597   0.83822423]\n",
      " [-0.17154616  0.23864375 -0.72935027]]\n",
      "75 0.7730715 \n",
      " [[-0.28670248 -1.4952416   1.1309675 ]\n",
      " [ 0.92719615  0.5967912   0.8357443 ]\n",
      " [-0.16748284  0.23517027 -0.7299401 ]]\n",
      "76 0.77062535 \n",
      " [[-0.29385707 -1.494841    1.1377214 ]\n",
      " [ 0.9261104   0.6003207   0.8333006 ]\n",
      " [-0.16350073  0.23179032 -0.73054224]]\n",
      "77 0.76822466 \n",
      " [[-0.30097824 -1.4944253   1.144427  ]\n",
      " [ 0.9250879   0.60375124  0.83089256]\n",
      " [-0.15959734  0.22850133 -0.73115665]]\n",
      "78 0.7658681 \n",
      " [[-0.3080663  -1.4939951   1.1510848 ]\n",
      " [ 0.9241266   0.60708547  0.82851964]\n",
      " [-0.15576999  0.22530054 -0.7317832 ]]\n",
      "79 0.76355386 \n",
      " [[-0.3151216  -1.4935508   1.1576958 ]\n",
      " [ 0.923224    0.6103264   0.8261814 ]\n",
      " [-0.15201639  0.2221856  -0.7324219 ]]\n",
      "80 0.7612804 \n",
      " [[-0.32214433 -1.4930928   1.1642605 ]\n",
      " [ 0.92237794  0.6134766   0.8238773 ]\n",
      " [-0.14833395  0.21915379 -0.7330725 ]]\n",
      "81 0.75904644 \n",
      " [[-0.32913482 -1.4926215   1.1707798 ]\n",
      " [ 0.9215862   0.6165389   0.82160676]\n",
      " [-0.14472054  0.21620291 -0.733735  ]]\n",
      "82 0.7568501 \n",
      " [[-0.33609334 -1.4921376   1.1772543 ]\n",
      " [ 0.9208468   0.6195157   0.8193693 ]\n",
      " [-0.1411737   0.21333036 -0.73440933]]\n",
      "83 0.75469077 \n",
      " [[-0.34302014 -1.4916412   1.1836847 ]\n",
      " [ 0.9201576   0.62240976  0.8171645 ]\n",
      " [-0.13769136  0.21053395 -0.73509526]]\n",
      "84 0.7525666 \n",
      " [[-0.3499155  -1.4911327   1.1900716 ]\n",
      " [ 0.9195167   0.6252235   0.8149917 ]\n",
      " [-0.13427134  0.20781137 -0.7357927 ]]\n",
      "85 0.7504766 \n",
      " [[-0.3567797  -1.4906126   1.1964157 ]\n",
      " [ 0.91892207  0.6279594   0.81285053]\n",
      " [-0.13091154  0.2051604  -0.7365015 ]]\n",
      "86 0.74841964 \n",
      " [[-0.36361292 -1.4900813   1.2027175 ]\n",
      " [ 0.9183719   0.6306196   0.8107404 ]\n",
      " [-0.12760991  0.20257878 -0.73722154]]\n",
      "87 0.74639446 \n",
      " [[-0.37041548 -1.4895391   1.2089779 ]\n",
      " [ 0.9178644   0.63320667  0.8086609 ]\n",
      " [-0.12436458  0.20006455 -0.73795265]]\n",
      "88 0.7444002 \n",
      " [[-0.37718764 -1.4889864   1.2151973 ]\n",
      " [ 0.9173977   0.63572276  0.80661154]\n",
      " [-0.12117363  0.19761561 -0.73869467]]\n",
      "89 0.7424358 \n",
      " [[-0.38392958 -1.4884235   1.2213764 ]\n",
      " [ 0.91697025  0.63816994  0.8045918 ]\n",
      " [-0.11803511  0.19522986 -0.7394474 ]]\n",
      "90 0.7405002 \n",
      " [[-0.39064163 -1.4878507   1.2275157 ]\n",
      " [ 0.9165803   0.64055055  0.80260116]\n",
      " [-0.11494744  0.19290555 -0.7402108 ]]\n",
      "91 0.73859274 \n",
      " [[-0.39732397 -1.4872683   1.2336158 ]\n",
      " [ 0.9162263   0.6428665   0.8006392 ]\n",
      " [-0.11190879  0.19064064 -0.7409845 ]]\n",
      "92 0.73671234 \n",
      " [[-0.40397686 -1.4866768   1.2396772 ]\n",
      " [ 0.9159068   0.6451198   0.79870546]\n",
      " [-0.10891744  0.1884333  -0.7417685 ]]\n",
      "93 0.7348583 \n",
      " [[-0.41060054 -1.4860765   1.2457005 ]\n",
      " [ 0.91562015  0.6473124   0.7967995 ]\n",
      " [-0.1059719   0.1862818  -0.74256253]]\n",
      "94 0.7330296 \n",
      " [[-0.41719526 -1.4854674   1.2516862 ]\n",
      " [ 0.915365    0.6494462   0.79492086]\n",
      " [-0.10307053  0.18418434 -0.7433664 ]]\n",
      "95 0.7312258 \n",
      " [[-0.42376122 -1.4848502   1.2576349 ]\n",
      " [ 0.9151399   0.6515231   0.79306906]\n",
      " [-0.10021187  0.18213932 -0.7441801 ]]\n",
      "96 0.7294462 \n",
      " [[-0.4302987  -1.4842249   1.2635471 ]\n",
      " [ 0.91494364  0.6535448   0.7912437 ]\n",
      " [-0.09739438  0.180145   -0.7450032 ]]\n",
      "97 0.7276897 \n",
      " [[-0.43680787 -1.4835918   1.2694231 ]\n",
      " [ 0.9147748   0.65551305  0.78944427]\n",
      " [-0.09461679  0.17819989 -0.7458357 ]]\n",
      "98 0.72595596 \n",
      " [[-0.443289   -1.4829513   1.2752637 ]\n",
      " [ 0.9146322   0.6574295   0.78767043]\n",
      " [-0.09187762  0.17630236 -0.74667734]]\n",
      "99 0.72424436 \n",
      " [[-0.44974235 -1.4823035   1.2810693 ]\n",
      " [ 0.9145146   0.65929586  0.7859217 ]\n",
      " [-0.0891756   0.17445098 -0.74752796]]\n",
      "100 0.72255415 \n",
      " [[-0.4561681  -1.4816488   1.2868403 ]\n",
      " [ 0.9144209   0.6611136   0.7841976 ]\n",
      " [-0.08650946  0.17264427 -0.7483874 ]]\n",
      "101 0.72088486 \n",
      " [[-0.46256647 -1.4809873   1.2925773 ]\n",
      " [ 0.91435     0.6628843   0.7824979 ]\n",
      " [-0.08387794  0.17088078 -0.7492554 ]]\n",
      "102 0.71923596 \n",
      " [[-0.46893772 -1.4803194   1.2982806 ]\n",
      " [ 0.9143007   0.6646094   0.7808221 ]\n",
      " [-0.08127993  0.1691592  -0.75013185]]\n",
      "103 0.7176068 \n",
      " [[-0.47528207 -1.4796451   1.3039507 ]\n",
      " [ 0.914272    0.66629034  0.77916974]\n",
      " [-0.07871422  0.16747822 -0.75101656]]\n",
      "104 0.71599704 \n",
      " [[-0.48159975 -1.4789648   1.3095881 ]\n",
      " [ 0.914263    0.6679286   0.7775405 ]\n",
      " [-0.07617975  0.16583651 -0.7519093 ]]\n",
      "105 0.7144059 \n",
      " [[-0.48789096 -1.4782786   1.3151932 ]\n",
      " [ 0.91427267  0.6695254   0.77593404]\n",
      " [-0.07367544  0.16423286 -0.75280994]]\n",
      "106 0.7128334 \n",
      " [[-0.4941559  -1.4775869   1.3207663 ]\n",
      " [ 0.91430014  0.6710821   0.77434987]\n",
      " [-0.07120021  0.16266602 -0.7537183 ]]\n",
      "107 0.7112786 \n",
      " [[-0.5003949  -1.4768896   1.326308  ]\n",
      " [ 0.91434443  0.6726      0.7727877 ]\n",
      " [-0.06875318  0.1611349  -0.7546342 ]]\n",
      "108 0.70974123 \n",
      " [[-0.506608   -1.4761871   1.3318187 ]\n",
      " [ 0.91440475  0.6740802   0.7712471 ]\n",
      " [-0.06633331  0.1596383  -0.7555575 ]]\n",
      "109 0.7082211 \n",
      " [[-0.51279557 -1.4754796   1.3372988 ]\n",
      " [ 0.9144803   0.67552394  0.76972777]\n",
      " [-0.06393969  0.15817511 -0.7564879 ]]\n",
      "110 0.7067175 \n",
      " [[-0.51895773 -1.4747672   1.3427485 ]\n",
      " [ 0.9145702   0.6769325   0.7682293 ]\n",
      " [-0.06157153  0.15674444 -0.75742537]]\n",
      "111 0.7052302 \n",
      " [[-0.52509475 -1.4740502   1.3481685 ]\n",
      " [ 0.9146739   0.67830676  0.7667514 ]\n",
      " [-0.05922775  0.15534498 -0.7583697 ]]\n",
      "112 0.70375884 \n",
      " [[-0.53120685 -1.4733286   1.3535589 ]\n",
      " [ 0.9147904   0.679648    0.7652937 ]\n",
      " [-0.0569078   0.15397604 -0.7593207 ]]\n",
      "113 0.7023028 \n",
      " [[-0.53729415 -1.4726026   1.3589202 ]\n",
      " [ 0.9149192   0.680957    0.7638559 ]\n",
      " [-0.05461065  0.15263641 -0.7602782 ]]\n",
      "114 0.7008623 \n",
      " [[-0.54335696 -1.4718724   1.3642528 ]\n",
      " [ 0.9150595   0.682235    0.7624376 ]\n",
      " [-0.05233572  0.15132532 -0.7612421 ]]\n",
      "115 0.69943655 \n",
      " [[-0.54939544 -1.4711382   1.369557  ]\n",
      " [ 0.9152107   0.6834829   0.7610385 ]\n",
      " [-0.05008215  0.1500418  -0.76221216]]\n",
      "116 0.6980254 \n",
      " [[-0.55540985 -1.4704001   1.3748332 ]\n",
      " [ 0.91537225  0.6847016   0.7596582 ]\n",
      " [-0.04784925  0.14878501 -0.76318824]]\n",
      "117 0.69662845 \n",
      " [[-0.56140035 -1.4696581   1.3800818 ]\n",
      " [ 0.9155435   0.68589205  0.75829655]\n",
      " [-0.04563632  0.14755404 -0.76417017]]\n",
      "118 0.6952454 \n",
      " [[-0.56736714 -1.4689126   1.385303  ]\n",
      " [ 0.91572386  0.6870551   0.7569531 ]\n",
      " [-0.04344276  0.14634818 -0.7651579 ]]\n",
      "119 0.693876 \n",
      " [[-0.5733105  -1.4681636   1.3904973 ]\n",
      " [ 0.91591275  0.68819165  0.7556277 ]\n",
      " [-0.04126795  0.14516662 -0.76615113]]\n",
      "120 0.6925201 \n",
      " [[-0.57923055 -1.4674113   1.3956649 ]\n",
      " [ 0.9161098   0.6893024   0.7543199 ]\n",
      " [-0.0391111   0.14400846 -0.7671498 ]]\n",
      "121 0.69117725 \n",
      " [[-0.58512753 -1.4666556   1.4008063 ]\n",
      " [ 0.91631436  0.6903883   0.75302947]\n",
      " [-0.03697184  0.14287315 -0.7681538 ]]\n",
      "122 0.68984723 \n",
      " [[-0.59100163 -1.4658968   1.4059217 ]\n",
      " [ 0.9165261   0.69145     0.7517561 ]\n",
      " [-0.03484941  0.14175983 -0.7691629 ]]\n",
      "123 0.6885299 \n",
      " [[-0.596853   -1.4651351   1.4110113 ]\n",
      " [ 0.9167443   0.6924883   0.7504995 ]\n",
      " [-0.03274344  0.14066793 -0.77017695]]\n",
      "124 0.68722486 \n",
      " [[-0.60268193 -1.4643705   1.4160756 ]\n",
      " [ 0.91696876  0.6935039   0.7492594 ]\n",
      " [-0.03065324  0.13959666 -0.7711959 ]]\n",
      "125 0.68593204 \n",
      " [[-0.60848856 -1.4636031   1.4211148 ]\n",
      " [ 0.917199    0.6944975   0.7480356 ]\n",
      " [-0.02857837  0.13854542 -0.77221954]]\n",
      "126 0.68465096 \n",
      " [[-0.61427313 -1.462833    1.4261292 ]\n",
      " [ 0.9174346   0.69546986  0.7468277 ]\n",
      " [-0.02651839  0.13751367 -0.7732478 ]]\n",
      "127 0.6833816 \n",
      " [[-0.62003577 -1.4620605   1.4311192 ]\n",
      " [ 0.91767514  0.69642144  0.74563557]\n",
      " [-0.02447273  0.13650067 -0.7742804 ]]\n",
      "128 0.6821237 \n",
      " [[-0.6257767  -1.4612854   1.436085  ]\n",
      " [ 0.9179202   0.69735307  0.7444589 ]\n",
      " [-0.02244106  0.13550597 -0.7753174 ]]\n",
      "129 0.68087703 \n",
      " [[-0.63149613 -1.4605079   1.4410269 ]\n",
      " [ 0.9181696   0.69826514  0.7432974 ]\n",
      " [-0.02042271  0.1345288  -0.77635854]]\n",
      "130 0.6796415 \n",
      " [[-0.6371943  -1.4597281   1.4459453 ]\n",
      " [ 0.9184228   0.69915855  0.74215084]\n",
      " [-0.01841757  0.13356891 -0.7774038 ]]\n",
      "131 0.6784166 \n",
      " [[-0.64287126 -1.4589461   1.4508402 ]\n",
      " [ 0.9186797   0.7000335   0.74101895]\n",
      " [-0.01642492  0.13262546 -0.778453  ]]\n",
      "132 0.6772026 \n",
      " [[-0.64852726 -1.4581621   1.4557122 ]\n",
      " [ 0.9189398   0.7008908   0.73990154]\n",
      " [-0.01444461  0.13169818 -0.779506  ]]\n",
      "133 0.67599887 \n",
      " [[-0.6541625  -1.457376    1.4605614 ]\n",
      " [ 0.9192029   0.70173085  0.7387984 ]\n",
      " [-0.01247615  0.13078645 -0.78056276]]\n",
      "134 0.6748056 \n",
      " [[-0.6597772  -1.4565879   1.4653881 ]\n",
      " [ 0.91946864  0.7025543   0.7377092 ]\n",
      " [-0.01051922  0.12988982 -0.78162307]]\n",
      "135 0.67362237 \n",
      " [[-0.6653715  -1.455798    1.4701924 ]\n",
      " [ 0.9197369   0.70336145  0.73663384]\n",
      " [-0.00857335  0.12900776 -0.7826869 ]]\n",
      "136 0.672449 \n",
      " [[-0.6709455  -1.4550062   1.4749748 ]\n",
      " [ 0.92000717  0.70415306  0.735572  ]\n",
      " [-0.00663849  0.12814005 -0.78375405]]\n",
      "137 0.6712854 \n",
      " [[-0.6764995  -1.4542128   1.4797354 ]\n",
      " [ 0.92027956  0.70492923  0.7345235 ]\n",
      " [-0.00471388  0.12728587 -0.7848245 ]]\n",
      "138 0.6701314 \n",
      " [[-0.68203366 -1.4534177   1.4844744 ]\n",
      " [ 0.9205534   0.70569086  0.733488  ]\n",
      " [-0.0027997   0.1264453  -0.7858981 ]]\n",
      "139 0.6689869 \n",
      " [[-6.8754810e-01 -1.4526210e+00  1.4891922e+00]\n",
      " [ 9.2082888e-01  7.0643789e-01  7.3246551e-01]\n",
      " [-8.9516421e-04  1.2561738e-01 -7.8697473e-01]]\n",
      "140 0.6678518 \n",
      " [[-6.9304305e-01 -1.4518228e+00  1.4938890e+00]\n",
      " [ 9.2110544e-01  7.0717120e-01  7.3145568e-01]\n",
      " [ 9.9958701e-04  1.2480224e-01 -7.8805435e-01]]\n",
      "141 0.66672564 \n",
      " [[-0.69851863 -1.4510231   1.498565  ]\n",
      " [ 0.9213832   0.7078908   0.7304583 ]\n",
      " [ 0.00288519  0.12399907 -0.78913677]]\n",
      "142 0.6656085 \n",
      " [[-0.7039751  -1.450222    1.5032203 ]\n",
      " [ 0.9216617   0.7085974   0.72947323]\n",
      " [ 0.00476162  0.12320786 -0.790222  ]]\n",
      "143 0.66450024 \n",
      " [[-0.7094125  -1.4494196   1.5078554 ]\n",
      " [ 0.9219409   0.70929116  0.72850025]\n",
      " [ 0.0066294   0.12242794 -0.79130983]]\n",
      "144 0.66340065 \n",
      " [[-0.7148311  -1.4486159   1.5124704 ]\n",
      " [ 0.9222205   0.7099726   0.7275392 ]\n",
      " [ 0.0084885   0.12165926 -0.79240024]]\n",
      "145 0.66230965 \n",
      " [[-0.720231   -1.447811    1.5170654 ]\n",
      " [ 0.92250055  0.710642    0.72658986]\n",
      " [ 0.01033944  0.12090124 -0.79349315]]\n",
      "146 0.6612271 \n",
      " [[-0.7256124  -1.4470049   1.5216408 ]\n",
      " [ 0.92278063  0.7112997   0.72565204]\n",
      " [ 0.01218223  0.12015375 -0.79458845]]\n",
      "147 0.6601528 \n",
      " [[-0.73097545 -1.4461977   1.5261967 ]\n",
      " [ 0.9230608   0.71194607  0.72472554]\n",
      " [ 0.01401723  0.11941636 -0.79568607]]\n",
      "148 0.6590868 \n",
      " [[-0.7363203  -1.4453895   1.5307333 ]\n",
      " [ 0.9233408   0.7125814   0.7238102 ]\n",
      " [ 0.01584461  0.11868881 -0.7967859 ]]\n",
      "149 0.6580287 \n",
      " [[-0.7416472  -1.4445802   1.5352509 ]\n",
      " [ 0.92362046  0.71320605  0.7229059 ]\n",
      " [ 0.01766451  0.11797084 -0.79788786]]\n",
      "150 0.65697867 \n",
      " [[-0.74695617 -1.4437699   1.5397496 ]\n",
      " [ 0.92389977  0.7138202   0.7220124 ]\n",
      " [ 0.01947726  0.1172621  -0.79899186]]\n",
      "151 0.65593636 \n",
      " [[-0.7522475  -1.4429587   1.5442297 ]\n",
      " [ 0.9241785   0.7144244   0.72112954]\n",
      " [ 0.02128292  0.11656242 -0.8000978 ]]\n",
      "152 0.6549016 \n",
      " [[-0.7575213  -1.4421467   1.5486915 ]\n",
      " [ 0.92445666  0.7150186   0.72025716]\n",
      " [ 0.02308187  0.11587138 -0.8012057 ]]\n",
      "153 0.65387475 \n",
      " [[-0.7627777  -1.4413338   1.553135  ]\n",
      " [ 0.9247339   0.71560335  0.7193951 ]\n",
      " [ 0.02487398  0.11518897 -0.8023154 ]]\n",
      "154 0.65285516 \n",
      " [[-0.7680168  -1.44052     1.5575604 ]\n",
      " [ 0.9250105   0.7161786   0.71854323]\n",
      " [ 0.02665986  0.11451456 -0.80342686]]\n",
      "155 0.65184295 \n",
      " [[-0.7732389  -1.4397056   1.561968  ]\n",
      " [ 0.92528594  0.7167451   0.7177013 ]\n",
      " [ 0.02843916  0.11384843 -0.80454004]]\n",
      "156 0.65083796 \n",
      " [[-0.778444   -1.4388905   1.5663579 ]\n",
      " [ 0.9255605   0.71730256  0.7168693 ]\n",
      " [ 0.03021247  0.11318985 -0.80565476]]\n",
      "157 0.6498402 \n",
      " [[-0.7836323  -1.4380746   1.5707303 ]\n",
      " [ 0.9258337   0.7178517   0.7160469 ]\n",
      " [ 0.03197961  0.112539   -0.80677104]]\n",
      "158 0.6488495 \n",
      " [[-0.78880394 -1.4372581   1.5750854 ]\n",
      " [ 0.9261059   0.7183923   0.71523416]\n",
      " [ 0.03374109  0.11189529 -0.8078888 ]]\n",
      "159 0.6478658 \n",
      " [[-0.7939591  -1.436441    1.5794234 ]\n",
      " [ 0.92637664  0.718925    0.71443075]\n",
      " [ 0.03549666  0.11125888 -0.80900794]]\n",
      "160 0.64688873 \n",
      " [[-0.79909784 -1.4356232   1.5837445 ]\n",
      " [ 0.9266461   0.71944964  0.71363664]\n",
      " [ 0.03724679  0.11062925 -0.81012845]]\n",
      "161 0.64591855 \n",
      " [[-0.80422044 -1.4348049   1.5880488 ]\n",
      " [ 0.926914    0.71996677  0.71285164]\n",
      " [ 0.03899134  0.11000649 -0.81125027]]\n",
      "162 0.6449549 \n",
      " [[-0.80932695 -1.4339861   1.5923365 ]\n",
      " [ 0.9271804   0.7204763   0.71207565]\n",
      " [ 0.04073066  0.10939016 -0.8123733 ]]\n",
      "163 0.643998 \n",
      " [[-0.8144175  -1.4331667   1.5966078 ]\n",
      " [ 0.92744523  0.7209787   0.7113085 ]\n",
      " [ 0.04246472  0.10878024 -0.8134974 ]]\n",
      "164 0.64304745 \n",
      " [[-0.8194922  -1.4323469   1.6008627 ]\n",
      " [ 0.92770845  0.72147393  0.71055   ]\n",
      " [ 0.04419371  0.10817649 -0.81462264]]\n",
      "165 0.6421033 \n",
      " [[-0.8245513  -1.4315268   1.6051016 ]\n",
      " [ 0.92797     0.7219623   0.7098001 ]\n",
      " [ 0.04591778  0.10757872 -0.81574893]]\n",
      "166 0.64116555 \n",
      " [[-0.82959485 -1.4307061   1.6093246 ]\n",
      " [ 0.9282297   0.72244394  0.70905876]\n",
      " [ 0.04763689  0.10698688 -0.8168762 ]]\n",
      "167 0.6402339 \n",
      " [[-0.834623   -1.4298851   1.6135317 ]\n",
      " [ 0.9284877   0.722919    0.7083257 ]\n",
      " [ 0.04935137  0.10640064 -0.8180044 ]]\n",
      "168 0.63930845 \n",
      " [[-0.8396359  -1.4290638   1.6177232 ]\n",
      " [ 0.9287437   0.72338784  0.70760083]\n",
      " [ 0.05106103  0.10582007 -0.8191335 ]]\n",
      "169 0.6383892 \n",
      " [[-0.84463364 -1.4282421   1.6218994 ]\n",
      " [ 0.9289981   0.72385025  0.706884  ]\n",
      " [ 0.05276638  0.10524468 -0.82026345]]\n",
      "170 0.63747555 \n",
      " [[-0.8496164  -1.42742     1.6260601 ]\n",
      " [ 0.9292503   0.72430694  0.7061752 ]\n",
      " [ 0.05446697  0.10467482 -0.82139415]]\n",
      "171 0.63656807 \n",
      " [[-0.8545843  -1.4265978   1.6302058 ]\n",
      " [ 0.9295008   0.7247574   0.70547426]\n",
      " [ 0.05616352  0.10410972 -0.82252556]]\n",
      "172 0.63566625 \n",
      " [[-0.8595374  -1.4257753   1.6343364 ]\n",
      " [ 0.9297491   0.7252024   0.704781  ]\n",
      " [ 0.05785549  0.1035499  -0.8236577 ]]\n",
      "173 0.6347704 \n",
      " [[-0.8644759  -1.4249525   1.638452  ]\n",
      " [ 0.9299956   0.7256415   0.70409536]\n",
      " [ 0.05954356  0.1029946  -0.8247905 ]]\n",
      "174 0.63387996 \n",
      " [[-0.86939996 -1.4241295   1.6425531 ]\n",
      " [ 0.9302398   0.7260754   0.70341724]\n",
      " [ 0.06122722  0.10244431 -0.82592386]]\n",
      "175 0.6329952 \n",
      " [[-0.87430954 -1.4233063   1.6466396 ]\n",
      " [ 0.9304822   0.72650373  0.70274657]\n",
      " [ 0.06290713  0.10189832 -0.8270578 ]]\n",
      "176 0.63211596 \n",
      " [[-0.8792049  -1.422483    1.6507117 ]\n",
      " [ 0.93072224  0.72692716  0.7020832 ]\n",
      " [ 0.06458277  0.10135711 -0.82819223]]\n",
      "177 0.63124216 \n",
      " [[-0.88408613 -1.4216595   1.6547694 ]\n",
      " [ 0.9309605   0.72734517  0.701427  ]\n",
      " [ 0.06625485  0.10081989 -0.8293271 ]]\n",
      "178 0.63037384 \n",
      " [[-0.8889534  -1.4208357   1.658813  ]\n",
      " [ 0.9311962   0.7277586   0.7007778 ]\n",
      " [ 0.06792278  0.10028726 -0.8304624 ]]\n",
      "179 0.62951076 \n",
      " [[-0.89380664 -1.420012    1.6628425 ]\n",
      " [ 0.93143016  0.7281668   0.7001357 ]\n",
      " [ 0.06958731  0.09975839 -0.83159804]]\n",
      "180 0.6286528 \n",
      " [[-0.8986462  -1.4191881   1.6668582 ]\n",
      " [ 0.9316616   0.72857064  0.69950044]\n",
      " [ 0.07124782  0.0992339  -0.83273405]]\n",
      "181 0.6278002 \n",
      " [[-0.903472   -1.4183642   1.67086   ]\n",
      " [ 0.9318912   0.7289696   0.69887197]\n",
      " [ 0.07290504  0.09871303 -0.8338704 ]]\n",
      "182 0.6269527 \n",
      " [[-0.9082843  -1.4175401   1.6748483 ]\n",
      " [ 0.93211824  0.72936434  0.6982502 ]\n",
      " [ 0.07455837  0.09819631 -0.835007  ]]\n",
      "183 0.62611026 \n",
      " [[-0.9130831  -1.416716    1.6788231 ]\n",
      " [ 0.9323434   0.7297543   0.697635  ]\n",
      " [ 0.07620857  0.09768294 -0.83614385]]\n",
      "184 0.62527275 \n",
      " [[-0.9178686  -1.4158919   1.6827844 ]\n",
      " [ 0.93256605  0.7301404   0.6970263 ]\n",
      " [ 0.07785497  0.09717357 -0.83728087]]\n",
      "185 0.62444025 \n",
      " [[-0.92264086 -1.4150678   1.6867325 ]\n",
      " [ 0.9327868   0.7305219   0.696424  ]\n",
      " [ 0.07949832  0.09666739 -0.83841807]]\n",
      "186 0.6236126 \n",
      " [[-0.9274     -1.4142436   1.6906675 ]\n",
      " [ 0.93300503  0.7308997   0.6958281 ]\n",
      " [ 0.08113801  0.09616502 -0.8395554 ]]\n",
      "187 0.62278974 \n",
      " [[-0.9321461  -1.4134195   1.6945895 ]\n",
      " [ 0.93322134  0.7312732   0.69523835]\n",
      " [ 0.08277473  0.09566572 -0.84069276]]\n",
      "188 0.6219716 \n",
      " [[-0.9368793  -1.4125954   1.6984986 ]\n",
      " [ 0.9334351   0.731643    0.69465476]\n",
      " [ 0.08440793  0.09517001 -0.84183025]]\n",
      "189 0.6211581 \n",
      " [[-0.94159967 -1.4117713   1.702395  ]\n",
      " [ 0.93364686  0.7320087   0.69407725]\n",
      " [ 0.08603821  0.09467722 -0.84296775]]\n",
      "190 0.6203494 \n",
      " [[-0.9463074  -1.4109472   1.7062786 ]\n",
      " [ 0.9338562   0.7323709   0.6935057 ]\n",
      " [ 0.08766512  0.09418782 -0.84410524]]\n",
      "191 0.61954516 \n",
      " [[-0.95100254 -1.4101232   1.7101496 ]\n",
      " [ 0.9340635   0.73272926  0.69294006]\n",
      " [ 0.08928911  0.0937013  -0.84524274]]\n",
      "192 0.61874557 \n",
      " [[-0.95568514 -1.4092993   1.7140083 ]\n",
      " [ 0.93426836  0.73308426  0.6923802 ]\n",
      " [ 0.09090987  0.09321798 -0.8463802 ]]\n",
      "193 0.61795044 \n",
      " [[-0.96035534 -1.4084754   1.7178547 ]\n",
      " [ 0.9344712   0.7334355   0.6918261 ]\n",
      " [ 0.09252784  0.09273734 -0.8475175 ]]\n",
      "194 0.6171597 \n",
      " [[-0.96501327 -1.4076517   1.7216889 ]\n",
      " [ 0.9346715   0.7337836   0.6912777 ]\n",
      " [ 0.09414259  0.09225982 -0.8486547 ]]\n",
      "195 0.6163734 \n",
      " [[-0.969659   -1.406828    1.725511  ]\n",
      " [ 0.93486995  0.73412806  0.6907348 ]\n",
      " [ 0.09575471  0.0917848  -0.84979177]]\n",
      "196 0.6155915 \n",
      " [[-0.97429264 -1.4060045   1.729321  ]\n",
      " [ 0.93506587  0.7344695   0.69019747]\n",
      " [ 0.09736364  0.09131279 -0.85092866]]\n",
      "197 0.6148137 \n",
      " [[-0.9789142  -1.4051812   1.7331192 ]\n",
      " [ 0.9352598   0.73480743  0.68966556]\n",
      " [ 0.09896997  0.09084319 -0.8520654 ]]\n",
      "198 0.6140402 \n",
      " [[-0.9835239  -1.4043579   1.7369057 ]\n",
      " [ 0.9354513   0.7351425   0.68913895]\n",
      " [ 0.10057322  0.09037649 -0.8532019 ]]\n",
      "199 0.6132709 \n",
      " [[-0.98812175 -1.4035348   1.7406805 ]\n",
      " [ 0.9356409   0.7354742   0.68861765]\n",
      " [ 0.10217393  0.08991205 -0.8543382 ]]\n",
      "200 0.61250573 \n",
      " [[-0.9927079  -1.4027117   1.7444437 ]\n",
      " [ 0.935828    0.7358032   0.6881016 ]\n",
      " [ 0.10377165  0.08945035 -0.85547423]]\n",
      "Prediction:  [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Launch graph\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #test data로 모델 학습 시키기. cost가 해당 learning rate에 어떻게 변하고 weight 확인\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_train, Y:y_train})\n",
    "        print(step, cost_val,'\\n', W_val)\n",
    "        \n",
    "    #predict y value for test dataset\n",
    "    print('Prediction: ', sess.run(prediction, feed_dict = {X:x_test}))\n",
    "    #Calculate the accuracy\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "\n",
    "### Big learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.5\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "#Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.9315684 \n",
      " [[-1.8322963   0.31240633 -1.2948012 ]\n",
      " [-2.586586    2.9208498   1.5273173 ]\n",
      " [-2.2611632   1.8091605   0.43917197]]\n",
      "10 5.4506016 \n",
      " [[-3.1222386  -0.48419112  0.79173845]\n",
      " [-2.0367558   1.8519707   2.0463657 ]\n",
      " [-2.313683    2.7100115  -0.4091587 ]]\n",
      "20 2.7473001 \n",
      " [[-4.305207  -0.9552013  2.4457169]\n",
      " [-1.3355334  1.6111796  1.585934 ]\n",
      " [-1.6485262  3.4488695 -1.8131742]]\n",
      "30 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "40 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "50 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "60 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "70 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "80 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "90 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "100 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "110 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "120 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "130 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "140 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "150 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "160 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "170 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "180 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "190 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "200 nan \n",
      " [[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "Prediction:  [0 0 0]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Launch graph\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #test data로 모델 학습 시키기. cost가 해당 learning rate에 어떻게 변하고 weight 확인\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_train, Y:y_train})\n",
    "        if step % 10 == 0:\n",
    "            print(step, cost_val,'\\n', W_val)\n",
    "        \n",
    "    #predict y value for test dataset\n",
    "    print('Prediction: ', sess.run(prediction, feed_dict = {X:x_test}))\n",
    "    #Calculate the accuracy\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-10\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "#Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "10 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "20 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "30 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "40 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "50 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "60 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "70 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "80 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "90 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "100 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "110 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "120 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "130 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "140 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "150 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "160 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "170 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "180 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "190 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "200 5.7827015 \n",
      " [[-1.2852678   0.9210705  -1.5207653 ]\n",
      " [ 0.5973209   0.5339927  -1.0807931 ]\n",
      " [-0.12238696  0.47184774 -1.1203287 ]]\n",
      "Prediction:  [1 1 1]\n",
      "Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Launch graph\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #test data로 모델 학습 시키기. cost가 해당 learning rate에 어떻게 변하고 weight 확인\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict = {X:x_train, Y:y_train})\n",
    "        if step % 10 == 0:\n",
    "            print(step, cost_val,'\\n', W_val)\n",
    "        \n",
    "    #predict y value for test dataset\n",
    "    print('Prediction: ', sess.run(prediction, feed_dict = {X:x_test}))\n",
    "    #Calculate the accuracy\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X:x_test, Y:y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과에서 cost가 줄어들지 않는다. local minimum에 빠졌을 가능성이 크다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-normalized inputs\n",
    "- 위의 것들을 잘 했어도 Nan이 나올 경우!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973,833.450012,908100,828.349976,831.659973],\n",
    "              [823.02002,828.07007,1828100,821.655029,828.07007],\n",
    "               [819.929993,824.400023,1438100,818.97998,824.159973],\n",
    "               [816,820.958984,1008100, 815.48999,819.23999],\n",
    "               [819.359985,823,1188100,818.469971,818.97998],\n",
    "               [819,823,1198100,816,820.450012],\n",
    "               [811.700012,815.25,1098100,809.780029,813.669983],\n",
    "               [809.51001,816.659973,1398100,804.539978,809.559998]])\n",
    "              \n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "\n",
    "x_dim = len(x_data[0])\n",
    "y_dim = len(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, x_dim])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, y_dim])\n",
    "W = tf.Variable(tf.random_normal([x_dim, y_dim]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([y_dim]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Cost:  10089017000000.0 \n",
      "Prediction: \n",
      " [[2241436.8]\n",
      " [4511237. ]\n",
      " [3549032. ]\n",
      " [2488139.8]\n",
      " [2932235.8]\n",
      " [2956905.2]\n",
      " [2710179.5]\n",
      " [3450329.2]]\n",
      "5  Cost:  inf \n",
      "Prediction: \n",
      " [[-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]]\n",
      "10  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "105  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "110  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "115  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "120  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "125  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "130  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "135  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "140  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "145  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "150  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "155  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "160  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "165  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "170  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "175  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "180  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "185  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "190  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "195  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "200  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "205  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "210  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "215  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "220  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "225  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "230  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "235  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "240  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "245  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "250  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "255  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "260  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "265  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "270  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "275  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "280  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "285  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "290  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "295  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "300  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "305  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "310  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "315  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "320  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "325  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "330  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "335  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "340  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "345  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "350  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "355  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "360  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "365  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "370  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "375  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "380  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "385  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "390  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "395  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "400  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "405  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "410  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "415  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "420  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "425  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "430  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "435  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "440  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "445  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "450  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "455  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "460  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "465  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "470  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "475  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "480  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "485  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "490  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "495  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "500  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "505  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "510  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "515  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "520  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "525  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "530  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "535  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "540  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "545  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "550  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "555  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "560  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "565  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "570  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "575  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "580  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "585  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "590  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "595  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "600  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "605  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "610  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "615  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "620  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "625  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "630  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "635  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "640  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "645  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "650  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "655  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "660  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "665  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "670  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "675  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "680  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "685  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "690  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "695  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "700  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "705  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "710  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "715  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "720  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "725  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "730  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "735  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "740  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "745  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "750  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "755  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "760  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "765  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "770  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "775  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "780  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "785  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "795  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "800  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "805  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "810  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "815  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "820  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "825  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "830  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "835  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "840  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "845  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "850  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "855  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "860  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "865  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "870  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "875  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "880  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "885  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "890  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "895  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "900  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "905  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "910  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "915  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "920  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "925  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "930  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "935  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "940  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "945  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "950  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "955  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "960  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "965  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "970  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "975  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "980  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "985  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "990  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "995  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1005  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1010  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1015  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1020  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1025  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1030  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1035  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1040  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1045  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1050  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1055  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1060  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1065  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1070  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1075  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1080  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1085  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1090  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1095  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1100  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1105  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1110  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1115  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1120  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1125  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1130  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1135  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1140  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1145  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1150  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1155  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1160  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1165  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1170  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1175  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1180  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1185  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1190  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1195  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1200  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1205  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1210  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1215  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1220  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1225  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1230  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1235  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1240  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1245  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1250  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1255  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1260  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1265  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1270  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1275  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1280  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1285  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1290  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1295  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1300  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1305  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1310  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1315  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1320  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1325  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1330  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1335  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1340  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1345  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1350  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1355  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1360  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1365  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1370  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1375  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1380  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1385  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1390  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1395  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1400  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1405  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1410  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1415  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1420  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1425  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1430  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1435  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1440  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1445  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1450  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1455  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1460  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1465  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1470  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1475  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1480  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1485  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1490  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1495  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1500  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1505  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1510  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1515  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1520  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1525  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1530  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1535  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1540  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1545  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1550  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1555  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1560  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1565  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1570  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1575  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1580  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1585  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1590  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1595  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1600  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1605  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1610  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1615  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1620  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1625  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1630  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1635  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1645  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1650  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1655  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1660  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1665  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1670  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1675  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1680  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1685  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1690  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1695  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1700  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1705  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1710  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1715  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1720  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1725  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1730  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1735  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1740  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1745  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1750  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1755  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1760  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1765  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1770  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1775  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1780  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1785  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1790  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1795  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1800  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1805  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1810  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1815  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1820  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1825  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1830  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1835  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1840  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1845  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1850  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1855  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1860  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1865  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1870  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1875  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1880  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1885  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1890  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1895  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1900  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1905  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1910  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1915  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1920  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1925  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1930  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1935  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1940  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1945  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1950  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1955  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1960  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1965  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1970  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1975  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1980  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1985  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1990  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1995  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000  Cost:  nan \n",
      "Prediction: \n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict = {X:x_data, Y: y_data})\n",
    "    if step % 5 == 0:\n",
    "        print(step,' Cost: ', cost_val, '\\nPrediction: \\n', hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solution: Normalized inputs (min-max scale)\n",
    "제일 작은 값 = 0, 제일 큰 값 = 1 (기준: column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.28659973e+02, 8.33450012e+02, 9.08100000e+05, 8.28349976e+02,\n",
       "        8.31659973e+02],\n",
       "       [8.23020020e+02, 8.28070070e+02, 1.82810000e+06, 8.21655029e+02,\n",
       "        8.28070070e+02],\n",
       "       [8.19929993e+02, 8.24400023e+02, 1.43810000e+06, 8.18979980e+02,\n",
       "        8.24159973e+02],\n",
       "       [8.16000000e+02, 8.20958984e+02, 1.00810000e+06, 8.15489990e+02,\n",
       "        8.19239990e+02],\n",
       "       [8.19359985e+02, 8.23000000e+02, 1.18810000e+06, 8.18469971e+02,\n",
       "        8.18979980e+02],\n",
       "       [8.19000000e+02, 8.23000000e+02, 1.19810000e+06, 8.16000000e+02,\n",
       "        8.20450012e+02],\n",
       "       [8.11700012e+02, 8.15250000e+02, 1.09810000e+06, 8.09780029e+02,\n",
       "        8.13669983e+02],\n",
       "       [8.09510010e+02, 8.16659973e+02, 1.39810000e+06, 8.04539978e+02,\n",
       "        8.09559998e+02]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.28659973e+02, 8.23020020e+02, 8.19929993e+02, 8.16000000e+02,\n",
       "        8.19359985e+02, 8.19000000e+02, 8.11700012e+02, 8.09510010e+02],\n",
       "       [8.33450012e+02, 8.28070070e+02, 8.24400023e+02, 8.20958984e+02,\n",
       "        8.23000000e+02, 8.23000000e+02, 8.15250000e+02, 8.16659973e+02],\n",
       "       [9.08100000e+05, 1.82810000e+06, 1.43810000e+06, 1.00810000e+06,\n",
       "        1.18810000e+06, 1.19810000e+06, 1.09810000e+06, 1.39810000e+06],\n",
       "       [8.28349976e+02, 8.21655029e+02, 8.18979980e+02, 8.15489990e+02,\n",
       "        8.18469971e+02, 8.16000000e+02, 8.09780029e+02, 8.04539978e+02],\n",
       "       [8.31659973e+02, 8.28070070e+02, 8.24159973e+02, 8.19239990e+02,\n",
       "        8.18979980e+02, 8.20450012e+02, 8.13669983e+02, 8.09559998e+02]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0) #column별로 가장 작은 값을 data에서 빼줌 (min을 0으로!)\n",
    "    denominator = np.max(data,0) - np.min(data,0) #컬럼별로 가장 큰 값에서 가장 작은 값 빼준 값\n",
    "    #noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-normalized: \n",
      " [[8.28659973e+02 8.33450012e+02 9.08100000e+05 8.28349976e+02\n",
      "  8.31659973e+02]\n",
      " [8.23020020e+02 8.28070070e+02 1.82810000e+06 8.21655029e+02\n",
      "  8.28070070e+02]\n",
      " [8.19929993e+02 8.24400023e+02 1.43810000e+06 8.18979980e+02\n",
      "  8.24159973e+02]\n",
      " [8.16000000e+02 8.20958984e+02 1.00810000e+06 8.15489990e+02\n",
      "  8.19239990e+02]\n",
      " [8.19359985e+02 8.23000000e+02 1.18810000e+06 8.18469971e+02\n",
      "  8.18979980e+02]\n",
      " [8.19000000e+02 8.23000000e+02 1.19810000e+06 8.16000000e+02\n",
      "  8.20450012e+02]\n",
      " [8.11700012e+02 8.15250000e+02 1.09810000e+06 8.09780029e+02\n",
      "  8.13669983e+02]\n",
      " [8.09510010e+02 8.16659973e+02 1.39810000e+06 8.04539978e+02\n",
      "  8.09559998e+02]]\n",
      "\n",
      " [[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439898 1.         0.71881782 0.83756076]\n",
      " [0.54412549 0.50274818 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Non-normalized: \\n', xy)\n",
    "\n",
    "xy_n = MinMaxScaler(xy)\n",
    "print('\\n',xy_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = xy_n[:, 0:-1]\n",
    "y_data = xy_n[:,[-1]]\n",
    "\n",
    "x_dim = len(x_data[0])\n",
    "y_dim = len(y_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Cost:  1.2626262 \n",
      "Prediction: \n",
      " [[2.6818376 ]\n",
      " [2.662682  ]\n",
      " [1.866132  ]\n",
      " [0.9749556 ]\n",
      " [1.5227472 ]\n",
      " [1.4203852 ]\n",
      " [0.31308216]\n",
      " [0.34765327]]\n",
      "5  Cost:  1.262181 \n",
      "Prediction: \n",
      " [[2.681559  ]\n",
      " [2.6624134 ]\n",
      " [1.86591   ]\n",
      " [0.9747863 ]\n",
      " [1.5225444 ]\n",
      " [1.4201899 ]\n",
      " [0.31295562]\n",
      " [0.34752917]]\n",
      "10  Cost:  1.2617366 \n",
      "Prediction: \n",
      " [[2.6812806 ]\n",
      " [2.662145  ]\n",
      " [1.8656883 ]\n",
      " [0.97461706]\n",
      " [1.5223417 ]\n",
      " [1.4199944 ]\n",
      " [0.31282908]\n",
      " [0.3474052 ]]\n",
      "15  Cost:  1.261292 \n",
      "Prediction: \n",
      " [[2.681002  ]\n",
      " [2.6618764 ]\n",
      " [1.8654666 ]\n",
      " [0.9744478 ]\n",
      " [1.5221393 ]\n",
      " [1.4197991 ]\n",
      " [0.3127026 ]\n",
      " [0.34728122]]\n",
      "20  Cost:  1.2608472 \n",
      "Prediction: \n",
      " [[2.6807232 ]\n",
      " [2.661608  ]\n",
      " [1.8652446 ]\n",
      " [0.97427857]\n",
      " [1.5219365 ]\n",
      " [1.4196038 ]\n",
      " [0.31257612]\n",
      " [0.3471572 ]]\n",
      "25  Cost:  1.2604029 \n",
      "Prediction: \n",
      " [[2.6804447 ]\n",
      " [2.6613398 ]\n",
      " [1.8650227 ]\n",
      " [0.9741093 ]\n",
      " [1.521734  ]\n",
      " [1.4194083 ]\n",
      " [0.31244963]\n",
      " [0.34703332]]\n",
      "30  Cost:  1.2599585 \n",
      "Prediction: \n",
      " [[2.6801662 ]\n",
      " [2.661071  ]\n",
      " [1.8648009 ]\n",
      " [0.97394   ]\n",
      " [1.5215312 ]\n",
      " [1.4192129 ]\n",
      " [0.31232324]\n",
      " [0.34690937]]\n",
      "35  Cost:  1.2595145 \n",
      "Prediction: \n",
      " [[2.6798878 ]\n",
      " [2.6608028 ]\n",
      " [1.8645793 ]\n",
      " [0.97377086]\n",
      " [1.5213288 ]\n",
      " [1.4190178 ]\n",
      " [0.3121968 ]\n",
      " [0.34678543]]\n",
      "40  Cost:  1.2590703 \n",
      "Prediction: \n",
      " [[2.679609 ]\n",
      " [2.6605344]\n",
      " [1.8643575]\n",
      " [0.9736017]\n",
      " [1.5211263]\n",
      " [1.4188224]\n",
      " [0.3120704]\n",
      " [0.3466616]]\n",
      "45  Cost:  1.2586262 \n",
      "Prediction: \n",
      " [[2.6793306]\n",
      " [2.660266 ]\n",
      " [1.8641357]\n",
      " [0.9734326]\n",
      " [1.5209236]\n",
      " [1.418627 ]\n",
      " [0.311944 ]\n",
      " [0.3465377]]\n",
      "50  Cost:  1.2581828 \n",
      "Prediction: \n",
      " [[2.6790524 ]\n",
      " [2.659998  ]\n",
      " [1.863914  ]\n",
      " [0.9732635 ]\n",
      " [1.5207212 ]\n",
      " [1.418432  ]\n",
      " [0.31181768]\n",
      " [0.34641388]]\n",
      "55  Cost:  1.257739 \n",
      "Prediction: \n",
      " [[2.6787739 ]\n",
      " [2.6597295 ]\n",
      " [1.8636924 ]\n",
      " [0.97309434]\n",
      " [1.5205187 ]\n",
      " [1.4182366 ]\n",
      " [0.31169134]\n",
      " [0.34629005]]\n",
      "60  Cost:  1.2572954 \n",
      "Prediction: \n",
      " [[2.6784952 ]\n",
      " [2.6594613 ]\n",
      " [1.8634706 ]\n",
      " [0.97292525]\n",
      " [1.5203161 ]\n",
      " [1.4180415 ]\n",
      " [0.31156504]\n",
      " [0.34616625]]\n",
      "65  Cost:  1.2568519 \n",
      "Prediction: \n",
      " [[2.678217  ]\n",
      " [2.659193  ]\n",
      " [1.8632491 ]\n",
      " [0.97275615]\n",
      " [1.5201137 ]\n",
      " [1.4178462 ]\n",
      " [0.31143868]\n",
      " [0.34604245]]\n",
      "70  Cost:  1.2564085 \n",
      "Prediction: \n",
      " [[2.6779387 ]\n",
      " [2.6589246 ]\n",
      " [1.8630273 ]\n",
      " [0.9725871 ]\n",
      " [1.5199113 ]\n",
      " [1.4176509 ]\n",
      " [0.3113125 ]\n",
      " [0.34591872]]\n",
      "75  Cost:  1.2559655 \n",
      "Prediction: \n",
      " [[2.6776602 ]\n",
      " [2.6586566 ]\n",
      " [1.8628058 ]\n",
      " [0.97241807]\n",
      " [1.5197089 ]\n",
      " [1.4174559 ]\n",
      " [0.3111862 ]\n",
      " [0.34579498]]\n",
      "80  Cost:  1.2555224 \n",
      "Prediction: \n",
      " [[2.6773818 ]\n",
      " [2.6583881 ]\n",
      " [1.8625844 ]\n",
      " [0.97224903]\n",
      " [1.5195065 ]\n",
      " [1.4172608 ]\n",
      " [0.31105995]\n",
      " [0.34567124]]\n",
      "85  Cost:  1.2550794 \n",
      "Prediction: \n",
      " [[2.6771035]\n",
      " [2.6581202]\n",
      " [1.8623626]\n",
      " [0.97208  ]\n",
      " [1.519304 ]\n",
      " [1.4170656]\n",
      " [0.3109337]\n",
      " [0.3455475]]\n",
      "90  Cost:  1.2546365 \n",
      "Prediction: \n",
      " [[2.6768253 ]\n",
      " [2.657852  ]\n",
      " [1.862141  ]\n",
      " [0.97191113]\n",
      " [1.5191017 ]\n",
      " [1.4168706 ]\n",
      " [0.31080753]\n",
      " [0.34542382]]\n",
      "95  Cost:  1.254194 \n",
      "Prediction: \n",
      " [[2.676547  ]\n",
      " [2.657584  ]\n",
      " [1.8619195 ]\n",
      " [0.97174215]\n",
      " [1.5188994 ]\n",
      " [1.4166754 ]\n",
      " [0.31068137]\n",
      " [0.34530017]]\n",
      "100  Cost:  1.2537514 \n",
      "Prediction: \n",
      " [[2.6762686 ]\n",
      " [2.6573157 ]\n",
      " [1.8616982 ]\n",
      " [0.97157323]\n",
      " [1.518697  ]\n",
      " [1.4164804 ]\n",
      " [0.31055522]\n",
      " [0.34517652]]\n",
      "105  Cost:  1.253309 \n",
      "Prediction: \n",
      " [[2.6759903 ]\n",
      " [2.6570475 ]\n",
      " [1.8614768 ]\n",
      " [0.97140443]\n",
      " [1.518495  ]\n",
      " [1.4162854 ]\n",
      " [0.31042907]\n",
      " [0.34505293]]\n",
      "110  Cost:  1.2528672 \n",
      "Prediction: \n",
      " [[2.6757128 ]\n",
      " [2.6567798 ]\n",
      " [1.8612554 ]\n",
      " [0.9712355 ]\n",
      " [1.5182929 ]\n",
      " [1.4160906 ]\n",
      " [0.310303  ]\n",
      " [0.34492934]]\n",
      "115  Cost:  1.2524257 \n",
      "Prediction: \n",
      " [[2.6754353 ]\n",
      " [2.656512  ]\n",
      " [1.8610343 ]\n",
      " [0.97106683]\n",
      " [1.5180908 ]\n",
      " [1.4158959 ]\n",
      " [0.31017694]\n",
      " [0.34480575]]\n",
      "120  Cost:  1.2519845 \n",
      "Prediction: \n",
      " [[2.6751575 ]\n",
      " [2.6562448 ]\n",
      " [1.8608131 ]\n",
      " [0.97089833]\n",
      " [1.517889  ]\n",
      " [1.4157012 ]\n",
      " [0.3100509 ]\n",
      " [0.34468216]]\n",
      "125  Cost:  1.2515438 \n",
      "Prediction: \n",
      " [[2.6748805 ]\n",
      " [2.6559772 ]\n",
      " [1.8605924 ]\n",
      " [0.9707298 ]\n",
      " [1.5176873 ]\n",
      " [1.4155068 ]\n",
      " [0.30992496]\n",
      " [0.34455866]]\n",
      "130  Cost:  1.251103 \n",
      "Prediction: \n",
      " [[2.6746035 ]\n",
      " [2.65571   ]\n",
      " [1.8603716 ]\n",
      " [0.9705614 ]\n",
      " [1.5174856 ]\n",
      " [1.4153123 ]\n",
      " [0.30979902]\n",
      " [0.34443516]]\n",
      "135  Cost:  1.2506623 \n",
      "Prediction: \n",
      " [[2.674326  ]\n",
      " [2.6554427 ]\n",
      " [1.8601508 ]\n",
      " [0.97039294]\n",
      " [1.5172838 ]\n",
      " [1.4151177 ]\n",
      " [0.30967313]\n",
      " [0.3443117 ]]\n",
      "140  Cost:  1.2502217 \n",
      "Prediction: \n",
      " [[2.674049  ]\n",
      " [2.6551752 ]\n",
      " [1.8599298 ]\n",
      " [0.9702245 ]\n",
      " [1.5170821 ]\n",
      " [1.4149232 ]\n",
      " [0.3095472 ]\n",
      " [0.34418818]]\n",
      "145  Cost:  1.2497815 \n",
      "Prediction: \n",
      " [[2.6737716 ]\n",
      " [2.6549082 ]\n",
      " [1.859709  ]\n",
      " [0.97005594]\n",
      " [1.5168804 ]\n",
      " [1.4147288 ]\n",
      " [0.3094213 ]\n",
      " [0.34406477]]\n",
      "150  Cost:  1.2493412 \n",
      "Prediction: \n",
      " [[2.6734943 ]\n",
      " [2.654641  ]\n",
      " [1.8594884 ]\n",
      " [0.9698877 ]\n",
      " [1.5166789 ]\n",
      " [1.4145346 ]\n",
      " [0.30929554]\n",
      " [0.3439415 ]]\n",
      "155  Cost:  1.2489016 \n",
      "Prediction: \n",
      " [[2.6732175 ]\n",
      " [2.6543744 ]\n",
      " [1.8592676 ]\n",
      " [0.9697193 ]\n",
      " [1.5164773 ]\n",
      " [1.4143401 ]\n",
      " [0.3091697 ]\n",
      " [0.34381825]]\n",
      "160  Cost:  1.2484617 \n",
      "Prediction: \n",
      " [[2.67294   ]\n",
      " [2.654107  ]\n",
      " [1.8590472 ]\n",
      " [0.9695509 ]\n",
      " [1.5162758 ]\n",
      " [1.414146  ]\n",
      " [0.30904394]\n",
      " [0.34369498]]\n",
      "165  Cost:  1.2480221 \n",
      "Prediction: \n",
      " [[2.672663  ]\n",
      " [2.6538403 ]\n",
      " [1.8588265 ]\n",
      " [0.96938264]\n",
      " [1.5160743 ]\n",
      " [1.4139516 ]\n",
      " [0.3089182 ]\n",
      " [0.3435718 ]]\n",
      "170  Cost:  1.2475827 \n",
      "Prediction: \n",
      " [[2.6723862 ]\n",
      " [2.6535733 ]\n",
      " [1.8586061 ]\n",
      " [0.96921444]\n",
      " [1.5158727 ]\n",
      " [1.4137573 ]\n",
      " [0.30879253]\n",
      " [0.34344864]]\n",
      "175  Cost:  1.2471428 \n",
      "Prediction: \n",
      " [[2.6721087]\n",
      " [2.653306 ]\n",
      " [1.8583854]\n",
      " [0.969046 ]\n",
      " [1.5156714]\n",
      " [1.4135629]\n",
      " [0.3086668]\n",
      " [0.3433255]]\n",
      "180  Cost:  1.2467039 \n",
      "Prediction: \n",
      " [[2.6718318 ]\n",
      " [2.6530395 ]\n",
      " [1.858165  ]\n",
      " [0.96887785]\n",
      " [1.5154698 ]\n",
      " [1.4133687 ]\n",
      " [0.30854112]\n",
      " [0.34320235]]\n",
      "185  Cost:  1.2462646 \n",
      "Prediction: \n",
      " [[2.6715548 ]\n",
      " [2.6527724 ]\n",
      " [1.8579445 ]\n",
      " [0.9687096 ]\n",
      " [1.5152683 ]\n",
      " [1.4131746 ]\n",
      " [0.30841547]\n",
      " [0.3430792 ]]\n",
      "190  Cost:  1.2458255 \n",
      "Prediction: \n",
      " [[2.6712778 ]\n",
      " [2.6525059 ]\n",
      " [1.857724  ]\n",
      " [0.9685414 ]\n",
      " [1.5150669 ]\n",
      " [1.4129804 ]\n",
      " [0.30828983]\n",
      " [0.34295613]]\n",
      "195  Cost:  1.2453866 \n",
      "Prediction: \n",
      " [[2.671001  ]\n",
      " [2.6522388 ]\n",
      " [1.8575034 ]\n",
      " [0.9683731 ]\n",
      " [1.5148656 ]\n",
      " [1.4127862 ]\n",
      " [0.30816418]\n",
      " [0.34283298]]\n",
      "200  Cost:  1.2449479 \n",
      "Prediction: \n",
      " [[2.6707237 ]\n",
      " [2.6519723 ]\n",
      " [1.8572831 ]\n",
      " [0.968205  ]\n",
      " [1.5146642 ]\n",
      " [1.4125922 ]\n",
      " [0.30803862]\n",
      " [0.34270993]]\n",
      "205  Cost:  1.2445092 \n",
      "Prediction: \n",
      " [[2.6704469 ]\n",
      " [2.6517055 ]\n",
      " [1.8570628 ]\n",
      " [0.9680369 ]\n",
      " [1.5144628 ]\n",
      " [1.412398  ]\n",
      " [0.307913  ]\n",
      " [0.34258687]]\n",
      "210  Cost:  1.2440705 \n",
      "Prediction: \n",
      " [[2.67017   ]\n",
      " [2.6514387 ]\n",
      " [1.856842  ]\n",
      " [0.96786875]\n",
      " [1.5142615 ]\n",
      " [1.4122038 ]\n",
      " [0.30778748]\n",
      " [0.34246385]]\n",
      "215  Cost:  1.2436321 \n",
      "Prediction: \n",
      " [[2.6698928 ]\n",
      " [2.651172  ]\n",
      " [1.8566219 ]\n",
      " [0.9677006 ]\n",
      " [1.5140601 ]\n",
      " [1.4120098 ]\n",
      " [0.3076619 ]\n",
      " [0.34234083]]\n",
      "220  Cost:  1.2431939 \n",
      "Prediction: \n",
      " [[2.6696162 ]\n",
      " [2.6509054 ]\n",
      " [1.8564014 ]\n",
      " [0.9675325 ]\n",
      " [1.5138589 ]\n",
      " [1.4118156 ]\n",
      " [0.3075364 ]\n",
      " [0.34221783]]\n",
      "225  Cost:  1.2427558 \n",
      "Prediction: \n",
      " [[2.6693392 ]\n",
      " [2.6506386 ]\n",
      " [1.8561813 ]\n",
      " [0.96736443]\n",
      " [1.5136577 ]\n",
      " [1.4116217 ]\n",
      " [0.30741087]\n",
      " [0.34209487]]\n",
      "230  Cost:  1.2423177 \n",
      "Prediction: \n",
      " [[2.6690624 ]\n",
      " [2.6503718 ]\n",
      " [1.8559606 ]\n",
      " [0.96719635]\n",
      " [1.5134565 ]\n",
      " [1.4114277 ]\n",
      " [0.3072854 ]\n",
      " [0.3419719 ]]\n",
      "235  Cost:  1.2418795 \n",
      "Prediction: \n",
      " [[2.6687856 ]\n",
      " [2.650105  ]\n",
      " [1.8557404 ]\n",
      " [0.96702826]\n",
      " [1.513255  ]\n",
      " [1.4112337 ]\n",
      " [0.30715993]\n",
      " [0.34184894]]\n",
      "240  Cost:  1.2414417 \n",
      "Prediction: \n",
      " [[2.6685085 ]\n",
      " [2.6498384 ]\n",
      " [1.8555202 ]\n",
      " [0.96686035]\n",
      " [1.5130539 ]\n",
      " [1.4110396 ]\n",
      " [0.3070345 ]\n",
      " [0.34172612]]\n",
      "245  Cost:  1.2410042 \n",
      "Prediction: \n",
      " [[2.668232  ]\n",
      " [2.6495721 ]\n",
      " [1.8553    ]\n",
      " [0.96669245]\n",
      " [1.5128529 ]\n",
      " [1.4108456 ]\n",
      " [0.30690908]\n",
      " [0.34160322]]\n",
      "250  Cost:  1.2405673 \n",
      "Prediction: \n",
      " [[2.6679559 ]\n",
      " [2.6493058 ]\n",
      " [1.8550801 ]\n",
      " [0.96652454]\n",
      " [1.5126519 ]\n",
      " [1.410652  ]\n",
      " [0.30678374]\n",
      " [0.3414803 ]]\n",
      "255  Cost:  1.2401307 \n",
      "Prediction: \n",
      " [[2.6676798 ]\n",
      " [2.6490397 ]\n",
      " [1.8548602 ]\n",
      " [0.96635693]\n",
      " [1.512451  ]\n",
      " [1.4104583 ]\n",
      " [0.30665845]\n",
      " [0.34135747]]\n",
      "260  Cost:  1.2396945 \n",
      "Prediction: \n",
      " [[2.667404  ]\n",
      " [2.648774  ]\n",
      " [1.8546405 ]\n",
      " [0.9661893 ]\n",
      " [1.5122504 ]\n",
      " [1.4102648 ]\n",
      " [0.30653322]\n",
      " [0.34123462]]\n",
      "265  Cost:  1.2392583 \n",
      "Prediction: \n",
      " [[2.667128 ]\n",
      " [2.6485078]\n",
      " [1.8544209]\n",
      " [0.9660218]\n",
      " [1.5120498]\n",
      " [1.4100714]\n",
      " [0.306408 ]\n",
      " [0.3411119]]\n",
      "270  Cost:  1.2388221 \n",
      "Prediction: \n",
      " [[2.666852  ]\n",
      " [2.648242  ]\n",
      " [1.8542011 ]\n",
      " [0.96585417]\n",
      " [1.511849  ]\n",
      " [1.409878  ]\n",
      " [0.3062827 ]\n",
      " [0.34098905]]\n",
      "275  Cost:  1.2383862 \n",
      "Prediction: \n",
      " [[2.6665764 ]\n",
      " [2.647976  ]\n",
      " [1.8539816 ]\n",
      " [0.9656865 ]\n",
      " [1.5116485 ]\n",
      " [1.4096845 ]\n",
      " [0.30615747]\n",
      " [0.34086633]]\n",
      "280  Cost:  1.2379507 \n",
      "Prediction: \n",
      " [[2.6663008 ]\n",
      " [2.6477106 ]\n",
      " [1.8537619 ]\n",
      " [0.965519  ]\n",
      " [1.5114479 ]\n",
      " [1.4094911 ]\n",
      " [0.30603236]\n",
      " [0.3407436 ]]\n",
      "285  Cost:  1.2375146 \n",
      "Prediction: \n",
      " [[2.666025  ]\n",
      " [2.6474442 ]\n",
      " [1.8535421 ]\n",
      " [0.9653515 ]\n",
      " [1.5112472 ]\n",
      " [1.4092977 ]\n",
      " [0.3059072 ]\n",
      " [0.34062093]]\n",
      "290  Cost:  1.2370789 \n",
      "Prediction: \n",
      " [[2.665749  ]\n",
      " [2.6471786 ]\n",
      " [1.8533224 ]\n",
      " [0.965184  ]\n",
      " [1.5110466 ]\n",
      " [1.4091042 ]\n",
      " [0.305782  ]\n",
      " [0.34049818]]\n",
      "295  Cost:  1.2366437 \n",
      "Prediction: \n",
      " [[2.6654735 ]\n",
      " [2.6469128 ]\n",
      " [1.8531029 ]\n",
      " [0.96501666]\n",
      " [1.5108461 ]\n",
      " [1.408911  ]\n",
      " [0.30565688]\n",
      " [0.34037554]]\n",
      "300  Cost:  1.2362084 \n",
      "Prediction: \n",
      " [[2.6651978 ]\n",
      " [2.646647  ]\n",
      " [1.8528833 ]\n",
      " [0.9648491 ]\n",
      " [1.5106456 ]\n",
      " [1.4087176 ]\n",
      " [0.30553177]\n",
      " [0.34025288]]\n",
      "305  Cost:  1.2357733 \n",
      "Prediction: \n",
      " [[2.6649222 ]\n",
      " [2.6463814 ]\n",
      " [1.852664  ]\n",
      " [0.9646817 ]\n",
      " [1.5104451 ]\n",
      " [1.4085243 ]\n",
      " [0.3054067 ]\n",
      " [0.34013027]]\n",
      "310  Cost:  1.235338 \n",
      "Prediction: \n",
      " [[2.6646461 ]\n",
      " [2.6461158 ]\n",
      " [1.8524443 ]\n",
      " [0.96451426]\n",
      " [1.5102447 ]\n",
      " [1.4083309 ]\n",
      " [0.30528158]\n",
      " [0.3400076 ]]\n",
      "315  Cost:  1.2349031 \n",
      "Prediction: \n",
      " [[2.664371  ]\n",
      " [2.6458497 ]\n",
      " [1.852225  ]\n",
      " [0.9643469 ]\n",
      " [1.510044  ]\n",
      " [1.4081377 ]\n",
      " [0.30515656]\n",
      " [0.339885  ]]\n",
      "320  Cost:  1.2344685 \n",
      "Prediction: \n",
      " [[2.6640954 ]\n",
      " [2.6455843 ]\n",
      " [1.8520054 ]\n",
      " [0.9641794 ]\n",
      " [1.5098436 ]\n",
      " [1.4079443 ]\n",
      " [0.30503154]\n",
      " [0.33976245]]\n",
      "325  Cost:  1.2340336 \n",
      "Prediction: \n",
      " [[2.6638198 ]\n",
      " [2.6453185 ]\n",
      " [1.851786  ]\n",
      " [0.964012  ]\n",
      " [1.5096432 ]\n",
      " [1.4077512 ]\n",
      " [0.30490652]\n",
      " [0.33963993]]\n",
      "330  Cost:  1.2335988 \n",
      "Prediction: \n",
      " [[2.663544  ]\n",
      " [2.6450527 ]\n",
      " [1.8515664 ]\n",
      " [0.96384484]\n",
      " [1.5094428 ]\n",
      " [1.407558  ]\n",
      " [0.3047815 ]\n",
      " [0.33951735]]\n",
      "335  Cost:  1.2331645 \n",
      "Prediction: \n",
      " [[2.6632686 ]\n",
      " [2.644787  ]\n",
      " [1.851347  ]\n",
      " [0.9636775 ]\n",
      " [1.5092425 ]\n",
      " [1.4073647 ]\n",
      " [0.30465657]\n",
      " [0.3393948 ]]\n",
      "340  Cost:  1.2327305 \n",
      "Prediction: \n",
      " [[2.662993  ]\n",
      " [2.644522  ]\n",
      " [1.851128  ]\n",
      " [0.9635103 ]\n",
      " [1.5090421 ]\n",
      " [1.4071717 ]\n",
      " [0.3045317 ]\n",
      " [0.33927256]]\n",
      "345  Cost:  1.2322967 \n",
      "Prediction: \n",
      " [[2.6627176 ]\n",
      " [2.6442568 ]\n",
      " [1.8509088 ]\n",
      " [0.9633431 ]\n",
      " [1.508842  ]\n",
      " [1.4069787 ]\n",
      " [0.30440676]\n",
      " [0.3391502 ]]\n",
      "350  Cost:  1.2318622 \n",
      "Prediction: \n",
      " [[2.6624417 ]\n",
      " [2.643991  ]\n",
      " [1.8506894 ]\n",
      " [0.96317583]\n",
      " [1.5086415 ]\n",
      " [1.4067855 ]\n",
      " [0.3042819 ]\n",
      " [0.33902788]]\n",
      "355  Cost:  1.2314289 \n",
      "Prediction: \n",
      " [[2.6621666 ]\n",
      " [2.643726  ]\n",
      " [1.8504703 ]\n",
      " [0.9630085 ]\n",
      " [1.5084414 ]\n",
      " [1.4065925 ]\n",
      " [0.30415708]\n",
      " [0.33890563]]\n",
      "360  Cost:  1.2309954 \n",
      "Prediction: \n",
      " [[2.6618912 ]\n",
      " [2.643461  ]\n",
      " [1.8502511 ]\n",
      " [0.9628414 ]\n",
      " [1.5082412 ]\n",
      " [1.4063996 ]\n",
      " [0.3040323 ]\n",
      " [0.33878335]]\n",
      "365  Cost:  1.2305617 \n",
      "Prediction: \n",
      " [[2.6616156 ]\n",
      " [2.6431954 ]\n",
      " [1.850032  ]\n",
      " [0.9626742 ]\n",
      " [1.508041  ]\n",
      " [1.4062067 ]\n",
      " [0.30390745]\n",
      " [0.33866107]]\n",
      "370  Cost:  1.230128 \n",
      "Prediction: \n",
      " [[2.66134   ]\n",
      " [2.6429303 ]\n",
      " [1.8498127 ]\n",
      " [0.962507  ]\n",
      " [1.5078409 ]\n",
      " [1.4060135 ]\n",
      " [0.3037827 ]\n",
      " [0.33853886]]\n",
      "375  Cost:  1.2296951 \n",
      "Prediction: \n",
      " [[2.6610649 ]\n",
      " [2.6426651 ]\n",
      " [1.8495936 ]\n",
      " [0.9623399 ]\n",
      " [1.5076408 ]\n",
      " [1.4058206 ]\n",
      " [0.30365798]\n",
      " [0.33841673]]\n",
      "380  Cost:  1.2292624 \n",
      "Prediction: \n",
      " [[2.6607897 ]\n",
      " [2.6424005 ]\n",
      " [1.8493748 ]\n",
      " [0.962173  ]\n",
      " [1.5074408 ]\n",
      " [1.4056277 ]\n",
      " [0.3035333 ]\n",
      " [0.33829454]]\n",
      "385  Cost:  1.2288296 \n",
      "Prediction: \n",
      " [[2.6605146 ]\n",
      " [2.6421356 ]\n",
      " [1.8491559 ]\n",
      " [0.9620061 ]\n",
      " [1.5072409 ]\n",
      " [1.4054351 ]\n",
      " [0.30340865]\n",
      " [0.33817235]]\n",
      "390  Cost:  1.2283975 \n",
      "Prediction: \n",
      " [[2.66024   ]\n",
      " [2.6418707 ]\n",
      " [1.8489374 ]\n",
      " [0.96183926]\n",
      " [1.5070411 ]\n",
      " [1.4052426 ]\n",
      " [0.30328405]\n",
      " [0.3380502 ]]\n",
      "395  Cost:  1.2279657 \n",
      "Prediction: \n",
      " [[2.6599655]\n",
      " [2.641606 ]\n",
      " [1.8487188]\n",
      " [0.9616724]\n",
      " [1.5068415]\n",
      " [1.40505  ]\n",
      " [0.3031595]\n",
      " [0.3379281]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400  Cost:  1.2275336 \n",
      "Prediction: \n",
      " [[2.6596906 ]\n",
      " [2.6413414 ]\n",
      " [1.8485    ]\n",
      " [0.96150565]\n",
      " [1.5066419 ]\n",
      " [1.4048574 ]\n",
      " [0.3030349 ]\n",
      " [0.337806  ]]\n",
      "405  Cost:  1.2271018 \n",
      "Prediction: \n",
      " [[2.659416  ]\n",
      " [2.6410768 ]\n",
      " [1.8482814 ]\n",
      " [0.96133894]\n",
      " [1.5064421 ]\n",
      " [1.4046648 ]\n",
      " [0.30291036]\n",
      " [0.33768386]]\n",
      "410  Cost:  1.2266705 \n",
      "Prediction: \n",
      " [[2.6591418 ]\n",
      " [2.6408124 ]\n",
      " [1.848063  ]\n",
      " [0.96117216]\n",
      " [1.5062425 ]\n",
      " [1.4044726 ]\n",
      " [0.30278587]\n",
      " [0.33756185]]\n",
      "415  Cost:  1.2262392 \n",
      "Prediction: \n",
      " [[2.6588671 ]\n",
      " [2.640548  ]\n",
      " [1.8478445 ]\n",
      " [0.9610057 ]\n",
      " [1.5060431 ]\n",
      " [1.4042801 ]\n",
      " [0.30266136]\n",
      " [0.33743984]]\n",
      "420  Cost:  1.2258081 \n",
      "Prediction: \n",
      " [[2.658593  ]\n",
      " [2.6402836 ]\n",
      " [1.8476262 ]\n",
      " [0.96083903]\n",
      " [1.5058434 ]\n",
      " [1.4040877 ]\n",
      " [0.30253685]\n",
      " [0.33731782]]\n",
      "425  Cost:  1.2253773 \n",
      "Prediction: \n",
      " [[2.6583188 ]\n",
      " [2.6400194 ]\n",
      " [1.8474077 ]\n",
      " [0.96067244]\n",
      " [1.505644  ]\n",
      " [1.4038953 ]\n",
      " [0.30241245]\n",
      " [0.3371958 ]]\n",
      "430  Cost:  1.2249463 \n",
      "Prediction: \n",
      " [[2.6580446 ]\n",
      " [2.6397548 ]\n",
      " [1.8471893 ]\n",
      " [0.96050584]\n",
      " [1.5054444 ]\n",
      " [1.4037031 ]\n",
      " [0.30228797]\n",
      " [0.3370739 ]]\n",
      "435  Cost:  1.2245157 \n",
      "Prediction: \n",
      " [[2.6577704 ]\n",
      " [2.6394908 ]\n",
      " [1.8469709 ]\n",
      " [0.9603392 ]\n",
      " [1.5052451 ]\n",
      " [1.4035108 ]\n",
      " [0.3021636 ]\n",
      " [0.33695197]]\n",
      "440  Cost:  1.2240849 \n",
      "Prediction: \n",
      " [[2.657496  ]\n",
      " [2.6392264 ]\n",
      " [1.8467525 ]\n",
      " [0.9601728 ]\n",
      " [1.5050455 ]\n",
      " [1.4033185 ]\n",
      " [0.30203918]\n",
      " [0.33683002]]\n",
      "445  Cost:  1.2236545 \n",
      "Prediction: \n",
      " [[2.6572218 ]\n",
      " [2.6389623 ]\n",
      " [1.8465344 ]\n",
      " [0.9600061 ]\n",
      " [1.5048462 ]\n",
      " [1.4031262 ]\n",
      " [0.30191475]\n",
      " [0.33670813]]\n",
      "450  Cost:  1.2232242 \n",
      "Prediction: \n",
      " [[2.6569476 ]\n",
      " [2.638698  ]\n",
      " [1.8463161 ]\n",
      " [0.95983976]\n",
      " [1.5046468 ]\n",
      " [1.4029341 ]\n",
      " [0.30179042]\n",
      " [0.3365863 ]]\n",
      "455  Cost:  1.2227936 \n",
      "Prediction: \n",
      " [[2.6566732 ]\n",
      " [2.6384337 ]\n",
      " [1.8460977 ]\n",
      " [0.9596733 ]\n",
      " [1.5044475 ]\n",
      " [1.4027417 ]\n",
      " [0.30166608]\n",
      " [0.3364644 ]]\n",
      "460  Cost:  1.2223632 \n",
      "Prediction: \n",
      " [[2.656399  ]\n",
      " [2.6381693 ]\n",
      " [1.8458793 ]\n",
      " [0.9595068 ]\n",
      " [1.5042479 ]\n",
      " [1.4025495 ]\n",
      " [0.30154175]\n",
      " [0.3363425 ]]\n",
      "465  Cost:  1.2219335 \n",
      "Prediction: \n",
      " [[2.656125  ]\n",
      " [2.6379054 ]\n",
      " [1.845661  ]\n",
      " [0.95934033]\n",
      " [1.5040487 ]\n",
      " [1.4023573 ]\n",
      " [0.30141744]\n",
      " [0.3362207 ]]\n",
      "470  Cost:  1.2215035 \n",
      "Prediction: \n",
      " [[2.655851  ]\n",
      " [2.637641  ]\n",
      " [1.845443  ]\n",
      " [0.959174  ]\n",
      " [1.5038494 ]\n",
      " [1.4021652 ]\n",
      " [0.3012932 ]\n",
      " [0.33609897]]\n",
      "475  Cost:  1.2210739 \n",
      "Prediction: \n",
      " [[2.655577  ]\n",
      " [2.637377  ]\n",
      " [1.8452249 ]\n",
      " [0.95900756]\n",
      " [1.5036502 ]\n",
      " [1.4019732 ]\n",
      " [0.30116892]\n",
      " [0.33597714]]\n",
      "480  Cost:  1.220644 \n",
      "Prediction: \n",
      " [[2.6553025 ]\n",
      " [2.6371126 ]\n",
      " [1.8450066 ]\n",
      " [0.95884115]\n",
      " [1.5034509 ]\n",
      " [1.4017811 ]\n",
      " [0.30104464]\n",
      " [0.3358553 ]]\n",
      "485  Cost:  1.2202144 \n",
      "Prediction: \n",
      " [[2.6550286 ]\n",
      " [2.6368487 ]\n",
      " [1.8447883 ]\n",
      " [0.9586748 ]\n",
      " [1.5032516 ]\n",
      " [1.4015889 ]\n",
      " [0.30092043]\n",
      " [0.3357336 ]]\n",
      "490  Cost:  1.2197851 \n",
      "Prediction: \n",
      " [[2.6547546 ]\n",
      " [2.6365848 ]\n",
      " [1.8445702 ]\n",
      " [0.9585085 ]\n",
      " [1.5030522 ]\n",
      " [1.4013969 ]\n",
      " [0.30079627]\n",
      " [0.33561194]]\n",
      "495  Cost:  1.2193558 \n",
      "Prediction: \n",
      " [[2.6544805 ]\n",
      " [2.6363206 ]\n",
      " [1.8443522 ]\n",
      " [0.95834213]\n",
      " [1.5028532 ]\n",
      " [1.4012048 ]\n",
      " [0.30067205]\n",
      " [0.33549017]]\n",
      "500  Cost:  1.2189265 \n",
      "Prediction: \n",
      " [[2.6542065 ]\n",
      " [2.6360567 ]\n",
      " [1.844134  ]\n",
      " [0.95817584]\n",
      " [1.502654  ]\n",
      " [1.4010125 ]\n",
      " [0.3005479 ]\n",
      " [0.3353685 ]]\n",
      "505  Cost:  1.2184975 \n",
      "Prediction: \n",
      " [[2.6539326 ]\n",
      " [2.6357925 ]\n",
      " [1.8439159 ]\n",
      " [0.95800954]\n",
      " [1.5024548 ]\n",
      " [1.4008207 ]\n",
      " [0.30042368]\n",
      " [0.3352468 ]]\n",
      "510  Cost:  1.2180688 \n",
      "Prediction: \n",
      " [[2.6536589 ]\n",
      " [2.6355286 ]\n",
      " [1.843698  ]\n",
      " [0.9578434 ]\n",
      " [1.5022557 ]\n",
      " [1.4006288 ]\n",
      " [0.30029964]\n",
      " [0.3351252 ]]\n",
      "515  Cost:  1.2176402 \n",
      "Prediction: \n",
      " [[2.6533852 ]\n",
      " [2.6352646 ]\n",
      " [1.8434801 ]\n",
      " [0.95767725]\n",
      " [1.5020567 ]\n",
      " [1.4004369 ]\n",
      " [0.3001756 ]\n",
      " [0.33500353]]\n",
      "520  Cost:  1.2172118 \n",
      "Prediction: \n",
      " [[2.6531112 ]\n",
      " [2.6350012 ]\n",
      " [1.8432623 ]\n",
      " [0.957511  ]\n",
      " [1.5018579 ]\n",
      " [1.4002452 ]\n",
      " [0.30005157]\n",
      " [0.3348819 ]]\n",
      "525  Cost:  1.2167838 \n",
      "Prediction: \n",
      " [[2.652838 ]\n",
      " [2.6347375]\n",
      " [1.8430445]\n",
      " [0.9573452]\n",
      " [1.5016589]\n",
      " [1.4000533]\n",
      " [0.2999276]\n",
      " [0.3347603]]\n",
      "530  Cost:  1.2163562 \n",
      "Prediction: \n",
      " [[2.6525648 ]\n",
      " [2.634474  ]\n",
      " [1.8428268 ]\n",
      " [0.9571791 ]\n",
      " [1.5014603 ]\n",
      " [1.3998618 ]\n",
      " [0.29980367]\n",
      " [0.33463883]]\n",
      "535  Cost:  1.2159287 \n",
      "Prediction: \n",
      " [[2.6522913 ]\n",
      " [2.6342108 ]\n",
      " [1.8426094 ]\n",
      " [0.9570133 ]\n",
      " [1.5012617 ]\n",
      " [1.3996704 ]\n",
      " [0.29967982]\n",
      " [0.33451742]]\n",
      "540  Cost:  1.2155014 \n",
      "Prediction: \n",
      " [[2.652018  ]\n",
      " [2.6339476 ]\n",
      " [1.842392  ]\n",
      " [0.95684737]\n",
      " [1.5010631 ]\n",
      " [1.3994789 ]\n",
      " [0.2995559 ]\n",
      " [0.33439606]]\n",
      "545  Cost:  1.2150741 \n",
      "Prediction: \n",
      " [[2.6517448]\n",
      " [2.6336844]\n",
      " [1.8421745]\n",
      " [0.9566815]\n",
      " [1.5008643]\n",
      " [1.3992873]\n",
      " [0.2994321]\n",
      " [0.3342747]]\n",
      "550  Cost:  1.2146473 \n",
      "Prediction: \n",
      " [[2.6514719 ]\n",
      " [2.6334214 ]\n",
      " [1.8419571 ]\n",
      " [0.9565158 ]\n",
      " [1.5006659 ]\n",
      " [1.3990959 ]\n",
      " [0.29930833]\n",
      " [0.33415338]]\n",
      "555  Cost:  1.2142204 \n",
      "Prediction: \n",
      " [[2.6511986 ]\n",
      " [2.6331584 ]\n",
      " [1.8417398 ]\n",
      " [0.9563499 ]\n",
      " [1.5004672 ]\n",
      " [1.3989043 ]\n",
      " [0.2991845 ]\n",
      " [0.33403206]]\n",
      "560  Cost:  1.2137939 \n",
      "Prediction: \n",
      " [[2.6509256 ]\n",
      " [2.6328955 ]\n",
      " [1.8415226 ]\n",
      " [0.95618427]\n",
      " [1.5002688 ]\n",
      " [1.3987131 ]\n",
      " [0.2990607 ]\n",
      " [0.33391076]]\n",
      "565  Cost:  1.2133675 \n",
      "Prediction: \n",
      " [[2.650653  ]\n",
      " [2.6326325 ]\n",
      " [1.8413054 ]\n",
      " [0.9560185 ]\n",
      " [1.5000705 ]\n",
      " [1.3985217 ]\n",
      " [0.29893702]\n",
      " [0.3337896 ]]\n",
      "570  Cost:  1.2129414 \n",
      "Prediction: \n",
      " [[2.6503801 ]\n",
      " [2.63237   ]\n",
      " [1.8410883 ]\n",
      " [0.9558529 ]\n",
      " [1.499872  ]\n",
      " [1.3983307 ]\n",
      " [0.29881328]\n",
      " [0.3336683 ]]\n",
      "575  Cost:  1.2125151 \n",
      "Prediction: \n",
      " [[2.6501071 ]\n",
      " [2.632107  ]\n",
      " [1.8408711 ]\n",
      " [0.9556873 ]\n",
      " [1.4996737 ]\n",
      " [1.3981392 ]\n",
      " [0.29868954]\n",
      " [0.33354712]]\n",
      "580  Cost:  1.2120891 \n",
      "Prediction: \n",
      " [[2.6498342 ]\n",
      " [2.631844  ]\n",
      " [1.8406539 ]\n",
      " [0.95552164]\n",
      " [1.4994752 ]\n",
      " [1.397948  ]\n",
      " [0.29856586]\n",
      " [0.33342588]]\n",
      "585  Cost:  1.2116632 \n",
      "Prediction: \n",
      " [[2.6495616 ]\n",
      " [2.6315813 ]\n",
      " [1.8404368 ]\n",
      " [0.955356  ]\n",
      " [1.499277  ]\n",
      " [1.3977568 ]\n",
      " [0.29844216]\n",
      " [0.33330473]]\n",
      "590  Cost:  1.2112374 \n",
      "Prediction: \n",
      " [[2.649289  ]\n",
      " [2.6313183 ]\n",
      " [1.8402197 ]\n",
      " [0.9551904 ]\n",
      " [1.4990786 ]\n",
      " [1.3975658 ]\n",
      " [0.2983185 ]\n",
      " [0.33318353]]\n",
      "595  Cost:  1.2108117 \n",
      "Prediction: \n",
      " [[2.649016  ]\n",
      " [2.6310558 ]\n",
      " [1.8400027 ]\n",
      " [0.95502484]\n",
      " [1.4988804 ]\n",
      " [1.3973745 ]\n",
      " [0.2981949 ]\n",
      " [0.3330624 ]]\n",
      "600  Cost:  1.2103863 \n",
      "Prediction: \n",
      " [[2.6487432 ]\n",
      " [2.630793  ]\n",
      " [1.8397856 ]\n",
      " [0.95485926]\n",
      " [1.498682  ]\n",
      " [1.3971834 ]\n",
      " [0.29807124]\n",
      " [0.33294132]]\n",
      "605  Cost:  1.2099609 \n",
      "Prediction: \n",
      " [[2.6484706 ]\n",
      " [2.6305304 ]\n",
      " [1.8395686 ]\n",
      " [0.9546938 ]\n",
      " [1.498484  ]\n",
      " [1.3969924 ]\n",
      " [0.29794767]\n",
      " [0.3328202 ]]\n",
      "610  Cost:  1.2095356 \n",
      "Prediction: \n",
      " [[2.6481981 ]\n",
      " [2.6302676 ]\n",
      " [1.8393515 ]\n",
      " [0.9545282 ]\n",
      " [1.4982857 ]\n",
      " [1.3968012 ]\n",
      " [0.2978241 ]\n",
      " [0.33269915]]\n",
      "615  Cost:  1.2091103 \n",
      "Prediction: \n",
      " [[2.6479251 ]\n",
      " [2.6300046 ]\n",
      " [1.8391346 ]\n",
      " [0.95436275]\n",
      " [1.4980875 ]\n",
      " [1.3966101 ]\n",
      " [0.2977005 ]\n",
      " [0.33257803]]\n",
      "620  Cost:  1.2086853 \n",
      "Prediction: \n",
      " [[2.6476524 ]\n",
      " [2.6297424 ]\n",
      " [1.8389176 ]\n",
      " [0.9541972 ]\n",
      " [1.4978893 ]\n",
      " [1.396419  ]\n",
      " [0.29757696]\n",
      " [0.332457  ]]\n",
      "625  Cost:  1.2082603 \n",
      "Prediction: \n",
      " [[2.6473799 ]\n",
      " [2.6294796 ]\n",
      " [1.8387007 ]\n",
      " [0.9540318 ]\n",
      " [1.4976912 ]\n",
      " [1.396228  ]\n",
      " [0.2974535 ]\n",
      " [0.33233604]]\n",
      "630  Cost:  1.2078354 \n",
      "Prediction: \n",
      " [[2.6471074 ]\n",
      " [2.629217  ]\n",
      " [1.8384837 ]\n",
      " [0.95386636]\n",
      " [1.4974929 ]\n",
      " [1.396037  ]\n",
      " [0.29732996]\n",
      " [0.332215  ]]\n",
      "635  Cost:  1.2074107 \n",
      "Prediction: \n",
      " [[2.6468349 ]\n",
      " [2.6289544 ]\n",
      " [1.8382665 ]\n",
      " [0.9537009 ]\n",
      " [1.4972948 ]\n",
      " [1.395846  ]\n",
      " [0.29720646]\n",
      " [0.33209395]]\n",
      "640  Cost:  1.2069862 \n",
      "Prediction: \n",
      " [[2.646562  ]\n",
      " [2.6286917 ]\n",
      " [1.8380499 ]\n",
      " [0.9535355 ]\n",
      " [1.4970968 ]\n",
      " [1.395655  ]\n",
      " [0.29708302]\n",
      " [0.33197302]]\n",
      "645  Cost:  1.206562 \n",
      "Prediction: \n",
      " [[2.6462898 ]\n",
      " [2.6284297 ]\n",
      " [1.8378332 ]\n",
      " [0.9533704 ]\n",
      " [1.4968988 ]\n",
      " [1.3954642 ]\n",
      " [0.2969597 ]\n",
      " [0.33185214]]\n",
      "650  Cost:  1.2061383 \n",
      "Prediction: \n",
      " [[2.6460178 ]\n",
      " [2.6281674 ]\n",
      " [1.8376166 ]\n",
      " [0.9532051 ]\n",
      " [1.4967009 ]\n",
      " [1.3952734 ]\n",
      " [0.29683632]\n",
      " [0.33173114]]\n",
      "655  Cost:  1.2057142 \n",
      "Prediction: \n",
      " [[2.6457455 ]\n",
      " [2.627905  ]\n",
      " [1.8373997 ]\n",
      " [0.9530399 ]\n",
      " [1.4965031 ]\n",
      " [1.3950825 ]\n",
      " [0.29671293]\n",
      " [0.33161026]]\n",
      "660  Cost:  1.2052906 \n",
      "Prediction: \n",
      " [[2.6454735 ]\n",
      " [2.6276426 ]\n",
      " [1.8371831 ]\n",
      " [0.95287466]\n",
      " [1.4963051 ]\n",
      " [1.3948917 ]\n",
      " [0.29658964]\n",
      " [0.33148935]]\n",
      "665  Cost:  1.2048669 \n",
      "Prediction: \n",
      " [[2.6452012 ]\n",
      " [2.6273804 ]\n",
      " [1.8369666 ]\n",
      " [0.9527095 ]\n",
      " [1.4961075 ]\n",
      " [1.3947011 ]\n",
      " [0.29646635]\n",
      " [0.3313685 ]]\n",
      "670  Cost:  1.2044437 \n",
      "Prediction: \n",
      " [[2.6449292 ]\n",
      " [2.6271183 ]\n",
      " [1.8367503 ]\n",
      " [0.95254445]\n",
      " [1.4959097 ]\n",
      " [1.3945105 ]\n",
      " [0.2963431 ]\n",
      " [0.3312477 ]]\n",
      "675  Cost:  1.2040207 \n",
      "Prediction: \n",
      " [[2.6446576 ]\n",
      " [2.6268563 ]\n",
      " [1.8365338 ]\n",
      " [0.9523794 ]\n",
      " [1.495712  ]\n",
      " [1.39432   ]\n",
      " [0.29621986]\n",
      " [0.3311268 ]]\n",
      "680  Cost:  1.2035975 \n",
      "Prediction: \n",
      " [[2.6443856 ]\n",
      " [2.6265943 ]\n",
      " [1.8363173 ]\n",
      " [0.95221454]\n",
      " [1.4955144 ]\n",
      " [1.3941293 ]\n",
      " [0.29609665]\n",
      " [0.33100605]]\n",
      "685  Cost:  1.203175 \n",
      "Prediction: \n",
      " [[2.644114  ]\n",
      " [2.6263323 ]\n",
      " [1.8361008 ]\n",
      " [0.95204955]\n",
      " [1.495317  ]\n",
      " [1.393939  ]\n",
      " [0.29597348]\n",
      " [0.33088523]]\n",
      "690  Cost:  1.2027521 \n",
      "Prediction: \n",
      " [[2.643842  ]\n",
      " [2.6260705 ]\n",
      " [1.8358846 ]\n",
      " [0.95188457]\n",
      " [1.4951191 ]\n",
      " [1.3937485 ]\n",
      " [0.29585034]\n",
      " [0.33076447]]\n",
      "695  Cost:  1.2023296 \n",
      "Prediction: \n",
      " [[2.6435704 ]\n",
      " [2.6258085 ]\n",
      " [1.8356681 ]\n",
      " [0.9517196 ]\n",
      " [1.4949218 ]\n",
      " [1.3935579 ]\n",
      " [0.29572713]\n",
      " [0.3306437 ]]\n",
      "700  Cost:  1.2019069 \n",
      "Prediction: \n",
      " [[2.6432984 ]\n",
      " [2.6255465 ]\n",
      " [1.8354518 ]\n",
      " [0.9515548 ]\n",
      " [1.494724  ]\n",
      " [1.3933674 ]\n",
      " [0.29560402]\n",
      " [0.33052298]]\n",
      "705  Cost:  1.2014848 \n",
      "Prediction: \n",
      " [[2.6430268 ]\n",
      " [2.6252847 ]\n",
      " [1.8352357 ]\n",
      " [0.9513898 ]\n",
      " [1.4945265 ]\n",
      " [1.3931769 ]\n",
      " [0.29548097]\n",
      " [0.33040226]]\n",
      "710  Cost:  1.201063 \n",
      "Prediction: \n",
      " [[2.6427555 ]\n",
      " [2.6250231 ]\n",
      " [1.8350196 ]\n",
      " [0.951225  ]\n",
      " [1.4943292 ]\n",
      " [1.3929868 ]\n",
      " [0.29535782]\n",
      " [0.33028162]]\n",
      "715  Cost:  1.200641 \n",
      "Prediction: \n",
      " [[2.642484  ]\n",
      " [2.6247613 ]\n",
      " [1.8348033 ]\n",
      " [0.9510601 ]\n",
      " [1.4941318 ]\n",
      " [1.3927964 ]\n",
      " [0.29523474]\n",
      " [0.33016098]]\n",
      "720  Cost:  1.2002195 \n",
      "Prediction: \n",
      " [[2.6422126 ]\n",
      " [2.6244998 ]\n",
      " [1.8345873 ]\n",
      " [0.9508955 ]\n",
      " [1.4939346 ]\n",
      " [1.3926063 ]\n",
      " [0.29511172]\n",
      " [0.33004028]]\n",
      "725  Cost:  1.1997981 \n",
      "Prediction: \n",
      " [[2.6419413 ]\n",
      " [2.6242385 ]\n",
      " [1.8343712 ]\n",
      " [0.9507308 ]\n",
      " [1.4937373 ]\n",
      " [1.3924159 ]\n",
      " [0.29498875]\n",
      " [0.32991987]]\n",
      "730  Cost:  1.1993771 \n",
      "Prediction: \n",
      " [[2.6416702 ]\n",
      " [2.6239772 ]\n",
      " [1.8341553 ]\n",
      " [0.95056605]\n",
      " [1.4935399 ]\n",
      " [1.3922259 ]\n",
      " [0.29486573]\n",
      " [0.3297994 ]]\n",
      "735  Cost:  1.1989561 \n",
      "Prediction: \n",
      " [[2.641399  ]\n",
      " [2.623716  ]\n",
      " [1.8339396 ]\n",
      " [0.9504014 ]\n",
      " [1.4933429 ]\n",
      " [1.3920358 ]\n",
      " [0.29474285]\n",
      " [0.32967898]]\n",
      "740  Cost:  1.1985352 \n",
      "Prediction: \n",
      " [[2.6411276 ]\n",
      " [2.6234548 ]\n",
      " [1.8337238 ]\n",
      " [0.95023674]\n",
      " [1.4931457 ]\n",
      " [1.3918457 ]\n",
      " [0.29461992]\n",
      " [0.3295586 ]]\n",
      "745  Cost:  1.1981143 \n",
      "Prediction: \n",
      " [[2.6408563 ]\n",
      " [2.6231935 ]\n",
      " [1.833508  ]\n",
      " [0.9500721 ]\n",
      " [1.4929485 ]\n",
      " [1.3916557 ]\n",
      " [0.294497  ]\n",
      " [0.32943827]]\n",
      "750  Cost:  1.1976933 \n",
      "Prediction: \n",
      " [[2.640585  ]\n",
      " [2.6229322 ]\n",
      " [1.8332919 ]\n",
      " [0.9499075 ]\n",
      " [1.4927512 ]\n",
      " [1.3914655 ]\n",
      " [0.29437417]\n",
      " [0.32931787]]\n",
      "755  Cost:  1.1972728 \n",
      "Prediction: \n",
      " [[2.6403136 ]\n",
      " [2.622671  ]\n",
      " [1.8330762 ]\n",
      " [0.94974303]\n",
      " [1.4925542 ]\n",
      " [1.3912755 ]\n",
      " [0.29425132]\n",
      " [0.32919756]]\n",
      "760  Cost:  1.1968522 \n",
      "Prediction: \n",
      " [[2.6400423 ]\n",
      " [2.6224096 ]\n",
      " [1.8328605 ]\n",
      " [0.9495784 ]\n",
      " [1.4923571 ]\n",
      " [1.3910856 ]\n",
      " [0.29412848]\n",
      " [0.32907727]]\n",
      "765  Cost:  1.1964319 \n",
      "Prediction: \n",
      " [[2.6397712 ]\n",
      " [2.6221485 ]\n",
      " [1.8326446 ]\n",
      " [0.9494139 ]\n",
      " [1.4921602 ]\n",
      " [1.3908956 ]\n",
      " [0.29400566]\n",
      " [0.32895693]]\n",
      "770  Cost:  1.1960118 \n",
      "Prediction: \n",
      " [[2.6395004 ]\n",
      " [2.6218874 ]\n",
      " [1.8324288 ]\n",
      " [0.94924927]\n",
      " [1.491963  ]\n",
      " [1.3907055 ]\n",
      " [0.29388282]\n",
      " [0.32883665]]\n",
      "775  Cost:  1.1955917 \n",
      "Prediction: \n",
      " [[2.639229  ]\n",
      " [2.6216264 ]\n",
      " [1.8322134 ]\n",
      " [0.9490849 ]\n",
      " [1.491766  ]\n",
      " [1.3905156 ]\n",
      " [0.29376015]\n",
      " [0.32871643]]\n",
      "780  Cost:  1.1951721 \n",
      "Prediction: \n",
      " [[2.6389585 ]\n",
      " [2.6213655 ]\n",
      " [1.8319978 ]\n",
      " [0.94892067]\n",
      " [1.4915692 ]\n",
      " [1.3903259 ]\n",
      " [0.29363745]\n",
      " [0.32859617]]\n",
      "785  Cost:  1.1947526 \n",
      "Prediction: \n",
      " [[2.6386876 ]\n",
      " [2.6211047 ]\n",
      " [1.8317823 ]\n",
      " [0.9487563 ]\n",
      " [1.4913723 ]\n",
      " [1.390136  ]\n",
      " [0.29351473]\n",
      " [0.32847595]]\n",
      "790  Cost:  1.1943333 \n",
      "Prediction: \n",
      " [[2.6384168 ]\n",
      " [2.620844  ]\n",
      " [1.831567  ]\n",
      " [0.9485919 ]\n",
      " [1.4911757 ]\n",
      " [1.3899463 ]\n",
      " [0.29339206]\n",
      " [0.32835567]]\n",
      "795  Cost:  1.1939137 \n",
      "Prediction: \n",
      " [[2.638146  ]\n",
      " [2.620583  ]\n",
      " [1.8313512 ]\n",
      " [0.9484276 ]\n",
      " [1.4909788 ]\n",
      " [1.3897566 ]\n",
      " [0.29326946]\n",
      " [0.32823557]]\n",
      "800  Cost:  1.1934948 \n",
      "Prediction: \n",
      " [[2.6378753 ]\n",
      " [2.6203222 ]\n",
      " [1.8311359 ]\n",
      " [0.9482633 ]\n",
      " [1.4907821 ]\n",
      " [1.3895669 ]\n",
      " [0.29314685]\n",
      " [0.32811534]]\n",
      "805  Cost:  1.1930755 \n",
      "Prediction: \n",
      " [[2.6376045 ]\n",
      " [2.6200612 ]\n",
      " [1.8309206 ]\n",
      " [0.94809914]\n",
      " [1.4905853 ]\n",
      " [1.3893772 ]\n",
      " [0.29302424]\n",
      " [0.32799524]]\n",
      "810  Cost:  1.1926569 \n",
      "Prediction: \n",
      " [[2.6373339 ]\n",
      " [2.6198008 ]\n",
      " [1.8307055 ]\n",
      " [0.94793487]\n",
      " [1.4903886 ]\n",
      " [1.3891877 ]\n",
      " [0.29290166]\n",
      " [0.3278751 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815  Cost:  1.1922386 \n",
      "Prediction: \n",
      " [[2.6370635 ]\n",
      " [2.6195405 ]\n",
      " [1.83049   ]\n",
      " [0.94777083]\n",
      " [1.490192  ]\n",
      " [1.3889983 ]\n",
      " [0.2927792 ]\n",
      " [0.32775497]]\n",
      "820  Cost:  1.1918201 \n",
      "Prediction: \n",
      " [[2.6367934 ]\n",
      " [2.6192799 ]\n",
      " [1.8302748 ]\n",
      " [0.9476066 ]\n",
      " [1.4899957 ]\n",
      " [1.3888087 ]\n",
      " [0.29265666]\n",
      " [0.32763493]]\n",
      "825  Cost:  1.1914017 \n",
      "Prediction: \n",
      " [[2.6365228 ]\n",
      " [2.6190193 ]\n",
      " [1.8300598 ]\n",
      " [0.94744265]\n",
      " [1.489799  ]\n",
      " [1.3886193 ]\n",
      " [0.29253417]\n",
      " [0.3275149 ]]\n",
      "830  Cost:  1.1909835 \n",
      "Prediction: \n",
      " [[2.6362524 ]\n",
      " [2.6187587 ]\n",
      " [1.8298445 ]\n",
      " [0.94727856]\n",
      " [1.4896024 ]\n",
      " [1.3884298 ]\n",
      " [0.29241168]\n",
      " [0.32739478]]\n",
      "835  Cost:  1.1905656 \n",
      "Prediction: \n",
      " [[2.6359823 ]\n",
      " [2.6184983 ]\n",
      " [1.8296293 ]\n",
      " [0.9471145 ]\n",
      " [1.489406  ]\n",
      " [1.3882403 ]\n",
      " [0.29228926]\n",
      " [0.3272748 ]]\n",
      "840  Cost:  1.1901476 \n",
      "Prediction: \n",
      " [[2.635712  ]\n",
      " [2.6182377 ]\n",
      " [1.8294141 ]\n",
      " [0.9469505 ]\n",
      " [1.4892097 ]\n",
      " [1.3880508 ]\n",
      " [0.29216683]\n",
      " [0.32715482]]\n",
      "845  Cost:  1.1897299 \n",
      "Prediction: \n",
      " [[2.6354415 ]\n",
      " [2.6179776 ]\n",
      " [1.829199  ]\n",
      " [0.9467866 ]\n",
      " [1.4890131 ]\n",
      " [1.3878616 ]\n",
      " [0.29204446]\n",
      " [0.32703477]]\n",
      "850  Cost:  1.1893122 \n",
      "Prediction: \n",
      " [[2.6351712 ]\n",
      " [2.617717  ]\n",
      " [1.8289841 ]\n",
      " [0.94662243]\n",
      " [1.4888167 ]\n",
      " [1.3876723 ]\n",
      " [0.29192203]\n",
      " [0.3269148 ]]\n",
      "855  Cost:  1.1888945 \n",
      "Prediction: \n",
      " [[2.6349008 ]\n",
      " [2.6174567 ]\n",
      " [1.828769  ]\n",
      " [0.94645846]\n",
      " [1.4886203 ]\n",
      " [1.3874828 ]\n",
      " [0.29179963]\n",
      " [0.3267949 ]]\n",
      "860  Cost:  1.1884775 \n",
      "Prediction: \n",
      " [[2.6346312 ]\n",
      " [2.6171966 ]\n",
      " [1.8285539 ]\n",
      " [0.94629467]\n",
      " [1.4884241 ]\n",
      " [1.3872936 ]\n",
      " [0.2916773 ]\n",
      " [0.32667494]]\n",
      "865  Cost:  1.1880606 \n",
      "Prediction: \n",
      " [[2.6343613 ]\n",
      " [2.6169364 ]\n",
      " [1.8283393 ]\n",
      " [0.9461308 ]\n",
      " [1.4882278 ]\n",
      " [1.3871043 ]\n",
      " [0.291555  ]\n",
      " [0.32655507]]\n",
      "870  Cost:  1.1876438 \n",
      "Prediction: \n",
      " [[2.6340914 ]\n",
      " [2.6166763 ]\n",
      " [1.8281244 ]\n",
      " [0.945967  ]\n",
      " [1.4880315 ]\n",
      " [1.3869152 ]\n",
      " [0.29143268]\n",
      " [0.3264352 ]]\n",
      "875  Cost:  1.1872268 \n",
      "Prediction: \n",
      " [[2.6338212 ]\n",
      " [2.6164162 ]\n",
      " [1.8279095 ]\n",
      " [0.9458032 ]\n",
      " [1.4878354 ]\n",
      " [1.3867261 ]\n",
      " [0.29131037]\n",
      " [0.32631528]]\n",
      "880  Cost:  1.1868101 \n",
      "Prediction: \n",
      " [[2.6335516 ]\n",
      " [2.6161559 ]\n",
      " [1.8276947 ]\n",
      " [0.9456395 ]\n",
      " [1.4876392 ]\n",
      " [1.386537  ]\n",
      " [0.29118812]\n",
      " [0.32619554]]\n",
      "885  Cost:  1.1863936 \n",
      "Prediction: \n",
      " [[2.6332817 ]\n",
      " [2.615896  ]\n",
      " [1.8274798 ]\n",
      " [0.9454757 ]\n",
      " [1.487443  ]\n",
      " [1.3863478 ]\n",
      " [0.2910658 ]\n",
      " [0.32607567]]\n",
      "890  Cost:  1.1859772 \n",
      "Prediction: \n",
      " [[2.6330118 ]\n",
      " [2.6156359 ]\n",
      " [1.8272651 ]\n",
      " [0.945312  ]\n",
      " [1.4872469 ]\n",
      " [1.3861588 ]\n",
      " [0.2909436 ]\n",
      " [0.32595584]]\n",
      "895  Cost:  1.185561 \n",
      "Prediction: \n",
      " [[2.632742  ]\n",
      " [2.615376  ]\n",
      " [1.8270502 ]\n",
      " [0.9451483 ]\n",
      " [1.4870508 ]\n",
      " [1.3859698 ]\n",
      " [0.29082137]\n",
      " [0.32583612]]\n",
      "900  Cost:  1.1851444 \n",
      "Prediction: \n",
      " [[2.6324723 ]\n",
      " [2.6151156 ]\n",
      " [1.8268356 ]\n",
      " [0.9449846 ]\n",
      " [1.4868546 ]\n",
      " [1.3857806 ]\n",
      " [0.29069918]\n",
      " [0.32571638]]\n",
      "905  Cost:  1.1847286 \n",
      "Prediction: \n",
      " [[2.6322026 ]\n",
      " [2.614856  ]\n",
      " [1.8266207 ]\n",
      " [0.9448208 ]\n",
      " [1.4866586 ]\n",
      " [1.3855915 ]\n",
      " [0.290577  ]\n",
      " [0.32559663]]\n",
      "910  Cost:  1.1843129 \n",
      "Prediction: \n",
      " [[2.631933  ]\n",
      " [2.6145961 ]\n",
      " [1.8264064 ]\n",
      " [0.94465744]\n",
      " [1.4864627 ]\n",
      " [1.3854027 ]\n",
      " [0.29045492]\n",
      " [0.3254769 ]]\n",
      "915  Cost:  1.1838975 \n",
      "Prediction: \n",
      " [[2.6316636 ]\n",
      " [2.6143365 ]\n",
      " [1.8261919 ]\n",
      " [0.9444939 ]\n",
      " [1.4862669 ]\n",
      " [1.3852139 ]\n",
      " [0.29033288]\n",
      " [0.32535723]]\n",
      "920  Cost:  1.1834824 \n",
      "Prediction: \n",
      " [[2.6313944 ]\n",
      " [2.614077  ]\n",
      " [1.8259776 ]\n",
      " [0.94433045]\n",
      " [1.4860711 ]\n",
      " [1.3850251 ]\n",
      " [0.29021087]\n",
      " [0.32523772]]\n",
      "925  Cost:  1.1830676 \n",
      "Prediction: \n",
      " [[2.631125  ]\n",
      " [2.6138177 ]\n",
      " [1.8257633 ]\n",
      " [0.944167  ]\n",
      " [1.4858752 ]\n",
      " [1.3848364 ]\n",
      " [0.29008886]\n",
      " [0.32511815]]\n",
      "930  Cost:  1.1826525 \n",
      "Prediction: \n",
      " [[2.6308556]\n",
      " [2.6135583]\n",
      " [1.8255488]\n",
      " [0.9440036]\n",
      " [1.4856795]\n",
      " [1.3846477]\n",
      " [0.2899669]\n",
      " [0.3249987]]\n",
      "935  Cost:  1.1822376 \n",
      "Prediction: \n",
      " [[2.6305861 ]\n",
      " [2.613299  ]\n",
      " [1.8253347 ]\n",
      " [0.9438402 ]\n",
      " [1.4854838 ]\n",
      " [1.3844589 ]\n",
      " [0.289845  ]\n",
      " [0.32487923]]\n",
      "940  Cost:  1.1818231 \n",
      "Prediction: \n",
      " [[2.630317  ]\n",
      " [2.6130395 ]\n",
      " [1.8251204 ]\n",
      " [0.9436769 ]\n",
      " [1.4852881 ]\n",
      " [1.3842704 ]\n",
      " [0.28972307]\n",
      " [0.32475978]]\n",
      "945  Cost:  1.1814086 \n",
      "Prediction: \n",
      " [[2.6300476 ]\n",
      " [2.6127803 ]\n",
      " [1.8249063 ]\n",
      " [0.94351345]\n",
      " [1.4850924 ]\n",
      " [1.3840818 ]\n",
      " [0.28960115]\n",
      " [0.32464033]]\n",
      "950  Cost:  1.1809943 \n",
      "Prediction: \n",
      " [[2.6297784 ]\n",
      " [2.6125212 ]\n",
      " [1.824692  ]\n",
      " [0.94335014]\n",
      " [1.4848968 ]\n",
      " [1.3838931 ]\n",
      " [0.28947932]\n",
      " [0.324521  ]]\n",
      "955  Cost:  1.1805804 \n",
      "Prediction: \n",
      " [[2.6295094 ]\n",
      " [2.612262  ]\n",
      " [1.8244783 ]\n",
      " [0.9431869 ]\n",
      " [1.4847014 ]\n",
      " [1.3837047 ]\n",
      " [0.28935748]\n",
      " [0.32440156]]\n",
      "960  Cost:  1.1801664 \n",
      "Prediction: \n",
      " [[2.6292405 ]\n",
      " [2.6120028 ]\n",
      " [1.824264  ]\n",
      " [0.9430237 ]\n",
      " [1.4845059 ]\n",
      " [1.3835162 ]\n",
      " [0.28923565]\n",
      " [0.32428223]]\n",
      "965  Cost:  1.1797525 \n",
      "Prediction: \n",
      " [[2.6289713 ]\n",
      " [2.6117437 ]\n",
      " [1.8240501 ]\n",
      " [0.94286054]\n",
      " [1.4843105 ]\n",
      " [1.3833278 ]\n",
      " [0.28911388]\n",
      " [0.32416284]]\n",
      "970  Cost:  1.1793389 \n",
      "Prediction: \n",
      " [[2.6287026]\n",
      " [2.6114848]\n",
      " [1.8238361]\n",
      " [0.9426973]\n",
      " [1.4841151]\n",
      " [1.3831394]\n",
      " [0.2889921]\n",
      " [0.3240435]]\n",
      "975  Cost:  1.1789253 \n",
      "Prediction: \n",
      " [[2.6284337 ]\n",
      " [2.6112258 ]\n",
      " [1.8236221 ]\n",
      " [0.94253427]\n",
      " [1.4839195 ]\n",
      " [1.3829509 ]\n",
      " [0.2888704 ]\n",
      " [0.32392424]]\n",
      "980  Cost:  1.1785119 \n",
      "Prediction: \n",
      " [[2.6281648 ]\n",
      " [2.6109667 ]\n",
      " [1.8234082 ]\n",
      " [0.94237113]\n",
      " [1.4837242 ]\n",
      " [1.3827627 ]\n",
      " [0.28874862]\n",
      " [0.32380494]]\n",
      "985  Cost:  1.1780987 \n",
      "Prediction: \n",
      " [[2.6278958 ]\n",
      " [2.6107078 ]\n",
      " [1.8231943 ]\n",
      " [0.94220805]\n",
      " [1.4835289 ]\n",
      " [1.3825742 ]\n",
      " [0.28862688]\n",
      " [0.32368562]]\n",
      "990  Cost:  1.1776855 \n",
      "Prediction: \n",
      " [[2.6276271 ]\n",
      " [2.6104488 ]\n",
      " [1.8229804 ]\n",
      " [0.94204485]\n",
      " [1.4833336 ]\n",
      " [1.382386  ]\n",
      " [0.28850523]\n",
      " [0.3235664 ]]\n",
      "995  Cost:  1.1772726 \n",
      "Prediction: \n",
      " [[2.6273582 ]\n",
      " [2.6101902 ]\n",
      " [1.8227665 ]\n",
      " [0.9418819 ]\n",
      " [1.4831383 ]\n",
      " [1.3821976 ]\n",
      " [0.28838354]\n",
      " [0.3234472 ]]\n",
      "1000  Cost:  1.1768594 \n",
      "Prediction: \n",
      " [[2.6270895 ]\n",
      " [2.609931  ]\n",
      " [1.8225529 ]\n",
      " [0.9417188 ]\n",
      " [1.4829428 ]\n",
      " [1.3820093 ]\n",
      " [0.28826186]\n",
      " [0.32332793]]\n",
      "1005  Cost:  1.1764467 \n",
      "Prediction: \n",
      " [[2.6268206 ]\n",
      " [2.6096723 ]\n",
      " [1.8223388 ]\n",
      " [0.9415558 ]\n",
      " [1.4827476 ]\n",
      " [1.381821  ]\n",
      " [0.28814024]\n",
      " [0.32320875]]\n",
      "1010  Cost:  1.1760342 \n",
      "Prediction: \n",
      " [[2.626552  ]\n",
      " [2.6094136 ]\n",
      " [1.8221251 ]\n",
      " [0.9413929 ]\n",
      " [1.4825524 ]\n",
      " [1.3816329 ]\n",
      " [0.28801864]\n",
      " [0.3230896 ]]\n",
      "1015  Cost:  1.175622 \n",
      "Prediction: \n",
      " [[2.6262836 ]\n",
      " [2.609155  ]\n",
      " [1.8219118 ]\n",
      " [0.94123   ]\n",
      " [1.4823573 ]\n",
      " [1.3814449 ]\n",
      " [0.28789705]\n",
      " [0.32297045]]\n",
      "1020  Cost:  1.1752098 \n",
      "Prediction: \n",
      " [[2.6260152 ]\n",
      " [2.6088963 ]\n",
      " [1.821698  ]\n",
      " [0.9410671 ]\n",
      " [1.4821621 ]\n",
      " [1.3812567 ]\n",
      " [0.28777546]\n",
      " [0.32285133]]\n",
      "1025  Cost:  1.1747975 \n",
      "Prediction: \n",
      " [[2.6257467 ]\n",
      " [2.6086376 ]\n",
      " [1.8214842 ]\n",
      " [0.94090414]\n",
      " [1.4819671 ]\n",
      " [1.3810686 ]\n",
      " [0.28765386]\n",
      " [0.3227322 ]]\n",
      "1030  Cost:  1.1743855 \n",
      "Prediction: \n",
      " [[2.6254783 ]\n",
      " [2.6083791 ]\n",
      " [1.8212707 ]\n",
      " [0.94074136]\n",
      " [1.481772  ]\n",
      " [1.3808806 ]\n",
      " [0.2875324 ]\n",
      " [0.32261318]]\n",
      "1035  Cost:  1.173974 \n",
      "Prediction: \n",
      " [[2.62521   ]\n",
      " [2.6081207 ]\n",
      " [1.8210573 ]\n",
      " [0.9405785 ]\n",
      " [1.481577  ]\n",
      " [1.3806927 ]\n",
      " [0.28741086]\n",
      " [0.3224941 ]]\n",
      "1040  Cost:  1.1735623 \n",
      "Prediction: \n",
      " [[2.6249416 ]\n",
      " [2.607862  ]\n",
      " [1.8208438 ]\n",
      " [0.94041586]\n",
      " [1.481382  ]\n",
      " [1.3805047 ]\n",
      " [0.28728938]\n",
      " [0.32237506]]\n",
      "1045  Cost:  1.173151 \n",
      "Prediction: \n",
      " [[2.6246736 ]\n",
      " [2.6076038 ]\n",
      " [1.8206303 ]\n",
      " [0.9402532 ]\n",
      " [1.4811871 ]\n",
      " [1.3803167 ]\n",
      " [0.28716797]\n",
      " [0.32225603]]\n",
      "1050  Cost:  1.17274 \n",
      "Prediction: \n",
      " [[2.6244056 ]\n",
      " [2.6073456 ]\n",
      " [1.8204169 ]\n",
      " [0.94009054]\n",
      " [1.4809923 ]\n",
      " [1.380129  ]\n",
      " [0.28704655]\n",
      " [0.32213703]]\n",
      "1055  Cost:  1.1723291 \n",
      "Prediction: \n",
      " [[2.6241379 ]\n",
      " [2.6070871 ]\n",
      " [1.8202038 ]\n",
      " [0.93992794]\n",
      " [1.4807976 ]\n",
      " [1.3799412 ]\n",
      " [0.2869252 ]\n",
      " [0.32201803]]\n",
      "1060  Cost:  1.1719182 \n",
      "Prediction: \n",
      " [[2.6238697 ]\n",
      " [2.606829  ]\n",
      " [1.8199905 ]\n",
      " [0.93976545]\n",
      " [1.4806029 ]\n",
      " [1.3797534 ]\n",
      " [0.2868038 ]\n",
      " [0.32189912]]\n",
      "1065  Cost:  1.1715071 \n",
      "Prediction: \n",
      " [[2.6236017 ]\n",
      " [2.6065705 ]\n",
      " [1.8197773 ]\n",
      " [0.93960273]\n",
      " [1.4804081 ]\n",
      " [1.3795656 ]\n",
      " [0.28668246]\n",
      " [0.32178017]]\n",
      "1070  Cost:  1.1710966 \n",
      "Prediction: \n",
      " [[2.6233337 ]\n",
      " [2.6063125 ]\n",
      " [1.819564  ]\n",
      " [0.93944025]\n",
      " [1.4802133 ]\n",
      " [1.379378  ]\n",
      " [0.28656116]\n",
      " [0.32166126]]\n",
      "1075  Cost:  1.1706862 \n",
      "Prediction: \n",
      " [[2.6230662 ]\n",
      " [2.6060545 ]\n",
      " [1.8193506 ]\n",
      " [0.93927765]\n",
      " [1.4800185 ]\n",
      " [1.3791901 ]\n",
      " [0.28643987]\n",
      " [0.32154235]]\n",
      "1080  Cost:  1.1702757 \n",
      "Prediction: \n",
      " [[2.622798  ]\n",
      " [2.6057963 ]\n",
      " [1.8191376 ]\n",
      " [0.9391153 ]\n",
      " [1.4798238 ]\n",
      " [1.3790025 ]\n",
      " [0.28631854]\n",
      " [0.32142344]]\n",
      "1085  Cost:  1.1698654 \n",
      "Prediction: \n",
      " [[2.62253   ]\n",
      " [2.6055381 ]\n",
      " [1.8189244 ]\n",
      " [0.93895274]\n",
      " [1.4796293 ]\n",
      " [1.3788146 ]\n",
      " [0.2861973 ]\n",
      " [0.32130456]]\n",
      "1090  Cost:  1.1694553 \n",
      "Prediction: \n",
      " [[2.6222622 ]\n",
      " [2.6052802 ]\n",
      " [1.8187112 ]\n",
      " [0.9387903 ]\n",
      " [1.4794346 ]\n",
      " [1.3786271 ]\n",
      " [0.28607607]\n",
      " [0.32118574]]\n",
      "1095  Cost:  1.1690452 \n",
      "Prediction: \n",
      " [[2.6219945 ]\n",
      " [2.6050217 ]\n",
      " [1.8184983 ]\n",
      " [0.93862784]\n",
      " [1.4792401 ]\n",
      " [1.3784394 ]\n",
      " [0.28595483]\n",
      " [0.32106692]]\n",
      "1100  Cost:  1.1686356 \n",
      "Prediction: \n",
      " [[2.621727  ]\n",
      " [2.6047637 ]\n",
      " [1.818285  ]\n",
      " [0.9384656 ]\n",
      " [1.4790456 ]\n",
      " [1.378252  ]\n",
      " [0.28583366]\n",
      " [0.32094806]]\n",
      "1105  Cost:  1.1682262 \n",
      "Prediction: \n",
      " [[2.6214595 ]\n",
      " [2.6045063 ]\n",
      " [1.8180721 ]\n",
      " [0.9383032 ]\n",
      " [1.4788511 ]\n",
      " [1.3780646 ]\n",
      " [0.28571248]\n",
      " [0.32082927]]\n",
      "1110  Cost:  1.1678166 \n",
      "Prediction: \n",
      " [[2.6211922 ]\n",
      " [2.604248  ]\n",
      " [1.8178592 ]\n",
      " [0.9381409 ]\n",
      " [1.4786566 ]\n",
      " [1.377877  ]\n",
      " [0.28559142]\n",
      " [0.32071054]]\n",
      "1115  Cost:  1.1674075 \n",
      "Prediction: \n",
      " [[2.6209247 ]\n",
      " [2.6039906 ]\n",
      " [1.8176464 ]\n",
      " [0.9379786 ]\n",
      " [1.4784623 ]\n",
      " [1.3776897 ]\n",
      " [0.2854703 ]\n",
      " [0.32059187]]\n",
      "1120  Cost:  1.1669984 \n",
      "Prediction: \n",
      " [[2.620657  ]\n",
      " [2.6037328 ]\n",
      " [1.8174337 ]\n",
      " [0.9378165 ]\n",
      " [1.4782679 ]\n",
      " [1.3775023 ]\n",
      " [0.28534925]\n",
      " [0.32047325]]\n",
      "1125  Cost:  1.1665899 \n",
      "Prediction: \n",
      " [[2.62039   ]\n",
      " [2.6034756 ]\n",
      " [1.817221  ]\n",
      " [0.93765414]\n",
      " [1.4780737 ]\n",
      " [1.377315  ]\n",
      " [0.28522825]\n",
      " [0.3203547 ]]\n",
      "1130  Cost:  1.1661812 \n",
      "Prediction: \n",
      " [[2.6201224 ]\n",
      " [2.603218  ]\n",
      " [1.8170085 ]\n",
      " [0.9374921 ]\n",
      " [1.4778795 ]\n",
      " [1.3771279 ]\n",
      " [0.28510725]\n",
      " [0.3202362 ]]\n",
      "1135  Cost:  1.1657724 \n",
      "Prediction: \n",
      " [[2.619855  ]\n",
      " [2.6029606 ]\n",
      " [1.8167956 ]\n",
      " [0.9373299 ]\n",
      " [1.4776852 ]\n",
      " [1.3769406 ]\n",
      " [0.28498632]\n",
      " [0.3201177 ]]\n",
      "1140  Cost:  1.1653638 \n",
      "Prediction: \n",
      " [[2.6195874 ]\n",
      " [2.602703  ]\n",
      " [1.8165829 ]\n",
      " [0.93716764]\n",
      " [1.4774909 ]\n",
      " [1.3767532 ]\n",
      " [0.2848653 ]\n",
      " [0.31999913]]\n",
      "1145  Cost:  1.1649556 \n",
      "Prediction: \n",
      " [[2.6193202 ]\n",
      " [2.6024458 ]\n",
      " [1.8163702 ]\n",
      " [0.93700564]\n",
      " [1.4772967 ]\n",
      " [1.376566  ]\n",
      " [0.28474438]\n",
      " [0.31988066]]\n",
      "1150  Cost:  1.1645474 \n",
      "Prediction: \n",
      " [[2.619053  ]\n",
      " [2.6021883 ]\n",
      " [1.8161578 ]\n",
      " [0.9368435 ]\n",
      " [1.4771025 ]\n",
      " [1.3763789 ]\n",
      " [0.28462344]\n",
      " [0.31976223]]\n",
      "1155  Cost:  1.1641393 \n",
      "Prediction: \n",
      " [[2.6187856 ]\n",
      " [2.601931  ]\n",
      " [1.815945  ]\n",
      " [0.9366814 ]\n",
      " [1.4769083 ]\n",
      " [1.3761916 ]\n",
      " [0.28450257]\n",
      " [0.31964374]]\n",
      "1160  Cost:  1.1637311 \n",
      "Prediction: \n",
      " [[2.618518  ]\n",
      " [2.6016736 ]\n",
      " [1.8157326 ]\n",
      " [0.93651927]\n",
      " [1.4767141 ]\n",
      " [1.3760045 ]\n",
      " [0.28438163]\n",
      " [0.3195253 ]]\n",
      "1165  Cost:  1.1633236 \n",
      "Prediction: \n",
      " [[2.6182513 ]\n",
      " [2.6014163 ]\n",
      " [1.8155202 ]\n",
      " [0.9363574 ]\n",
      " [1.4765203 ]\n",
      " [1.3758175 ]\n",
      " [0.28426078]\n",
      " [0.31940696]]\n",
      "1170  Cost:  1.1629162 \n",
      "Prediction: \n",
      " [[2.6179843 ]\n",
      " [2.6011596 ]\n",
      " [1.8153077 ]\n",
      " [0.93619543]\n",
      " [1.4763261 ]\n",
      " [1.3756305 ]\n",
      " [0.28414   ]\n",
      " [0.3192886 ]]\n",
      "1175  Cost:  1.162509 \n",
      "Prediction: \n",
      " [[2.6177173 ]\n",
      " [2.6009026 ]\n",
      " [1.8150954 ]\n",
      " [0.9360336 ]\n",
      " [1.4761323 ]\n",
      " [1.3754436 ]\n",
      " [0.28401917]\n",
      " [0.3191703 ]]\n",
      "1180  Cost:  1.162102 \n",
      "Prediction: \n",
      " [[2.6174507 ]\n",
      " [2.6006455 ]\n",
      " [1.8148834 ]\n",
      " [0.9358718 ]\n",
      " [1.4759387 ]\n",
      " [1.3752569 ]\n",
      " [0.28389835]\n",
      " [0.31905192]]\n",
      "1185  Cost:  1.1616952 \n",
      "Prediction: \n",
      " [[2.6171842 ]\n",
      " [2.6003885 ]\n",
      " [1.8146712 ]\n",
      " [0.9357101 ]\n",
      " [1.4757448 ]\n",
      " [1.37507   ]\n",
      " [0.2837777 ]\n",
      " [0.31893367]]\n",
      "1190  Cost:  1.1612889 \n",
      "Prediction: \n",
      " [[2.6169178 ]\n",
      " [2.6001322 ]\n",
      " [1.8144592 ]\n",
      " [0.9355484 ]\n",
      " [1.475551  ]\n",
      " [1.3748832 ]\n",
      " [0.28365695]\n",
      " [0.31881535]]\n",
      "1195  Cost:  1.1608821 \n",
      "Prediction: \n",
      " [[2.616651  ]\n",
      " [2.5998752 ]\n",
      " [1.8142469 ]\n",
      " [0.9353866 ]\n",
      " [1.4753573 ]\n",
      " [1.3746964 ]\n",
      " [0.28353631]\n",
      " [0.3186971 ]]\n",
      "1200  Cost:  1.1604757 \n",
      "Prediction: \n",
      " [[2.6163845 ]\n",
      " [2.5996184 ]\n",
      " [1.8140349 ]\n",
      " [0.935225  ]\n",
      " [1.4751638 ]\n",
      " [1.3745097 ]\n",
      " [0.28341565]\n",
      " [0.3185788 ]]\n",
      "1205  Cost:  1.1600693 \n",
      "Prediction: \n",
      " [[2.616118  ]\n",
      " [2.5993617 ]\n",
      " [1.8138229 ]\n",
      " [0.9350633 ]\n",
      " [1.47497   ]\n",
      " [1.374323  ]\n",
      " [0.28329504]\n",
      " [0.31846058]]\n",
      "1210  Cost:  1.1596632 \n",
      "Prediction: \n",
      " [[2.6158516 ]\n",
      " [2.5991051 ]\n",
      " [1.8136108 ]\n",
      " [0.93490165]\n",
      " [1.4747763 ]\n",
      " [1.3741362 ]\n",
      " [0.2831744 ]\n",
      " [0.3183424 ]]\n",
      "1215  Cost:  1.1592569 \n",
      "Prediction: \n",
      " [[2.6155849 ]\n",
      " [2.598848  ]\n",
      " [1.8133987 ]\n",
      " [0.93474   ]\n",
      " [1.4745827 ]\n",
      " [1.3739495 ]\n",
      " [0.28305376]\n",
      " [0.3182242 ]]\n",
      "1220  Cost:  1.1588511 \n",
      "Prediction: \n",
      " [[2.6153185 ]\n",
      " [2.5985916 ]\n",
      " [1.8131868 ]\n",
      " [0.93457836]\n",
      " [1.4743892 ]\n",
      " [1.3737628 ]\n",
      " [0.28293318]\n",
      " [0.31810606]]\n",
      "1225  Cost:  1.1584451 \n",
      "Prediction: \n",
      " [[2.615052  ]\n",
      " [2.5983346 ]\n",
      " [1.8129748 ]\n",
      " [0.9344168 ]\n",
      " [1.4741955 ]\n",
      " [1.3735763 ]\n",
      " [0.2828126 ]\n",
      " [0.31798792]]\n",
      "1230  Cost:  1.1580393 \n",
      "Prediction: \n",
      " [[2.6147857 ]\n",
      " [2.598078  ]\n",
      " [1.8127627 ]\n",
      " [0.9342553 ]\n",
      " [1.4740019 ]\n",
      " [1.3733896 ]\n",
      " [0.28269207]\n",
      " [0.31786978]]\n",
      "1235  Cost:  1.1576338 \n",
      "Prediction: \n",
      " [[2.6145191 ]\n",
      " [2.5978215 ]\n",
      " [1.8125508 ]\n",
      " [0.9340937 ]\n",
      " [1.4738083 ]\n",
      " [1.373203  ]\n",
      " [0.2825715 ]\n",
      " [0.31775165]]\n",
      "1240  Cost:  1.1572285 \n",
      "Prediction: \n",
      " [[2.614253 ]\n",
      " [2.597565 ]\n",
      " [1.8123388]\n",
      " [0.9339321]\n",
      " [1.4736149]\n",
      " [1.3730166]\n",
      " [0.282451 ]\n",
      " [0.3176335]]\n",
      "1245  Cost:  1.1568234 \n",
      "Prediction: \n",
      " [[2.613987  ]\n",
      " [2.5973084 ]\n",
      " [1.8121272 ]\n",
      " [0.93377084]\n",
      " [1.4734216 ]\n",
      " [1.3728302 ]\n",
      " [0.28233057]\n",
      " [0.31751543]]\n",
      "1250  Cost:  1.1564183 \n",
      "Prediction: \n",
      " [[2.613721  ]\n",
      " [2.597052  ]\n",
      " [1.8119155 ]\n",
      " [0.9336095 ]\n",
      " [1.4732281 ]\n",
      " [1.3726436 ]\n",
      " [0.2822101 ]\n",
      " [0.31739745]]\n",
      "1255  Cost:  1.1560135 \n",
      "Prediction: \n",
      " [[2.6134548 ]\n",
      " [2.5967958 ]\n",
      " [1.8117037 ]\n",
      " [0.9334481 ]\n",
      " [1.4730349 ]\n",
      " [1.3724573 ]\n",
      " [0.28208965]\n",
      " [0.31727934]]\n",
      "1260  Cost:  1.1556087 \n",
      "Prediction: \n",
      " [[2.6131887 ]\n",
      " [2.5965393 ]\n",
      " [1.811492  ]\n",
      " [0.93328667]\n",
      " [1.4728415 ]\n",
      " [1.3722708 ]\n",
      " [0.28196925]\n",
      " [0.3171613 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265  Cost:  1.155204 \n",
      "Prediction: \n",
      " [[2.6129227 ]\n",
      " [2.596283  ]\n",
      " [1.8112804 ]\n",
      " [0.93312526]\n",
      " [1.4726481 ]\n",
      " [1.3720846 ]\n",
      " [0.2818489 ]\n",
      " [0.31704336]]\n",
      "1270  Cost:  1.1547997 \n",
      "Prediction: \n",
      " [[2.6126568 ]\n",
      " [2.596027  ]\n",
      " [1.8110688 ]\n",
      " [0.93296397]\n",
      " [1.472455  ]\n",
      " [1.3718983 ]\n",
      " [0.28172854]\n",
      " [0.31692538]]\n",
      "1275  Cost:  1.1543951 \n",
      "Prediction: \n",
      " [[2.6123908 ]\n",
      " [2.5957704 ]\n",
      " [1.810857  ]\n",
      " [0.93280274]\n",
      " [1.4722617 ]\n",
      " [1.371712  ]\n",
      " [0.28160816]\n",
      " [0.3168074 ]]\n",
      "1280  Cost:  1.1539907 \n",
      "Prediction: \n",
      " [[2.612125  ]\n",
      " [2.5955143 ]\n",
      " [1.8106453 ]\n",
      " [0.9326413 ]\n",
      " [1.4720683 ]\n",
      " [1.3715255 ]\n",
      " [0.28148788]\n",
      " [0.31668943]]\n",
      "1285  Cost:  1.1535866 \n",
      "Prediction: \n",
      " [[2.6118588 ]\n",
      " [2.5952578 ]\n",
      " [1.8104337 ]\n",
      " [0.9324801 ]\n",
      " [1.4718753 ]\n",
      " [1.3713394 ]\n",
      " [0.28136754]\n",
      " [0.31657153]]\n",
      "1290  Cost:  1.1531825 \n",
      "Prediction: \n",
      " [[2.611593 ]\n",
      " [2.5950017]\n",
      " [1.8102221]\n",
      " [0.9323188]\n",
      " [1.471682 ]\n",
      " [1.3711531]\n",
      " [0.2812473]\n",
      " [0.3164536]]\n",
      "1295  Cost:  1.1527786 \n",
      "Prediction: \n",
      " [[2.6113272 ]\n",
      " [2.5947454 ]\n",
      " [1.8100107 ]\n",
      " [0.9321577 ]\n",
      " [1.4714887 ]\n",
      " [1.3709669 ]\n",
      " [0.28112698]\n",
      " [0.31633574]]\n",
      "1300  Cost:  1.1523747 \n",
      "Prediction: \n",
      " [[2.6110613 ]\n",
      " [2.5944893 ]\n",
      " [1.8097991 ]\n",
      " [0.93199635]\n",
      " [1.4712957 ]\n",
      " [1.3707806 ]\n",
      " [0.28100672]\n",
      " [0.3162178 ]]\n",
      "1305  Cost:  1.1519711 \n",
      "Prediction: \n",
      " [[2.6107955 ]\n",
      " [2.5942333 ]\n",
      " [1.8095876 ]\n",
      " [0.9318353 ]\n",
      " [1.4711024 ]\n",
      " [1.3705945 ]\n",
      " [0.2808865 ]\n",
      " [0.31610003]]\n",
      "1310  Cost:  1.1515677 \n",
      "Prediction: \n",
      " [[2.61053  ]\n",
      " [2.5939772]\n",
      " [1.8093761]\n",
      " [0.9316741]\n",
      " [1.4709095]\n",
      " [1.3704083]\n",
      " [0.2807663]\n",
      " [0.3159822]]\n",
      "1315  Cost:  1.1511648 \n",
      "Prediction: \n",
      " [[2.6102643 ]\n",
      " [2.5937216 ]\n",
      " [1.8091649 ]\n",
      " [0.9315132 ]\n",
      " [1.4707166 ]\n",
      " [1.3702224 ]\n",
      " [0.28064623]\n",
      " [0.31586447]]\n",
      "1320  Cost:  1.1507623 \n",
      "Prediction: \n",
      " [[2.6099992 ]\n",
      " [2.593466  ]\n",
      " [1.8089542 ]\n",
      " [0.9313523 ]\n",
      " [1.4705238 ]\n",
      " [1.3700368 ]\n",
      " [0.28052616]\n",
      " [0.3157469 ]]\n",
      "1325  Cost:  1.1503599 \n",
      "Prediction: \n",
      " [[2.6097338 ]\n",
      " [2.5932107 ]\n",
      " [1.8087432 ]\n",
      " [0.93119144]\n",
      " [1.4703312 ]\n",
      " [1.3698509 ]\n",
      " [0.28040612]\n",
      " [0.3156293 ]]\n",
      "1330  Cost:  1.1499577 \n",
      "Prediction: \n",
      " [[2.6094687 ]\n",
      " [2.592955  ]\n",
      " [1.8085322 ]\n",
      " [0.93103063]\n",
      " [1.4701387 ]\n",
      " [1.3696651 ]\n",
      " [0.28028613]\n",
      " [0.31551173]]\n",
      "1335  Cost:  1.1495554 \n",
      "Prediction: \n",
      " [[2.6092036 ]\n",
      " [2.5927    ]\n",
      " [1.8083212 ]\n",
      " [0.93086976]\n",
      " [1.4699459 ]\n",
      " [1.3694794 ]\n",
      " [0.28016615]\n",
      " [0.31539416]]\n",
      "1340  Cost:  1.1491535 \n",
      "Prediction: \n",
      " [[2.6089385 ]\n",
      " [2.5924447 ]\n",
      " [1.8081102 ]\n",
      " [0.93070906]\n",
      " [1.4697533 ]\n",
      " [1.3692938 ]\n",
      " [0.28004616]\n",
      " [0.31527662]]\n",
      "1345  Cost:  1.1487515 \n",
      "Prediction: \n",
      " [[2.6086733 ]\n",
      " [2.5921893 ]\n",
      " [1.8078995 ]\n",
      " [0.93054825]\n",
      " [1.4695607 ]\n",
      " [1.3691082 ]\n",
      " [0.27992618]\n",
      " [0.31515914]]\n",
      "1350  Cost:  1.1483496 \n",
      "Prediction: \n",
      " [[2.6084082 ]\n",
      " [2.591934  ]\n",
      " [1.8076887 ]\n",
      " [0.9303875 ]\n",
      " [1.4693681 ]\n",
      " [1.3689224 ]\n",
      " [0.27980632]\n",
      " [0.31504166]]\n",
      "1355  Cost:  1.1479478 \n",
      "Prediction: \n",
      " [[2.608143  ]\n",
      " [2.5916786 ]\n",
      " [1.8074778 ]\n",
      " [0.9302267 ]\n",
      " [1.4691755 ]\n",
      " [1.3687367 ]\n",
      " [0.27968633]\n",
      " [0.31492412]]\n",
      "1360  Cost:  1.1475465 \n",
      "Prediction: \n",
      " [[2.6078782 ]\n",
      " [2.5914235 ]\n",
      " [1.8072672 ]\n",
      " [0.930066  ]\n",
      " [1.4689832 ]\n",
      " [1.368551  ]\n",
      " [0.27956644]\n",
      " [0.31480667]]\n",
      "1365  Cost:  1.147145 \n",
      "Prediction: \n",
      " [[2.607613  ]\n",
      " [2.5911684 ]\n",
      " [1.8070562 ]\n",
      " [0.92990535]\n",
      " [1.4687905 ]\n",
      " [1.3683655 ]\n",
      " [0.27944654]\n",
      " [0.31468928]]\n",
      "1370  Cost:  1.1467437 \n",
      "Prediction: \n",
      " [[2.6073482 ]\n",
      " [2.590913  ]\n",
      " [1.8068454 ]\n",
      " [0.92974466]\n",
      " [1.4685981 ]\n",
      " [1.36818   ]\n",
      " [0.27932674]\n",
      " [0.3145718 ]]\n",
      "1375  Cost:  1.1463423 \n",
      "Prediction: \n",
      " [[2.607083  ]\n",
      " [2.590658  ]\n",
      " [1.8066345 ]\n",
      " [0.92958397]\n",
      " [1.4684054 ]\n",
      " [1.3679943 ]\n",
      " [0.27920687]\n",
      " [0.31445438]]\n",
      "1380  Cost:  1.1459413 \n",
      "Prediction: \n",
      " [[2.6068182 ]\n",
      " [2.5904026 ]\n",
      " [1.8064239 ]\n",
      " [0.9294233 ]\n",
      " [1.4682131 ]\n",
      " [1.3678088 ]\n",
      " [0.279087  ]\n",
      " [0.31433702]]\n",
      "1385  Cost:  1.1455404 \n",
      "Prediction: \n",
      " [[2.6065533 ]\n",
      " [2.5901477 ]\n",
      " [1.8062134 ]\n",
      " [0.92926276]\n",
      " [1.4680207 ]\n",
      " [1.3676233 ]\n",
      " [0.27896726]\n",
      " [0.31421965]]\n",
      "1390  Cost:  1.1451398 \n",
      "Prediction: \n",
      " [[2.6062887 ]\n",
      " [2.5898929 ]\n",
      " [1.8060027 ]\n",
      " [0.92910224]\n",
      " [1.4678284 ]\n",
      " [1.3674381 ]\n",
      " [0.27884752]\n",
      " [0.3141023 ]]\n",
      "1395  Cost:  1.1447394 \n",
      "Prediction: \n",
      " [[2.606024  ]\n",
      " [2.589638  ]\n",
      " [1.8057921 ]\n",
      " [0.9289417 ]\n",
      " [1.4676361 ]\n",
      " [1.3672527 ]\n",
      " [0.27872777]\n",
      " [0.313985  ]]\n",
      "1400  Cost:  1.1443388 \n",
      "Prediction: \n",
      " [[2.6057594 ]\n",
      " [2.5893831 ]\n",
      " [1.8055817 ]\n",
      " [0.9287813 ]\n",
      " [1.4674438 ]\n",
      " [1.3670673 ]\n",
      " [0.27860808]\n",
      " [0.31386763]]\n",
      "1405  Cost:  1.1439385 \n",
      "Prediction: \n",
      " [[2.605495  ]\n",
      " [2.589128  ]\n",
      " [1.8053712 ]\n",
      " [0.9286208 ]\n",
      " [1.4672515 ]\n",
      " [1.366882  ]\n",
      " [0.27848834]\n",
      " [0.3137504 ]]\n",
      "1410  Cost:  1.1435385 \n",
      "Prediction: \n",
      " [[2.6052303 ]\n",
      " [2.5888734 ]\n",
      " [1.8051608 ]\n",
      " [0.92846036]\n",
      " [1.4670594 ]\n",
      " [1.3666967 ]\n",
      " [0.27836868]\n",
      " [0.3136331 ]]\n",
      "1415  Cost:  1.1431384 \n",
      "Prediction: \n",
      " [[2.6049657 ]\n",
      " [2.5886185 ]\n",
      " [1.8049501 ]\n",
      " [0.92829996]\n",
      " [1.4668671 ]\n",
      " [1.3665113 ]\n",
      " [0.27824903]\n",
      " [0.31351584]]\n",
      "1420  Cost:  1.1427388 \n",
      "Prediction: \n",
      " [[2.6047015 ]\n",
      " [2.5883636 ]\n",
      " [1.8047398 ]\n",
      " [0.92813957]\n",
      " [1.4666752 ]\n",
      " [1.3663262 ]\n",
      " [0.2781294 ]\n",
      " [0.3133986 ]]\n",
      "1425  Cost:  1.1423388 \n",
      "Prediction: \n",
      " [[2.6044366 ]\n",
      " [2.5881088 ]\n",
      " [1.8045294 ]\n",
      " [0.92797935]\n",
      " [1.466483  ]\n",
      " [1.366141  ]\n",
      " [0.27800974]\n",
      " [0.31328142]]\n",
      "1430  Cost:  1.1419392 \n",
      "Prediction: \n",
      " [[2.6041722 ]\n",
      " [2.5878541 ]\n",
      " [1.8043189 ]\n",
      " [0.92781895]\n",
      " [1.4662907 ]\n",
      " [1.3659558 ]\n",
      " [0.27789018]\n",
      " [0.31316417]]\n",
      "1435  Cost:  1.1415393 \n",
      "Prediction: \n",
      " [[2.6039076 ]\n",
      " [2.5875993 ]\n",
      " [1.8041086 ]\n",
      " [0.92765844]\n",
      " [1.4660985 ]\n",
      " [1.3657706 ]\n",
      " [0.27777055]\n",
      " [0.313047  ]]\n",
      "1440  Cost:  1.1411399 \n",
      "Prediction: \n",
      " [[2.6036432 ]\n",
      " [2.5873446 ]\n",
      " [1.8038981 ]\n",
      " [0.9274983 ]\n",
      " [1.4659064 ]\n",
      " [1.3655853 ]\n",
      " [0.277651  ]\n",
      " [0.31292984]]\n",
      "1445  Cost:  1.1407408 \n",
      "Prediction: \n",
      " [[2.6033788 ]\n",
      " [2.58709   ]\n",
      " [1.8036882 ]\n",
      " [0.927338  ]\n",
      " [1.4657146 ]\n",
      " [1.3654002 ]\n",
      " [0.2775315 ]\n",
      " [0.31281275]]\n",
      "1450  Cost:  1.140342 \n",
      "Prediction: \n",
      " [[2.603115  ]\n",
      " [2.5868356 ]\n",
      " [1.8034779 ]\n",
      " [0.9271778 ]\n",
      " [1.4655226 ]\n",
      " [1.3652152 ]\n",
      " [0.27741206]\n",
      " [0.3126956 ]]\n",
      "1455  Cost:  1.139943 \n",
      "Prediction: \n",
      " [[2.6028507 ]\n",
      " [2.586581  ]\n",
      " [1.8032677 ]\n",
      " [0.9270176 ]\n",
      " [1.4653308 ]\n",
      " [1.3650303 ]\n",
      " [0.27729255]\n",
      " [0.31257844]]\n",
      "1460  Cost:  1.1395445 \n",
      "Prediction: \n",
      " [[2.6025867 ]\n",
      " [2.5863266 ]\n",
      " [1.8030577 ]\n",
      " [0.92685753]\n",
      " [1.4651389 ]\n",
      " [1.3648453 ]\n",
      " [0.27717316]\n",
      " [0.31246138]]\n",
      "1465  Cost:  1.1391461 \n",
      "Prediction: \n",
      " [[2.6023226 ]\n",
      " [2.5860724 ]\n",
      " [1.8028476 ]\n",
      " [0.92669755]\n",
      " [1.4649472 ]\n",
      " [1.3646603 ]\n",
      " [0.27705377]\n",
      " [0.31234434]]\n",
      "1470  Cost:  1.1387475 \n",
      "Prediction: \n",
      " [[2.6020586 ]\n",
      " [2.5858176 ]\n",
      " [1.8026376 ]\n",
      " [0.92653745]\n",
      " [1.4647553 ]\n",
      " [1.3644755 ]\n",
      " [0.2769344 ]\n",
      " [0.31222728]]\n",
      "1475  Cost:  1.1383493 \n",
      "Prediction: \n",
      " [[2.601795  ]\n",
      " [2.5855634 ]\n",
      " [1.8024278 ]\n",
      " [0.9263775 ]\n",
      " [1.4645636 ]\n",
      " [1.3642907 ]\n",
      " [0.276815  ]\n",
      " [0.31211025]]\n",
      "1480  Cost:  1.1379515 \n",
      "Prediction: \n",
      " [[2.601531  ]\n",
      " [2.5853095 ]\n",
      " [1.8022178 ]\n",
      " [0.92621756]\n",
      " [1.464372  ]\n",
      " [1.3641059 ]\n",
      " [0.27669567]\n",
      " [0.3119933 ]]\n",
      "1485  Cost:  1.1375538 \n",
      "Prediction: \n",
      " [[2.6012673 ]\n",
      " [2.5850554 ]\n",
      " [1.802008  ]\n",
      " [0.92605764]\n",
      " [1.4641805 ]\n",
      " [1.3639213 ]\n",
      " [0.27657634]\n",
      " [0.3118763 ]]\n",
      "1490  Cost:  1.137156 \n",
      "Prediction: \n",
      " [[2.601004  ]\n",
      " [2.5848012 ]\n",
      " [1.801798  ]\n",
      " [0.9258977 ]\n",
      " [1.4639888 ]\n",
      " [1.3637365 ]\n",
      " [0.27645704]\n",
      " [0.31175938]]\n",
      "1495  Cost:  1.1367583 \n",
      "Prediction: \n",
      " [[2.6007402 ]\n",
      " [2.584547  ]\n",
      " [1.8015882 ]\n",
      " [0.92573786]\n",
      " [1.4637972 ]\n",
      " [1.3635517 ]\n",
      " [0.27633768]\n",
      " [0.3116424 ]]\n",
      "1500  Cost:  1.1363609 \n",
      "Prediction: \n",
      " [[2.6004765 ]\n",
      " [2.584293  ]\n",
      " [1.8013785 ]\n",
      " [0.925578  ]\n",
      " [1.4636056 ]\n",
      " [1.3633671 ]\n",
      " [0.27621844]\n",
      " [0.31152552]]\n",
      "1505  Cost:  1.1359634 \n",
      "Prediction: \n",
      " [[2.6002128 ]\n",
      " [2.5840387 ]\n",
      " [1.8011687 ]\n",
      " [0.92541814]\n",
      " [1.4634141 ]\n",
      " [1.3631824 ]\n",
      " [0.27609918]\n",
      " [0.31140864]]\n",
      "1510  Cost:  1.1355664 \n",
      "Prediction: \n",
      " [[2.5999494 ]\n",
      " [2.5837848 ]\n",
      " [1.8009589 ]\n",
      " [0.92525834]\n",
      " [1.4632225 ]\n",
      " [1.3629978 ]\n",
      " [0.27597997]\n",
      " [0.3112918 ]]\n",
      "1515  Cost:  1.1351694 \n",
      "Prediction: \n",
      " [[2.5996857 ]\n",
      " [2.583531  ]\n",
      " [1.8007493 ]\n",
      " [0.92509854]\n",
      " [1.4630312 ]\n",
      " [1.3628134 ]\n",
      " [0.27586082]\n",
      " [0.31117508]]\n",
      "1520  Cost:  1.1347728 \n",
      "Prediction: \n",
      " [[2.5994222 ]\n",
      " [2.5832775 ]\n",
      " [1.8005397 ]\n",
      " [0.92493874]\n",
      " [1.4628398 ]\n",
      " [1.3626289 ]\n",
      " [0.27574167]\n",
      " [0.31105843]]\n",
      "1525  Cost:  1.1343759 \n",
      "Prediction: \n",
      " [[2.5991585 ]\n",
      " [2.5830238 ]\n",
      " [1.8003302 ]\n",
      " [0.9247791 ]\n",
      " [1.4626483 ]\n",
      " [1.3624442 ]\n",
      " [0.27562255]\n",
      " [0.31094176]]\n",
      "1530  Cost:  1.1339798 \n",
      "Prediction: \n",
      " [[2.5988953 ]\n",
      " [2.5827703 ]\n",
      " [1.8001207 ]\n",
      " [0.92461944]\n",
      " [1.4624571 ]\n",
      " [1.36226   ]\n",
      " [0.27550346]\n",
      " [0.31082514]]\n",
      "1535  Cost:  1.1335834 \n",
      "Prediction: \n",
      " [[2.598632  ]\n",
      " [2.5825167 ]\n",
      " [1.7999114 ]\n",
      " [0.9244597 ]\n",
      " [1.462266  ]\n",
      " [1.3620756 ]\n",
      " [0.27538437]\n",
      " [0.31070846]]\n",
      "1540  Cost:  1.1331875 \n",
      "Prediction: \n",
      " [[2.598369  ]\n",
      " [2.5822635 ]\n",
      " [1.7997022 ]\n",
      " [0.92430025]\n",
      " [1.4620748 ]\n",
      " [1.3618913 ]\n",
      " [0.2752654 ]\n",
      " [0.31059188]]\n",
      "1545  Cost:  1.1327918 \n",
      "Prediction: \n",
      " [[2.598106  ]\n",
      " [2.5820103 ]\n",
      " [1.7994928 ]\n",
      " [0.9241407 ]\n",
      " [1.4618834 ]\n",
      " [1.3617069 ]\n",
      " [0.27514637]\n",
      " [0.31047532]]\n",
      "1550  Cost:  1.1323956 \n",
      "Prediction: \n",
      " [[2.5978425 ]\n",
      " [2.5817564 ]\n",
      " [1.7992835 ]\n",
      " [0.92398113]\n",
      " [1.4616923 ]\n",
      " [1.3615227 ]\n",
      " [0.2750274 ]\n",
      " [0.31035873]]\n",
      "1555  Cost:  1.1320001 \n",
      "Prediction: \n",
      " [[2.5975795 ]\n",
      " [2.5815032 ]\n",
      " [1.7990742 ]\n",
      " [0.92382157]\n",
      " [1.4615014 ]\n",
      " [1.3613385 ]\n",
      " [0.2749084 ]\n",
      " [0.31024215]]\n",
      "1560  Cost:  1.1316044 \n",
      "Prediction: \n",
      " [[2.5973163 ]\n",
      " [2.5812497 ]\n",
      " [1.7988651 ]\n",
      " [0.92366207]\n",
      " [1.4613101 ]\n",
      " [1.3611542 ]\n",
      " [0.27478945]\n",
      " [0.31012562]]\n",
      "1565  Cost:  1.1312089 \n",
      "Prediction: \n",
      " [[2.5970533 ]\n",
      " [2.5809963 ]\n",
      " [1.7986559 ]\n",
      " [0.92350256]\n",
      " [1.4611189 ]\n",
      " [1.36097   ]\n",
      " [0.27467054]\n",
      " [0.31000912]]\n",
      "1570  Cost:  1.1308136 \n",
      "Prediction: \n",
      " [[2.59679   ]\n",
      " [2.580743  ]\n",
      " [1.7984465 ]\n",
      " [0.92334306]\n",
      " [1.460928  ]\n",
      " [1.3607858 ]\n",
      " [0.2745516 ]\n",
      " [0.30989262]]\n",
      "1575  Cost:  1.1304183 \n",
      "Prediction: \n",
      " [[2.596527  ]\n",
      " [2.5804899 ]\n",
      " [1.7982373 ]\n",
      " [0.9231836 ]\n",
      " [1.4607368 ]\n",
      " [1.3606017 ]\n",
      " [0.27443266]\n",
      " [0.30977613]]\n",
      "1580  Cost:  1.1300235 \n",
      "Prediction: \n",
      " [[2.5962641 ]\n",
      " [2.5802367 ]\n",
      " [1.7980283 ]\n",
      " [0.9230243 ]\n",
      " [1.4605459 ]\n",
      " [1.3604176 ]\n",
      " [0.27431387]\n",
      " [0.30965972]]\n",
      "1585  Cost:  1.1296289 \n",
      "Prediction: \n",
      " [[2.5960014 ]\n",
      " [2.5799837 ]\n",
      " [1.7978193 ]\n",
      " [0.92286515]\n",
      " [1.4603553 ]\n",
      " [1.3602337 ]\n",
      " [0.27419508]\n",
      " [0.3095433 ]]\n",
      "1590  Cost:  1.1292341 \n",
      "Prediction: \n",
      " [[2.5957386 ]\n",
      " [2.5797305 ]\n",
      " [1.7976104 ]\n",
      " [0.9227057 ]\n",
      " [1.4601644 ]\n",
      " [1.3600498 ]\n",
      " [0.27407628]\n",
      " [0.30942684]]\n",
      "1595  Cost:  1.1288397 \n",
      "Prediction: \n",
      " [[2.5954762 ]\n",
      " [2.5794775 ]\n",
      " [1.7974013 ]\n",
      " [0.92254645]\n",
      " [1.4599735 ]\n",
      " [1.3598658 ]\n",
      " [0.2739575 ]\n",
      " [0.30931044]]\n",
      "1600  Cost:  1.1284454 \n",
      "Prediction: \n",
      " [[2.5952134 ]\n",
      " [2.5792246 ]\n",
      " [1.7971925 ]\n",
      " [0.92238724]\n",
      " [1.4597827 ]\n",
      " [1.3596818 ]\n",
      " [0.2738388 ]\n",
      " [0.3091941 ]]\n",
      "1605  Cost:  1.128051 \n",
      "Prediction: \n",
      " [[2.5949507 ]\n",
      " [2.5789714 ]\n",
      " [1.7969836 ]\n",
      " [0.9222281 ]\n",
      " [1.4595921 ]\n",
      " [1.3594979 ]\n",
      " [0.2737201 ]\n",
      " [0.30907774]]\n",
      "1610  Cost:  1.127657 \n",
      "Prediction: \n",
      " [[2.5946882 ]\n",
      " [2.5787187 ]\n",
      " [1.7967749 ]\n",
      " [0.922069  ]\n",
      " [1.4594014 ]\n",
      " [1.359314  ]\n",
      " [0.27360135]\n",
      " [0.3089614 ]]\n",
      "1615  Cost:  1.1272628 \n",
      "Prediction: \n",
      " [[2.5944254 ]\n",
      " [2.5784655 ]\n",
      " [1.7965659 ]\n",
      " [0.9219097 ]\n",
      " [1.4592105 ]\n",
      " [1.3591301 ]\n",
      " [0.27348268]\n",
      " [0.30884504]]\n",
      "1620  Cost:  1.1268687 \n",
      "Prediction: \n",
      " [[2.5941627 ]\n",
      " [2.5782125 ]\n",
      " [1.796357  ]\n",
      " [0.92175066]\n",
      " [1.4590198 ]\n",
      " [1.3589463 ]\n",
      " [0.273364  ]\n",
      " [0.30872875]]\n",
      "1625  Cost:  1.1264753 \n",
      "Prediction: \n",
      " [[2.5939004 ]\n",
      " [2.5779598 ]\n",
      " [1.7961483 ]\n",
      " [0.92159164]\n",
      " [1.4588293 ]\n",
      " [1.3587626 ]\n",
      " [0.2732454 ]\n",
      " [0.30861247]]\n",
      "1630  Cost:  1.126082 \n",
      "Prediction: \n",
      " [[2.5936382 ]\n",
      " [2.577707  ]\n",
      " [1.7959397 ]\n",
      " [0.9214325 ]\n",
      " [1.4586385 ]\n",
      " [1.3585788 ]\n",
      " [0.27312672]\n",
      " [0.30849624]]\n",
      "1635  Cost:  1.1256884 \n",
      "Prediction: \n",
      " [[2.5933757]\n",
      " [2.5774543]\n",
      " [1.795731 ]\n",
      " [0.9212736]\n",
      " [1.458448 ]\n",
      " [1.3583951]\n",
      " [0.2730081]\n",
      " [0.30838  ]]\n",
      "1640  Cost:  1.1252956 \n",
      "Prediction: \n",
      " [[2.593114  ]\n",
      " [2.577202  ]\n",
      " [1.7955225 ]\n",
      " [0.9211146 ]\n",
      " [1.4582577 ]\n",
      " [1.3582115 ]\n",
      " [0.27288955]\n",
      " [0.3082638 ]]\n",
      "1645  Cost:  1.1249027 \n",
      "Prediction: \n",
      " [[2.5928516 ]\n",
      " [2.5769496 ]\n",
      " [1.7953138 ]\n",
      " [0.92095554]\n",
      " [1.4580672 ]\n",
      " [1.3580279 ]\n",
      " [0.272771  ]\n",
      " [0.3081476 ]]\n",
      "1650  Cost:  1.1245096 \n",
      "Prediction: \n",
      " [[2.5925894 ]\n",
      " [2.5766966 ]\n",
      " [1.7951052 ]\n",
      " [0.92079675]\n",
      " [1.4578768 ]\n",
      " [1.3578442 ]\n",
      " [0.27265242]\n",
      " [0.30803147]]\n",
      "1655  Cost:  1.1241167 \n",
      "Prediction: \n",
      " [[2.592327  ]\n",
      " [2.5764444 ]\n",
      " [1.7948965 ]\n",
      " [0.9206378 ]\n",
      " [1.4576863 ]\n",
      " [1.3576605 ]\n",
      " [0.2725339 ]\n",
      " [0.30791527]]\n",
      "1660  Cost:  1.1237242 \n",
      "Prediction: \n",
      " [[2.592065  ]\n",
      " [2.5761917 ]\n",
      " [1.7946881 ]\n",
      " [0.9204789 ]\n",
      " [1.4574958 ]\n",
      " [1.3574773 ]\n",
      " [0.2724154 ]\n",
      " [0.30779916]]\n",
      "1665  Cost:  1.1233315 \n",
      "Prediction: \n",
      " [[2.591803  ]\n",
      " [2.5759392 ]\n",
      " [1.7944796 ]\n",
      " [0.92032003]\n",
      " [1.4573054 ]\n",
      " [1.3572936 ]\n",
      " [0.2722969 ]\n",
      " [0.30768305]]\n",
      "1670  Cost:  1.1229391 \n",
      "Prediction: \n",
      " [[2.591541  ]\n",
      " [2.5756867 ]\n",
      " [1.794271  ]\n",
      " [0.920161  ]\n",
      " [1.457115  ]\n",
      " [1.35711   ]\n",
      " [0.2721784 ]\n",
      " [0.30756694]]\n",
      "1675  Cost:  1.1225464 \n",
      "Prediction: \n",
      " [[2.5912786 ]\n",
      " [2.575434  ]\n",
      " [1.7940626 ]\n",
      " [0.9200023 ]\n",
      " [1.4569247 ]\n",
      " [1.3569264 ]\n",
      " [0.27205992]\n",
      " [0.3074509 ]]\n",
      "1680  Cost:  1.1221546 \n",
      "Prediction: \n",
      " [[2.591017  ]\n",
      " [2.5751817 ]\n",
      " [1.7938542 ]\n",
      " [0.91984355]\n",
      " [1.4567345 ]\n",
      " [1.3567431 ]\n",
      " [0.2719415 ]\n",
      " [0.30733484]]\n",
      "1685  Cost:  1.1217628 \n",
      "Prediction: \n",
      " [[2.5907552 ]\n",
      " [2.5749295 ]\n",
      " [1.7936461 ]\n",
      " [0.91968477]\n",
      " [1.4565443 ]\n",
      " [1.3565599 ]\n",
      " [0.27182317]\n",
      " [0.3072188 ]]\n",
      "1690  Cost:  1.121371 \n",
      "Prediction: \n",
      " [[2.5904937 ]\n",
      " [2.5746772 ]\n",
      " [1.7934377 ]\n",
      " [0.9195261 ]\n",
      " [1.4563541 ]\n",
      " [1.3563764 ]\n",
      " [0.2717048 ]\n",
      " [0.30710277]]\n",
      "1695  Cost:  1.1209794 \n",
      "Prediction: \n",
      " [[2.5902317 ]\n",
      " [2.574425  ]\n",
      " [1.7932296 ]\n",
      " [0.91936743]\n",
      " [1.456164  ]\n",
      " [1.3561933 ]\n",
      " [0.27158642]\n",
      " [0.30698675]]\n",
      "1700  Cost:  1.120588 \n",
      "Prediction: \n",
      " [[2.58997   ]\n",
      " [2.574173  ]\n",
      " [1.7930212 ]\n",
      " [0.9192088 ]\n",
      " [1.4559739 ]\n",
      " [1.35601   ]\n",
      " [0.2714681 ]\n",
      " [0.30687082]]\n",
      "1705  Cost:  1.1201963 \n",
      "Prediction: \n",
      " [[2.5897083 ]\n",
      " [2.5739205 ]\n",
      " [1.7928132 ]\n",
      " [0.9190502 ]\n",
      " [1.4557837 ]\n",
      " [1.3558267 ]\n",
      " [0.2713498 ]\n",
      " [0.30675483]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710  Cost:  1.1198053 \n",
      "Prediction: \n",
      " [[2.5894468 ]\n",
      " [2.5736687 ]\n",
      " [1.7926047 ]\n",
      " [0.9188916 ]\n",
      " [1.4555937 ]\n",
      " [1.3556434 ]\n",
      " [0.27123153]\n",
      " [0.3066389 ]]\n",
      "1715  Cost:  1.1194142 \n",
      "Prediction: \n",
      " [[2.589185  ]\n",
      " [2.5734167 ]\n",
      " [1.7923968 ]\n",
      " [0.918733  ]\n",
      " [1.4554038 ]\n",
      " [1.3554603 ]\n",
      " [0.27111328]\n",
      " [0.30652308]]\n",
      "1720  Cost:  1.1190238 \n",
      "Prediction: \n",
      " [[2.588924  ]\n",
      " [2.573165  ]\n",
      " [1.792189  ]\n",
      " [0.9185746 ]\n",
      " [1.4552139 ]\n",
      " [1.3552774 ]\n",
      " [0.2709951 ]\n",
      " [0.30640736]]\n",
      "1725  Cost:  1.1186333 \n",
      "Prediction: \n",
      " [[2.5886624 ]\n",
      " [2.5729134 ]\n",
      " [1.7919812 ]\n",
      " [0.91841614]\n",
      " [1.4550241 ]\n",
      " [1.3550943 ]\n",
      " [0.270877  ]\n",
      " [0.30629164]]\n",
      "1730  Cost:  1.1182432 \n",
      "Prediction: \n",
      " [[2.5884013 ]\n",
      " [2.572662  ]\n",
      " [1.7917734 ]\n",
      " [0.9182577 ]\n",
      " [1.4548343 ]\n",
      " [1.3549114 ]\n",
      " [0.27075893]\n",
      " [0.30617592]]\n",
      "1735  Cost:  1.1178528 \n",
      "Prediction: \n",
      " [[2.5881398 ]\n",
      " [2.5724103 ]\n",
      " [1.7915655 ]\n",
      " [0.91809946]\n",
      " [1.4546446 ]\n",
      " [1.3547285 ]\n",
      " [0.27064085]\n",
      " [0.3060602 ]]\n",
      "1740  Cost:  1.1174629 \n",
      "Prediction: \n",
      " [[2.5878787 ]\n",
      " [2.5721588 ]\n",
      " [1.791358  ]\n",
      " [0.9179411 ]\n",
      " [1.4544549 ]\n",
      " [1.3545456 ]\n",
      " [0.27052277]\n",
      " [0.30594456]]\n",
      "1745  Cost:  1.117073 \n",
      "Prediction: \n",
      " [[2.5876174 ]\n",
      " [2.5719075 ]\n",
      " [1.7911503 ]\n",
      " [0.9177828 ]\n",
      " [1.4542652 ]\n",
      " [1.3543627 ]\n",
      " [0.27040482]\n",
      " [0.30582893]]\n",
      "1750  Cost:  1.1166832 \n",
      "Prediction: \n",
      " [[2.5873563 ]\n",
      " [2.571656  ]\n",
      " [1.7909427 ]\n",
      " [0.91762453]\n",
      " [1.4540756 ]\n",
      " [1.35418   ]\n",
      " [0.27028674]\n",
      " [0.30571324]]\n",
      "1755  Cost:  1.1162934 \n",
      "Prediction: \n",
      " [[2.587095  ]\n",
      " [2.5714045 ]\n",
      " [1.7907349 ]\n",
      " [0.9174662 ]\n",
      " [1.4538858 ]\n",
      " [1.353997  ]\n",
      " [0.27016872]\n",
      " [0.3055976 ]]\n",
      "1760  Cost:  1.1159037 \n",
      "Prediction: \n",
      " [[2.586834  ]\n",
      " [2.5711527 ]\n",
      " [1.7905273 ]\n",
      " [0.917308  ]\n",
      " [1.4536963 ]\n",
      " [1.3538144 ]\n",
      " [0.27005076]\n",
      " [0.30548206]]\n",
      "1765  Cost:  1.1155143 \n",
      "Prediction: \n",
      " [[2.5865726 ]\n",
      " [2.5709014 ]\n",
      " [1.7903197 ]\n",
      " [0.9171498 ]\n",
      " [1.4535066 ]\n",
      " [1.3536315 ]\n",
      " [0.2699328 ]\n",
      " [0.30536646]]\n",
      "1770  Cost:  1.1151247 \n",
      "Prediction: \n",
      " [[2.5863116 ]\n",
      " [2.5706499 ]\n",
      " [1.790112  ]\n",
      " [0.91699153]\n",
      " [1.4533169 ]\n",
      " [1.3534486 ]\n",
      " [0.26981485]\n",
      " [0.30525088]]\n",
      "1775  Cost:  1.1147355 \n",
      "Prediction: \n",
      " [[2.5860503]\n",
      " [2.5703986]\n",
      " [1.7899045]\n",
      " [0.9168333]\n",
      " [1.4531275]\n",
      " [1.3532659]\n",
      " [0.2696969]\n",
      " [0.3051353]]\n",
      "1780  Cost:  1.1143464 \n",
      "Prediction: \n",
      " [[2.5857894 ]\n",
      " [2.5701473 ]\n",
      " [1.7896969 ]\n",
      " [0.9166752 ]\n",
      " [1.4529378 ]\n",
      " [1.3530833 ]\n",
      " [0.26957902]\n",
      " [0.30501983]]\n",
      "1785  Cost:  1.1139575 \n",
      "Prediction: \n",
      " [[2.5855284 ]\n",
      " [2.569896  ]\n",
      " [1.7894894 ]\n",
      " [0.916517  ]\n",
      " [1.4527485 ]\n",
      " [1.3529006 ]\n",
      " [0.26946113]\n",
      " [0.3049043 ]]\n",
      "1790  Cost:  1.113569 \n",
      "Prediction: \n",
      " [[2.5852678 ]\n",
      " [2.569645  ]\n",
      " [1.7892821 ]\n",
      " [0.91635895]\n",
      " [1.452559  ]\n",
      " [1.3527181 ]\n",
      " [0.26934326]\n",
      " [0.30478886]]\n",
      "1795  Cost:  1.1131803 \n",
      "Prediction: \n",
      " [[2.585007  ]\n",
      " [2.5693936 ]\n",
      " [1.7890747 ]\n",
      " [0.916201  ]\n",
      " [1.4523697 ]\n",
      " [1.3525355 ]\n",
      " [0.2692254 ]\n",
      " [0.30467337]]\n",
      "1800  Cost:  1.1127918 \n",
      "Prediction: \n",
      " [[2.5847461 ]\n",
      " [2.5691426 ]\n",
      " [1.7888672 ]\n",
      " [0.9160428 ]\n",
      " [1.4521804 ]\n",
      " [1.3523529 ]\n",
      " [0.26910755]\n",
      " [0.30455795]]\n",
      "1805  Cost:  1.1124035 \n",
      "Prediction: \n",
      " [[2.5844855 ]\n",
      " [2.5688915 ]\n",
      " [1.78866   ]\n",
      " [0.915885  ]\n",
      " [1.4519911 ]\n",
      " [1.3521703 ]\n",
      " [0.2689898 ]\n",
      " [0.30444258]]\n",
      "1810  Cost:  1.1120152 \n",
      "Prediction: \n",
      " [[2.584225  ]\n",
      " [2.5686405 ]\n",
      " [1.7884526 ]\n",
      " [0.91572696]\n",
      " [1.4518018 ]\n",
      " [1.3519878 ]\n",
      " [0.26887196]\n",
      " [0.30432716]]\n",
      "1815  Cost:  1.1116273 \n",
      "Prediction: \n",
      " [[2.5839643 ]\n",
      " [2.5683894 ]\n",
      " [1.7882453 ]\n",
      " [0.91556895]\n",
      " [1.4516124 ]\n",
      " [1.3518053 ]\n",
      " [0.26875412]\n",
      " [0.30421174]]\n",
      "1820  Cost:  1.1112392 \n",
      "Prediction: \n",
      " [[2.5837035 ]\n",
      " [2.5681386 ]\n",
      " [1.788038  ]\n",
      " [0.915411  ]\n",
      " [1.451423  ]\n",
      " [1.3516229 ]\n",
      " [0.2686364 ]\n",
      " [0.30409643]]\n",
      "1825  Cost:  1.1108515 \n",
      "Prediction: \n",
      " [[2.5834432]\n",
      " [2.5678875]\n",
      " [1.7878308]\n",
      " [0.9152531]\n",
      " [1.4512339]\n",
      " [1.3514404]\n",
      " [0.2685187]\n",
      " [0.3039811]]\n",
      "1830  Cost:  1.1104641 \n",
      "Prediction: \n",
      " [[2.5831828 ]\n",
      " [2.5676367 ]\n",
      " [1.7876239 ]\n",
      " [0.9150953 ]\n",
      " [1.4510448 ]\n",
      " [1.3512583 ]\n",
      " [0.268401  ]\n",
      " [0.30386576]]\n",
      "1835  Cost:  1.1100767 \n",
      "Prediction: \n",
      " [[2.5829225 ]\n",
      " [2.567386  ]\n",
      " [1.7874167 ]\n",
      " [0.9149375 ]\n",
      " [1.4508557 ]\n",
      " [1.351076  ]\n",
      " [0.2682833 ]\n",
      " [0.30375043]]\n",
      "1840  Cost:  1.1096894 \n",
      "Prediction: \n",
      " [[2.582662  ]\n",
      " [2.567135  ]\n",
      " [1.7872096 ]\n",
      " [0.9147798 ]\n",
      " [1.4506667 ]\n",
      " [1.3508937 ]\n",
      " [0.26816568]\n",
      " [0.30363518]]\n",
      "1845  Cost:  1.1093023 \n",
      "Prediction: \n",
      " [[2.582402  ]\n",
      " [2.5668845 ]\n",
      " [1.7870026 ]\n",
      " [0.914622  ]\n",
      " [1.4504776 ]\n",
      " [1.3507116 ]\n",
      " [0.26804805]\n",
      " [0.3035199 ]]\n",
      "1850  Cost:  1.1089151 \n",
      "Prediction: \n",
      " [[2.5821416 ]\n",
      " [2.5666337 ]\n",
      " [1.7867956 ]\n",
      " [0.9144643 ]\n",
      " [1.4502885 ]\n",
      " [1.3505294 ]\n",
      " [0.26793042]\n",
      " [0.30340466]]\n",
      "1855  Cost:  1.1085284 \n",
      "Prediction: \n",
      " [[2.5818815 ]\n",
      " [2.5663831 ]\n",
      " [1.7865885 ]\n",
      " [0.9143066 ]\n",
      " [1.4500996 ]\n",
      " [1.350347  ]\n",
      " [0.26781285]\n",
      " [0.3032894 ]]\n",
      "1860  Cost:  1.1081419 \n",
      "Prediction: \n",
      " [[2.5816214 ]\n",
      " [2.5661325 ]\n",
      " [1.7863818 ]\n",
      " [0.91414917]\n",
      " [1.4499109 ]\n",
      " [1.3501651 ]\n",
      " [0.26769534]\n",
      " [0.30317423]]\n",
      "1865  Cost:  1.1077557 \n",
      "Prediction: \n",
      " [[2.5813615 ]\n",
      " [2.5658824 ]\n",
      " [1.786175  ]\n",
      " [0.9139916 ]\n",
      " [1.449722  ]\n",
      " [1.349983  ]\n",
      " [0.26757786]\n",
      " [0.30305904]]\n",
      "1870  Cost:  1.1073694 \n",
      "Prediction: \n",
      " [[2.581102  ]\n",
      " [2.5656319 ]\n",
      " [1.7859683 ]\n",
      " [0.9138341 ]\n",
      " [1.4495332 ]\n",
      " [1.3498012 ]\n",
      " [0.26746038]\n",
      " [0.3029439 ]]\n",
      "1875  Cost:  1.1069832 \n",
      "Prediction: \n",
      " [[2.580842 ]\n",
      " [2.5653815]\n",
      " [1.7857615]\n",
      " [0.9136764]\n",
      " [1.4493445]\n",
      " [1.349619 ]\n",
      " [0.2673429]\n",
      " [0.3028287]]\n",
      "1880  Cost:  1.1065971 \n",
      "Prediction: \n",
      " [[2.5805821 ]\n",
      " [2.565131  ]\n",
      " [1.7855549 ]\n",
      " [0.9135189 ]\n",
      " [1.4491557 ]\n",
      " [1.3494371 ]\n",
      " [0.26722547]\n",
      " [0.30271357]]\n",
      "1885  Cost:  1.1062113 \n",
      "Prediction: \n",
      " [[2.5803225 ]\n",
      " [2.5648806 ]\n",
      " [1.7853483 ]\n",
      " [0.9133615 ]\n",
      " [1.4489671 ]\n",
      " [1.3492552 ]\n",
      " [0.26710808]\n",
      " [0.30259848]]\n",
      "1890  Cost:  1.1058254 \n",
      "Prediction: \n",
      " [[2.5800626 ]\n",
      " [2.5646303 ]\n",
      " [1.7851417 ]\n",
      " [0.91320413]\n",
      " [1.4487784 ]\n",
      " [1.3490734 ]\n",
      " [0.26699066]\n",
      " [0.30248338]]\n",
      "1895  Cost:  1.1054397 \n",
      "Prediction: \n",
      " [[2.5798028 ]\n",
      " [2.56438   ]\n",
      " [1.7849349 ]\n",
      " [0.91304666]\n",
      " [1.4485896 ]\n",
      " [1.3488915 ]\n",
      " [0.26687324]\n",
      " [0.30236828]]\n",
      "1900  Cost:  1.1050539 \n",
      "Prediction: \n",
      " [[2.5795429 ]\n",
      " [2.5641296 ]\n",
      " [1.7847282 ]\n",
      " [0.91288924]\n",
      " [1.448401  ]\n",
      " [1.3487095 ]\n",
      " [0.2667559 ]\n",
      " [0.30225322]]\n",
      "1905  Cost:  1.1046686 \n",
      "Prediction: \n",
      " [[2.5792832 ]\n",
      " [2.5638795 ]\n",
      " [1.7845217 ]\n",
      " [0.9127319 ]\n",
      " [1.4482123 ]\n",
      " [1.3485277 ]\n",
      " [0.26663858]\n",
      " [0.3021382 ]]\n",
      "1910  Cost:  1.1042831 \n",
      "Prediction: \n",
      " [[2.5790236 ]\n",
      " [2.5636292 ]\n",
      " [1.7843149 ]\n",
      " [0.9125745 ]\n",
      " [1.4480237 ]\n",
      " [1.348346  ]\n",
      " [0.26652125]\n",
      " [0.30202317]]\n",
      "1915  Cost:  1.1038978 \n",
      "Prediction: \n",
      " [[2.5787637 ]\n",
      " [2.5633788 ]\n",
      " [1.7841084 ]\n",
      " [0.91241723]\n",
      " [1.4478352 ]\n",
      " [1.3481641 ]\n",
      " [0.26640394]\n",
      " [0.3019082 ]]\n",
      "1920  Cost:  1.103513 \n",
      "Prediction: \n",
      " [[2.578504  ]\n",
      " [2.5631292 ]\n",
      " [1.783902  ]\n",
      " [0.9122599 ]\n",
      " [1.4476467 ]\n",
      " [1.3479824 ]\n",
      " [0.26628673]\n",
      " [0.3017934 ]]\n",
      "1925  Cost:  1.1031282 \n",
      "Prediction: \n",
      " [[2.5782447 ]\n",
      " [2.562879  ]\n",
      " [1.7836958 ]\n",
      " [0.9121026 ]\n",
      " [1.4474581 ]\n",
      " [1.3478006 ]\n",
      " [0.26616952]\n",
      " [0.3016786 ]]\n",
      "1930  Cost:  1.1027433 \n",
      "Prediction: \n",
      " [[2.5779848]\n",
      " [2.562629 ]\n",
      " [1.7834893]\n",
      " [0.9119453]\n",
      " [1.4472697]\n",
      " [1.3476188]\n",
      " [0.2660523]\n",
      " [0.3015638]]\n",
      "1935  Cost:  1.1023588 \n",
      "Prediction: \n",
      " [[2.5777252 ]\n",
      " [2.5623794 ]\n",
      " [1.783283  ]\n",
      " [0.911788  ]\n",
      " [1.4470813 ]\n",
      " [1.3474373 ]\n",
      " [0.26593512]\n",
      " [0.301449  ]]\n",
      "1940  Cost:  1.1019744 \n",
      "Prediction: \n",
      " [[2.5774655 ]\n",
      " [2.5621295 ]\n",
      " [1.7830768 ]\n",
      " [0.9116308 ]\n",
      " [1.446893  ]\n",
      " [1.3472557 ]\n",
      " [0.26581797]\n",
      " [0.30133426]]\n",
      "1945  Cost:  1.1015903 \n",
      "Prediction: \n",
      " [[2.5772064 ]\n",
      " [2.5618799 ]\n",
      " [1.7828705 ]\n",
      " [0.9114737 ]\n",
      " [1.4467046 ]\n",
      " [1.3470743 ]\n",
      " [0.26570085]\n",
      " [0.30121958]]\n",
      "1950  Cost:  1.1012063 \n",
      "Prediction: \n",
      " [[2.5769472 ]\n",
      " [2.5616302 ]\n",
      " [1.7826645 ]\n",
      " [0.9113167 ]\n",
      " [1.4465163 ]\n",
      " [1.3468928 ]\n",
      " [0.26558372]\n",
      " [0.30110487]]\n",
      "1955  Cost:  1.1008224 \n",
      "Prediction: \n",
      " [[2.5766878 ]\n",
      " [2.5613806 ]\n",
      " [1.7824583 ]\n",
      " [0.91115946]\n",
      " [1.4463282 ]\n",
      " [1.3467112 ]\n",
      " [0.26546663]\n",
      " [0.30099016]]\n",
      "1960  Cost:  1.1004385 \n",
      "Prediction: \n",
      " [[2.5764284 ]\n",
      " [2.561131  ]\n",
      " [1.7822523 ]\n",
      " [0.9110025 ]\n",
      " [1.4461398 ]\n",
      " [1.3465298 ]\n",
      " [0.26534957]\n",
      " [0.30087554]]\n",
      "1965  Cost:  1.1000547 \n",
      "Prediction: \n",
      " [[2.5761693 ]\n",
      " [2.5608814 ]\n",
      " [1.7820461 ]\n",
      " [0.9108456 ]\n",
      " [1.4459517 ]\n",
      " [1.3463483 ]\n",
      " [0.2652325 ]\n",
      " [0.30076092]]\n",
      "1970  Cost:  1.0996714 \n",
      "Prediction: \n",
      " [[2.5759103 ]\n",
      " [2.560632  ]\n",
      " [1.78184   ]\n",
      " [0.9106885 ]\n",
      " [1.4457635 ]\n",
      " [1.3461671 ]\n",
      " [0.26511544]\n",
      " [0.30064625]]\n",
      "1975  Cost:  1.0992882 \n",
      "Prediction: \n",
      " [[2.5756512 ]\n",
      " [2.5603826 ]\n",
      " [1.7816341 ]\n",
      " [0.9105315 ]\n",
      " [1.4455755 ]\n",
      " [1.3459859 ]\n",
      " [0.2649984 ]\n",
      " [0.30053166]]\n",
      "1980  Cost:  1.0989051 \n",
      "Prediction: \n",
      " [[2.5753922 ]\n",
      " [2.5601332 ]\n",
      " [1.7814282 ]\n",
      " [0.91037464]\n",
      " [1.4453875 ]\n",
      " [1.3458046 ]\n",
      " [0.26488146]\n",
      " [0.3004171 ]]\n",
      "1985  Cost:  1.0985222 \n",
      "Prediction: \n",
      " [[2.5751336 ]\n",
      " [2.559884  ]\n",
      " [1.7812225 ]\n",
      " [0.91021776]\n",
      " [1.4451995 ]\n",
      " [1.3456233 ]\n",
      " [0.26476455]\n",
      " [0.3003025 ]]\n",
      "1990  Cost:  1.0981393 \n",
      "Prediction: \n",
      " [[2.5748746 ]\n",
      " [2.5596347 ]\n",
      " [1.7810165 ]\n",
      " [0.9100609 ]\n",
      " [1.4450115 ]\n",
      " [1.345442  ]\n",
      " [0.26464757]\n",
      " [0.30018798]]\n",
      "1995  Cost:  1.0977569 \n",
      "Prediction: \n",
      " [[2.574616  ]\n",
      " [2.5593855 ]\n",
      " [1.7808108 ]\n",
      " [0.90990406]\n",
      " [1.4448237 ]\n",
      " [1.3452611 ]\n",
      " [0.26453066]\n",
      " [0.30007344]]\n",
      "2000  Cost:  1.0973747 \n",
      "Prediction: \n",
      " [[2.5743575 ]\n",
      " [2.5591366 ]\n",
      " [1.7806052 ]\n",
      " [0.9097475 ]\n",
      " [1.4446359 ]\n",
      " [1.3450801 ]\n",
      " [0.26441383]\n",
      " [0.29995894]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, x_dim])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, y_dim])\n",
    "W = tf.Variable(tf.random_normal([x_dim, y_dim]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([y_dim]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "#Minimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 1e-5).minimize(cost)\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], feed_dict = {X:x_data, Y: y_data})\n",
    "    if step % 5 == 0:\n",
    "        print(step,' Cost: ', cost_val, '\\nPrediction: \\n', hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7-2. MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot = True) #label을 one_hot으로 바꾸기\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis =1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training epoch / batch\n",
    "- epoch: 전체 data set을 한 번 다 학습 시킨 것을 one epoch이라 한다. \n",
    "- batch: 몇 개씩 불러올 것인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001  cost =  2.820297588\n",
      "Epoch:  0002  cost =  1.042652133\n",
      "Epoch:  0003  cost =  0.853732881\n",
      "Epoch:  0004  cost =  0.755887076\n",
      "Epoch:  0005  cost =  0.692128849\n",
      "Epoch:  0006  cost =  0.648787716\n",
      "Epoch:  0007  cost =  0.612082051\n",
      "Epoch:  0008  cost =  0.584774076\n",
      "Epoch:  0009  cost =  0.562103268\n",
      "Epoch:  0010  cost =  0.542239473\n",
      "Epoch:  0011  cost =  0.526530240\n",
      "Epoch:  0012  cost =  0.511303535\n",
      "Epoch:  0013  cost =  0.497443372\n",
      "Epoch:  0014  cost =  0.486841581\n",
      "Epoch:  0015  cost =  0.476142364\n",
      "Accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "#parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session(config = config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #Training cycle:\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples/batch_size) #iteration 횟수\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)  #100개씩 data 읽어오기\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X:batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: ', '%04d' % (epoch +1), ' cost = ','{:.9f}'.format(avg_cost))\n",
    "    \n",
    "    #test the model using test sets\n",
    "    print('Accuracy:', accuracy.eval(session = sess, feed_dict = {X: mnist.test.images,\n",
    "                                                                 Y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample image show and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [4]\n",
      "Prediction:  [4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1) #임의의 image 꺼내기 \n",
    "print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], 1))) #실제 label\n",
    "print('Prediction: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], 1), \n",
    "                              feed_dict = {X: mnist.test.images[r:r+1]})) #예측 label\n",
    "\n",
    "#실제 이미지 보기 \n",
    "plt.imshow(mnist.test.images[r:r+1].reshape(28,28), cmap = 'Greys', interpolation = 'nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
